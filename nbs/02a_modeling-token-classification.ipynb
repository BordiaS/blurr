{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from seqeval import metrics as seq_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>nested-labels</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>welt.de vom 29.10.2005 [2005-10-29]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stern.de vom 21.03.2006 [2006-03-21]</td>\n",
       "      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>\n",
       "      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>\n",
       "      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                        source  \\\n",
       "0                                                                                                                                                         n-tv.de vom 26.02.2005 [2005-02-26]    \n",
       "1                                                                                                                                                         welt.de vom 29.10.2005 [2005-10-29]    \n",
       "2  http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&utm_medium=rss-feed&utm_campaign=sport [2010-03-25]    \n",
       "3                                                                                                                                                        stern.de vom 21.03.2006 [2006-03-21]    \n",
       "4                                                                         http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]    \n",
       "\n",
       "                                                                                                                                                                  tokens  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "2   [Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]   \n",
       "3                                                  [Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]   \n",
       "4                                                                  [Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]   \n",
       "\n",
       "                                                                                    labels  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "2             [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                              [B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]   \n",
       "4                                               [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                 nested-labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  \n",
       "2   train  \n",
       "3   train  \n",
       "4   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensures these cols are represented as lists (rather than string)\n",
    "df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval, 'nested-labels': ast.literal_eval}\n",
    "\n",
    "# full nlp dataset\n",
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner_cleaned.csv', converters=df_converters)\n",
    "\n",
    "# demo nlp dataset\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv', converters=df_converters)\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-ORG', 'I-ORGpart', 'I-OTH', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.configuration_bert.BertConfig,\n",
       " transformers.tokenization_bert.BertTokenizer,\n",
       " transformers.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_batch_tfm = HF_TokenClassBatchTransform(hf_arch, hf_tokenizer)\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(hf_arch, hf_tokenizer, hf_batch_tfm=hf_batch_tfm, max_length=128, is_pretokenized=True,\n",
    "                 tok_kwargs={ 'return_special_tokens_mask': True }), \n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('tokens'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('M', 'O'), ('die', 'O'), ('erste', 'O'), ('deutsche', 'B-LOCderiv'), ('Forschung', 'O'), ('in', 'O'), ('der', 'O'), ('Antarktis', 'B-LOC'), (',', 'O'), ('die', 'O'), ('Georg', 'B-LOC'), ('eröffnet', 'O'), ('.', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Im', 'O'), ('hohen', 'O'), ('Norden', 'O'), (',', 'O'), ('so', 'O'), ('heißt', 'O'), ('es', 'O'), (',', 'O'), ('können', 'O'), ('Menschen', 'O'), ('event', 'O'), ('noch', 'O'), ('über', 'O'), (',', 'O'), ('Australien', 'B-LOC'), ('dagegen', 'O'), ('hat', 'O'), ('noch', 'O'), ('höchsten', 'O'), ('zwei', 'O'), ('Monate', 'O'), ('.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for token classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_token_class_metrics(pred_toks, targ_toks, metric_key):\n",
    "    if (metric_key == 'accuracy'): return seq_metrics.accuracy_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'precision'): return seq_metrics.precision_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'recall'): return seq_metrics.recall_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'f1'): return seq_metrics.f1_score(targ_toks, pred_toks)\n",
    "        \n",
    "    if (metric_key == 'classification_report'): return seq_metrics.classification_report(targ_toks, pred_toks)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_TokenClassCallback(HF_BaseModelCallback):\n",
    "    \"\"\"A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the\n",
    "    `seqeval` library.  Additionally, this metric knows how to *not* include your 'ignore_token' in it's\n",
    "    calculations.\n",
    "    \n",
    "    See [here](https://github.com/chakki-works/seqeval) for more information on `seqeval`.\n",
    "    \"\"\"\n",
    "    def __init__(self, tok_metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self, 'tok_metrics, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in tok_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the target's HF_TokenizerTransform (used for rouge metrics)\n",
    "        hf_textblock_tfm = self.dls.tfms[0]\n",
    "        self.hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "        self.ignore_label_token_id = self.dls.tfms[1].ignore_token_id\n",
    "        self.tok_special_symbols = list(self.hf_tokenizer.special_tokens_map.values())\n",
    "        self.tok_kwargs = hf_textblock_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        self.learn.token_classification_report = None\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "    \n",
    "    \n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # do this only for validation set\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0] # yb is TensorText tuple, item 0 is the data\n",
    "        \n",
    "        preds_list, targets_list = [], []   \n",
    "        for i in range(targs.shape[0]):\n",
    "            item_targs, item_preds = [], []\n",
    "            \n",
    "            for j in range(targs.shape[1]):\n",
    "                if (targs[i, j] != self.ignore_label_token_id):\n",
    "                    item_preds.append(self.dls.vocab[preds[i][j].item()])\n",
    "                    item_targs.append(self.dls.vocab[targs[i][j].item()])\n",
    "                    \n",
    "            preds_list.append(item_preds)\n",
    "            targets_list.append(item_targs)\n",
    "            \n",
    "        self.results += [ (res[0], res[1]) for res in zip(preds_list, targets_list) ]\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.results = []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        if (len(self.results) < 1): return\n",
    "        \n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        for k in self.custom_metrics_dict.keys(): \n",
    "            self.custom_metrics_dict[k] = calculate_token_class_metrics(targs, preds, metric_key=k)\n",
    "        \n",
    "        self.learn.token_classification_report = calculate_token_class_metrics(targs, preds, 'classification_report')\n",
    "        \n",
    "        \n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                cbs=[HF_TokenClassCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([4, 38, 18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([4, 38]), 4, torch.Size([4, 38]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([152, 18]) torch.Size([152])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.0006309573538601399, lr_steep=2.0892961401841603e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXSU9fn+8fednSwkQAJCAgQw7DsRBGQtUqEollrXWq1U1Lpg1dZaf63W1tZ+rdq6InVBrWtFK1XcqiyKCIR9DyGENZAQIAtL1vv3RwabxkmYwDx5ZpL7dc4cMs8yc80cyMWzfkRVMcYYY2oLcTuAMcaYwGQFYYwxxisrCGOMMV5ZQRhjjPHKCsIYY4xXVhDGGGO8CnM7gD8lJiZqamqq2zGMMSZorFy58qCqJnmb16QKIjU1lYyMDLdjGGNM0BCRnXXNs11MxhhjvLKCMMYY45UVhDHGGK+sIIwxxnhlBWGMMcYrKwhjjDFeWUEAH2/cT0FJqdsxjDEmoDhWECISJSLLRWStiGwUkd95WSZSRN4UkSwRWSYiqTXm3eOZvlVEvutUzsJj5fz8zTWM+8tCXl6aQ0VllVNvZYwxQcXJLYhSYLyqDgAGAheIyLm1lpkOHFbVs4HHgD8DiEhv4HKgD3AB8LSIhDoRMj46nPduHknf5Hh++95GLnxyCStyDjnxVsYYE1QcKwitVuJ5Gu551B6+birwkufnt4HviIh4pr+hqqWqugPIAoY6lTWtXRyv/nQYT181mMJjZfxw1lLue28DJ8ornXpLY4wJeI4egxCRUBFZA+QBn6rqslqLJAO7AVS1AigE2tSc7rHHM83be8wQkQwRycjPzz+TrEzu157/3DmGn4xM5aWlO7n4qSVk5RWf9msaY0wwc7QgVLVSVQcCKcBQEenrwHvMVtV0VU1PSvJ6v6kGiY4I474L+/DCtenkFZcy5YkveXXZTiqrbOxuY0zz0ihnManqEWAB1ccTatoLdAQQkTAgHiioOd0jxTOt0Yzv2Y6PZo4ivXNr7n13A2MeXsDfF2dTeKwcAFVlV8Ex3l+3j3dX72HVrsMcOlqGqv+K5ER5pV9fzxhjGkKc+gUkIklAuaoeEZEWwCfAn1X1/RrL3Az0U9UbReRyYJqqXioifYDXqD7u0AH4DEhT1XoPCqSnp6u/7+ZaVaV8smk/LyzJYfmOQ7QID6V/SjxbDxRzxFMWNbWMCqN7uzj6JsfTu0NLzm4by86Co6zaeYTVuw+TnX+Us1pG0bF1NJ1aR5MYG0llVRVllUp5ZRWHjpaxs+Aouw4d42BJGWltY5k5IY3JfdsTEiJ+/WzGGCMiK1U13es8BwuiP9UHoEOp3lJ5S1UfEJEHgAxVnSciUcArwCDgEHC5qmZ71r8XuA6oAG5X1Q9P9Z5OFERNG/cVMmdJDlsPFNO7fUv6pcTTPzmBFhGh5Bw8Sk7BUXYcPMrW/cVsyi3iWNl/+yw2MowBHeNJaxtHfnEpOw8dZWfBMYpPVAAQERpCeKiQEB1Bp9bRdG4TTbuWUXywPpesvBJ6tIvjtu+k0at9HKEhQmiIEB0RRuuYCMc+rzGm6XOlINzgdEE0RFWVklNwlKy8Ejq3ieHstrGEetkCqKisIjREqD5569sqq5T31+3jb59tIzv/6Lfmd28Xy/ie7fhOr7YM6phAWKhd+2iM8Z0VRBNQWaUs3pZP4bFyKquUyirl0LEyFmfms3zHISqqlITocMZ2T2J8r3aMSUsiPjrc7djGmABnBdHEFZ0o54vMg3y2+QALM/M5dLSM0BBhSOdWjO/ZlvE925LWNrbOrRRjTPNlBdGMVFYpa/cc4bPNB/h8Sz6bc4sASE5owSVDUpg+qgsto2zLwhhTzQqiGcstPM6CLfl8smk/C7fmE98inBmju3LtiFRiIpvUkOTGmNNgBWEA2LC3kMc+zeSzLXm0jong9glpXDm0kx3YNqYZq68g7DdDM9I3OZ7nrz2Hd382gh7t4vjtexuZ8sSXLN1e4HY0Y0wAsoJohgZ1asVr1w/jmasGU3yigiv+/jU/e3Ul2fklp17ZGNNs2E7oZkpEmNSvPeN6tmX24myeWbidjzbs5+JBydw2Po3UxBi3IxpjXGbHIAwAB0tKeXbRdl5eupOKKmXqwA786NzODOqYYKfHGtOE2UFq47O84hM8s3A7byzfzfHySrq3i+WyczoxbVAyrey2HsY0OVYQpsGKT5Tz/rpc3li+i7V7CokIC2FKv/ZcdW4nBndqZVsVxjQRVhDmjGzaV8Try3fx7uq9lJRW0POsOG4Y05WpA5LtDrPGBDkrCOMXR0sreG/NPl5emsOW/cX0T4nnN1N6c05qa7ejGWNOk10HYfwiJjKMK4d1Yv5to3j00gHkFZXyw1lLufnVVeQVnXA7njHGz6wgTIOFhAjTBqfw+V1j+PmE7ny25QA/mPUVOwu+fTtyY0zwsoIwpy06IoyZE9J4c8ZwSk5UcMmspd/cHNAYE/ysIMwZG9AxgbduGE6oCJc9u5SVOw+5HckY4wdWEMYv0trF8fZNw2kTG8lVzy1jSdZBtyMZY86QYwUhIh1FZIGIbBKRjSIy08syvxCRNZ7HBhGpFJHWnnk5IrLeM89OTQoCKa2ieeuG4XRuHcN1c1bw5TYrCWOCmZNbEBXAnaraGzgXuFlEetdcQFUfVtWBqjoQuAdYpKo190+M88z3egqWCTxJcZG8dv0wuiTGMP2lFXyxLd/tSMaY0+RYQahqrqqu8vxcDGwGkutZ5QrgdafymMbTJjaSV39aXRI/fSmDxZlWEsYEo0Y5BiEiqcAgYFkd86OBC4C5NSYr8ImIrBSRGfW89gwRyRCRjPx8+0UUKNrERvLa9edWl8TLGby3Zq/bkYwxDeR4QYhILNW/+G9X1brOgbwQWFJr99J5qjoYmET17qnR3lZU1dmqmq6q6UlJSX7Nbs5M65gIXr/+XAamJDDzjTU88dk2mtKV+8Y0dY4WhIiEU10Or6rqO/Usejm1di+p6l7Pn3nAu8BQp3Ia57SKieCVnw7l+4OSeeTTTO765zrKKqrcjmWM8YGTZzEJ8DywWVUfrWe5eGAM8F6NaTEiEnfyZ2AisMGprMZZkWGhPHrpAH4+oTtzV+1h+ksrKK+0kjAm0Dm5BTESuBoYX+NU1skicqOI3Fhjue8Dn6hqzfs0tAO+FJG1wHLgA1X9yMGsxmEiwswJaTw0rR9fbDvIH+dvdjuSMeYUHBtyVFW/BE55L2hVnQPMqTUtGxjgSDDjqsuHdiLzQAkvLNlBv+R4pg1OcTuSMaYOdiW1aXT3TO7JuV1bc88761m/p9DtOMaYOlhBmEYXHhrCU1cOJjE2khteyeBgSanbkYwxXlhBGFe0iY3k2auHUHC0jHvfXe92HGOMF1YQxjV9k+P52diz+XjjAdbtOeJ2HGNMLVYQxlXXnZdKq+hwHvkk0+0oxpharCCMq+KiwrlxTDcWZeazIsfGkTAmkFhBGNf9eHgqibGR/OXjrXYrDmMCiBWEcV2LiFBuGdeNZTsO8dX2ArfjGGM8rCBMQLhiWCc6xEfxl09sK8KYQGEFYQJCZFgot34njdW7jvD5ljy34xhjsIIwAeSSISmktonm4Y+3UlllWxHGuM0KwgSM8NAQ7pzYgy37i5m31gYYMsZtVhAmoHyvX3v6dGjJI59kUlpR6XYcY5o1KwgTUEJChLsv6Mmew8d5fdkut+MY06xZQZiAMyotkRHd2vDE51mUlFa4HceYZssKwgQcEeGXF/Sk4GgZz3+xw+04xjRbVhAmIA3smMCkvmcxe/F2Cux24Ma4wgrCBKw7J/bgWHklLy3d6XYUY5olxwpCRDqKyAIR2SQiG0VkppdlxopIYY0xq39bY94FIrJVRLJE5FdO5TSB6+y2sUzo1Y5XluZwvMzOaDKmsTm5BVEB3KmqvYFzgZtFpLeX5b5Q1YGexwMAIhIKPAVMAnoDV9SxrmniZozuyuFj5by9ao/bUYxpdhwrCFXNVdVVnp+Lgc1Aso+rDwWyVDVbVcuAN4CpziQ1gSy9cysGdkzg+S+y7epqYxpZoxyDEJFUYBCwzMvs4SKyVkQ+FJE+nmnJwO4ay+zB93IxTYiIcMPoruQUHOPTTQfcjmNMs+J4QYhILDAXuF1Vi2rNXgV0VtUBwBPAv07j9WeISIaIZOTn5595YBNwJvY5i06to5m9eLvbUYxpVhwtCBEJp7ocXlXVd2rPV9UiVS3x/DwfCBeRRGAv0LHGoimead+iqrNVNV1V05OSkvz+GYz7QkOEn47qwqpdR1i500adM6axOHkWkwDPA5tV9dE6ljnLsxwiMtSTpwBYAaSJSBcRiQAuB+Y5ldUEvkuGpJAQHc7sxdluRzGm2Qhz8LVHAlcD60VkjWfar4FOAKo6C7gEuElEKoDjwOVaPVpMhYjcAnwMhAIvqOpGB7OaABcdEcbV53bmyQVZ5Bw8SmpijNuRjGnypCmN3pWenq4ZGRluxzAOySs+wciHPueqYZ25/6I+p17BGHNKIrJSVdO9zbMrqU3QaBsXxYX9O/D2yj0Unyh3O44xTZ4VhAkqPxnZhZLSCt7KsAvnjHGaFYQJKv1S4jkntRUvfZVjF84Z4zArCBN0fjKyC7sOHeOzzXbhnDFOsoIwQWdi73YkJ7TgxSU5bkcxpkmzgjBBJyw0hB8P78zS7AI27at9cb4xxl+sIExQuvycTrQID+XFJTbinDFOsYIwQSk+OpwfDEnmvbX7bMQ5YxxiBWGC1rUjUimrqOL15bvcjmJMk2QFYYLW2W3jGJWWyCtf76S8ssrtOMY0OVYQJqhdN7ILB4pK+XDDfrejGNPkWEGYoDamexKpbaKZYwerjfE7KwgT1EJChGtGpLJq1xHW7j7idhxjmhQrCBP0LhmSQmxkGHO+ynE7ijFNihWECXpxUeFcMiSF99ftI6/ohNtxjGkyrCBMk3DtiFQqqpSXlua4HcWYJsMKwjQJqYkxTOnfgWcXZbNy52G34xjTJFhBmCbjDxf3pX1CFLe8topDR8vcjmNM0HOsIESko4gsEJFNIrJRRGZ6WeYqEVknIutF5CsRGVBjXo5n+hoRsXFEzSnFtwjn6SuHUFBSxu1vrqHKxosw5ow4uQVRAdypqr2Bc4GbRaR3rWV2AGNUtR/we2B2rfnjVHVgXeOlGlNbv5R4fnthbxZn5vP0wiy34xgT1BwrCFXNVdVVnp+Lgc1Acq1lvlLVkzuMvwZSnMpjmo+rhnVi6sAOPPppJsuyC9yOY0zQapRjECKSCgwCltWz2HTgwxrPFfhERFaKyAzn0pmmRkT44/f7kdyqBff/e5PtajLmNDleECISC8wFbldVr6O7iMg4qgvi7hqTz1PVwcAkqndPja5j3RkikiEiGfn5+X5Ob4JVTGQYd03swebcIv69bp/bcYwJSo4WhIiEU10Or6rqO3Us0x94Dpiqqt/sD1DVvZ4/84B3gaHe1lfV2aqarqrpSUlJ/v4IJohd2L8Dvdu35OGPt1JaUel2HGOCjpNnMQnwPLBZVR+tY5lOwDvA1aqaWWN6jIjEnfwZmAhscCqraZpCQoS7J/Vkz+HjvLbMxowwpqHCHHztkcDVwHoRWeOZ9mugE4CqzgJ+C7QBnq7uEyo8Zyy1A971TAsDXlPVjxzMapqo0WmJjOjWhic+z+KSISnERYW7HcmYoCGqTecAXnp6umZk2CUT5n+t3X2EqU8t4bbvpHHH+d3djmNMQBGRlXVdSmBXUpsmb0DHBL7Xrz3PfZHNAbuZnzE+86kgPMcEQjw/dxeRizwHoI0JCnd9twdVqsx8YzUVNjypMT7xdQtiMRAlIsnAJ1QfW5jjVChj/K1LYgwPXtyPr7MP8cinmadewRjjc0GIqh4DpgFPq+oPgT7OxTLG/34wJIUrhnbimYXb+XTTAbfjGBPwfC4IERkOXAV84JkW6kwkY5xz34W96ZvckjveWsPOgqNuxzEmoPlaELcD9wDvqupGEekKLHAuljHOiAoP5ZmrhhAiwk3/WGUX0BlTD58KQlUXqepFqvpnz8Hqg6p6m8PZjHFEx9bRPPLDAWzKLeLZRdluxzEmYPl6FtNrItLSc1XzBmCTiPzC2WjGOGdC73ZM6d+eJxdkkZ1f4nYcYwKSr7uYentutHcx1Xdc7UL1mUzGBK3fTulNZFgI9767gaZ0wagx/uJrQYR7rnu4GJinquVU347bmKDVtmUUd1/Qk6XZBbyzaq/bcYwJOL4WxLNADhADLBaRzoDXW3cbE0yuHNqJwZ0S+MMHm2wca2Nq8fUg9eOqmqyqk7XaTmCcw9mMcVxIiPDHaf0oPlHBn+ZvdjuOMQHF14PU8SLy6MmBeUTkEaq3JowJej3Pasn087rw9qo9bN1f7HYcYwKGr7uYXgCKgUs9jyLgRadCGdPYbhrbjdiIMB6z23AY8w1fC6Kbqt6nqtmex++Ark4GM6YxJURHcN15Xfho43427C10O44xAcHXgjguIuedfCIiI4HjzkQyxh3TR3UhvkU4j9pWhDGA7wVxI/CUiOSISA7wJHCDY6mMcUHLqHBmjO7K51vyWLXrsNtxjHGdr2cxrVXVAUB/oL+qDgLGO5rMGBdcOyKV1jERdizCGBo4opyqFnmuqAa4w4E8xrgqJjKMm8Z044ttB1m+45DbcYxx1ZkMOSr1zhTpKCILRGSTiGwUkZlelhEReVxEskRknYgMrjHvGhHZ5nlccwY5jWmQH53bmaS4SB75ZKvbUYxx1ZkUxKlutVEB3KmqvYFzgZtFpHetZSYBaZ7HDOAZABFpDdwHDAOGAveJSKszyGqMz1pEhHLTmG4s23GIr7ML3I5jjGvqLQgRKRaRIi+PYqBDfeuqaq6qrvL8XAxsBpJrLTYVeNlzdfbXQIKItAe+C3yqqodU9TDwKXDB6X1EYxruymGdSIqL5G//2eZ2FGNcU29BqGqcqrb08ohT1TBf30REUoFBwLJas5KB3TWe7/FMq2u6t9eecfIK7/z8fF8jGVOvqPBQbhzTjaXZBSyzrQjTTJ3JLiafiEgsMBe4vcYBbr9R1dmqmq6q6UlJSf5+edOMXXVyK+Iz24owzZOjBeG5Rfhc4FVVfcfLInuBjjWep3im1TXdmEZzciviq+0FdkaTaZYcKwgREeB5YLOqPlrHYvOAH3vOZjoXKFTVXOBjYKKItPIcnJ7omWZMo7pqWCcSYyP522d2XYRpfpzcghhJ9ahz40VkjecxWURuFJEbPcvMB7KBLODvwM8AVPUQ8HtghefxgGeaMY2qeiuiK0uy7FiEaX6kKQ21mJ6erhkZGW7HME3M8bJKxj+ykIiwEObdch7xLcLdjmSM34jISlVN9zbP8YPUxgS7FhGhPHnlIPYePs6db62lqqrp/KfKmPpYQRjjgyGdW/Pryb34z+YDPLs42+04xjQKKwhjfPSTkal8r397Hv54C19tP+h2HGMcZwVhjI9EhD//oD9dEmO47fXVHCg64XYkYxxlBWFMA8RGhjHrR0MoKa3grn/a8QjTtFlBGNNAae3iuPd7vfli20Fe+Xqn23FMM+fkmahWEMachh8N68TYHkn8cf5msvKK3Y5jmrHH/rONaU8voaKyyu+vbQVhzGkQEf7vB/2Jjgjl9jfXUFbh/3+cxvhiwZY8QkOEsFD//zq3gjDmNLVtGcWfpvVnw94iHrcb+hkXHCwpZf3eQsZ0d+ZGpVYQxpyBC/qexQ+HpPD0wiwycuxuMKZxLc6sHuJgbI+2jry+FYQxZ+i+i/qQ0iqa299cQ/GJcrfjmGZkUWY+ibER9G7f0pHXt4Iw5gzFRobx2GUD2HfkOPfP2+R2HNNMVFYpizPzGd09iZAQceQ9rCCM8YMhnVtzy/g05q7awwfrct2OY5qB9XsLOXys3LHjD2AFYYzf3Dr+bAZ0TODX764nt/C423FME7dwax4iMDrNCsKYgBceGsLfLhtIeWUVd/1zraMXMBmzcGs+A1ISaBUT4dh7WEEY40epiTH8enIvlmQV8N6afW7HMU3U4aNlrN1zhLE9nNt6ACsIY/zuiqGdGJASz4PzN1NkZzUZByzelo8qjh5/ACsIY/wuNET4/cV9OVhSyl8/tQvojP8tysynVXQ4/VMSHH0fxwpCRF4QkTwR2VDH/F/UGKt6g4hUikhrz7wcEVnvmWdjiJqg0z8lgSuHduKlpTlszi1yO45pQqo8p7eOSksi1KHTW09ycgtiDnBBXTNV9WFVHaiqA4F7gEWqWvNS1HGe+V7HSjUm0P3iuz1oGRXGb9/bYAesjd9syi3iYEmZ47uXwMGCUNXFgK/3HrgCeN2pLMa4ISE6gl9N6smKnMPMXbXX7TimiZjzVQ7hocIYhw9QQwAcgxCRaKq3NObWmKzAJyKyUkRmnGL9GSKSISIZ+fn5TkY1psF+OKQjQzq34jf/2sDa3UfcjmOC3JrdR3h75R6uO68LibGRjr+f6wUBXAgsqbV76TxVHQxMAm4WkdF1rayqs1U1XVXTk5Kcb1RjGiIkRHjmqsG0iY3gujkryDl41O1IJkhVVSn3z9tIUlwkt45Pa5T3DISCuJxau5dUda/nzzzgXWCoC7mM8Yu2LaN46bqhVKlyzYvLOVhS6nYkE4T+tWYva3Yf4e4LehIbGdYo7+lqQYhIPDAGeK/GtBgRiTv5MzAR8HomlDHBoltSLM9few4Hik5w3ZwVHC2tcDuSCSIlpRU89OEWBnRMYNqg5EZ7XydPc30dWAr0EJE9IjJdRG4UkRtrLPZ94BNVrbnd3Q74UkTWAsuBD1T1I6dyGtNYBndqxZNXDGbD3kJ+/uYaqqrszCbjm6cWZJFXXMr9F/Z27M6t3ji2naKqV/iwzByqT4etOS0bGOBMKmPcNaF3O+79Xm9+//4mnl6YxS2NtC/ZBJ+yiiqWZhfw8cb9vJ2xh2mDkxnUqVWjZmicHVnGmG9cNzKVdXuO8MinmfRJjmecQ6OBmeCkqjz00RZeW7aL4hMVREeEMrFPO+6d3KvRs1hBGNPIRISHpvVn6/5iZr6+mn/feh6d28S4HcsEiANFpTy7KJtRaYlcMzyV89ISiQoPdSVLIJzFZEyz0yIilNlXpyMi3PDKSo6V2UFrU+3krVluGXc2E3q3c60cwArCGNd0ahPN3y4fSOaBYma8vJIT5ZVuRzIBYJOnIHp1cGac6YawgjDGRWN7tOXhSwawZPtBbvrHSkorrCSau825RaS0akHLqHC3o1hBGOO2HwxJ4cGL+7Fgaz63vraa8soqtyMZF23KLaJXe/e3HsAKwpiAcOWwTtx/YW8+2XSA299cQ6VdI9EsHS+rJOfg0YApCDuLyZgAce3ILpRWVPGnD7dwdlIsPz+/u9uRTCPbeqCYKoXeAVIQtgVhTACZMbor0wYn8/jn21iUaXcnbm427as+QG0FYYz5FhHhwYv70aNdHLe/sZq9R467Hck0os25RcRGhpHSqoXbUQArCGMCTouIUJ6+ajDllcrNr66irMIOWjcXm3OL6NU+rlHvt1QfKwhjAlDXpFj+75L+rNl9hD98sMntOKYRVFUpW/YXB8wBarCCMCZgTe7Xnp+e14WXl+5k9uLtbscxDtt9+BglpRUBVRB2FpMxAeyeyb3ILTrBH+dvISE6gkvTO7odyTjk5C02rCCMMT4JDREeu3QgRcfL+dXcdSS0CGdin7PcjmUcsCm3mBCBHu3i3I7yDdvFZEyAiwgLYdaPhtAvJYFbXl/NV9sPuh3JOGBzbhFdEmNoEeHezflqs4IwJgjERIYx59pz6NQ6mmtfWMGbK3a5Hcn42aZ9gXOLjZOsIIwJEq1iIvjnDcMZ1rU1d89dz//713o7BTZI5ReXsmFv4TfPC4+Xs/fI8eZTECLygojkiciGOuaPFZFCEVnjefy2xrwLRGSriGSJyK+cymhMsGkVE8GcnwzlhjFd+cfXu7jy71+zfk8hFXaDv6ChqtzwSgYXPvklL3y5A4AtngPUvQPgFt81OXmQeg7wJPByPct8oapTak4QkVDgKeB8YA+wQkTmqaqdDG4M1Qeu75nUi37J8fzin+u48MkviYkIZVCnVpyT2pprRnQmITrC7ZimDgu25rFq1xG6JsXwwPub2HXo2DdXTgfKLTZOcqwgVHWxiKSexqpDgSxVzQYQkTeAqYAVhDE1TOnfgWFd2rA0u4CMnEOsyDnMXz/L5L01e3nh2nNITbRhTANNVZXyl48z6dwmmg9njuLhj7by3Jc7iAoPoXVMBG3jIt2O+D/cPgYxXETWisiHItLHMy0Z2F1jmT2eacaYWpLiIrloQAcemNqXD2eO4p83DOfwsTKmPfMVK3cecjueqeXDDfvZlFvE7RPSiAwL5f9N6c0DU/tQVlFFnw4tEQmMW2yc5GZBrAI6q+oA4AngX6fzIiIyQ0QyRCQjP9/ufmmat/TU1rzzs5HEtwjnir8v499r97kdyXhUVimPfrqVtLaxXDTgv//n/fHwVObdch5//H4/F9N551pBqGqRqpZ4fp4PhItIIrAXqHm5aIpnWl2vM1tV01U1PSkpydHMxgSDLokxvHPTCAakxHPr66uZ+cZq9heecDtWs/ev1XvZnn+UO87vTmitm/H1TY6nY+tol5LVzbWCEJGzxLM9JSJDPVkKgBVAmoh0EZEI4HJgnls5jQlGrWIieGX6MG4bfzYfbtjP+EcWMmvRdjst1iVlFVX89bNM+ia35IK+wXMlvJOnub4OLAV6iMgeEZkuIjeKyI2eRS4BNojIWuBx4HKtVgHcAnwMbAbeUtWNTuU0pqmKCg/ljok9+M/PxzCiWyIPfbiFyY9/wZb9RW5Ha3beytjN7kPHuXNij4A7zlAfUW06Y9+mp6drRkaG2zGMCUifbznA3XPXU3yinAem9rUb/zWSE+WVjHl4ASmtonn7xuEBVxAislJV073Nc/ssJmNMIxnfsx0f3HYegzu14pdvr+Ouf67leFml27GavH98vZMDRaXcFWRbD2AFYUyz0jYuilemD2Pmd9KYu2oPV/z9a06UW0n4YsPeQhZsyaOyyve9LiWlFTy9cDvnnZ3I8G5tHEznDLvdtzHNTGiI8PPzu5zRLNcAAA57SURBVNPzrDh+9toq7p67jr9eNjDo/nfbWIpOlPPwR1v5x7KdqEJa21hmTkhjct/2pxwa9MUvd3DoaBl3fbdHI6X1LysIY5qpSf3ac9fEHjz88Va6t4vj5nFnux3J79buPsKGfYVcNKADcVHhDVpXVflgfS6/+/cmCkpKuXZEKgM7JvDE51nc8tpqerTL4ofpKfQ8qyU9zoojqdZV0EeOlTF7cTYTerVjYMcEf36sRmMFYUwz9rOx3cg8UMzDH1dfwNXUBiP63b83smrXER6av4XLh3bk2pFdSE5occr1KiqruPfdDbyZsZu+yS15/pp0+qdU/5Kf0r8D76/bxxOfZ/GHDzZ/s05ibATDurZhQq+2jOvRlmcXZ1NSVsGdE7s79vmcZmcxGdPMnSiv5LJnl7Itr4S3bxwRcHcUPV2Fx8oZ9PtPuGhAByoV5q/PBWBM9yQm9GrHd3q1pV3LqG+td7yskltfX8V/Nudx87hu/HxCd8JCvR+uPVhSytb9xWzZX8zGfYUszjzIwZJSQgRCRJjcrz2PXzHI0c95puo7i8kKwhjDgaITTH1yCaUVlbx03dBv/rcczD5Yl8vNr61i7k3DGdK5NXsOH+OVpTuZvyGX3YeOAzAgJZ4xPdoypnsSA1LiKSmtYPpLGazadZgHLurD1cNTG/SeVVXKur2FfLb5AGv3FPLgxX0D8grpmqwgjDGntLPgKD96fhmHj5bz3DXpnNs1+M66qenut9cxf0Muq39z/v9sAagq2/JK+HTTAT7bfIA1u49QpdAyKoyYyDAKSsr46+UDmdyvvYvpG48VhDHGJ/sLT3D188vYdegYz/xoMON7tnM70mlRVUY89DkDOybwzI+G1LvskWNlfJl1kMWZ+WzPP8qdE7szoltiIyV1n10oZ4zxyVnxUbx5w3C6t4tjxssrmb14e1COVpeVV0Ju4QlGdz/1DTwToiOY0r8D/3fJAObeNKJZlcOpWEEYY/5H65gIXrt+GON6tuWP87cw7Zmv2JwbXPdvWpRZfet/XwrC1M0KwhjzLXFR4cy+eghPXjmIvYePc+ETX/LIJ1s5VlbhdjSfLMrM5+y2sT6d0mrqZgVhjPFKRJjSvwP/uWMMFw3swBOfZzHm4YW88vVOygN4t9OJ8kqW7zjE6DTbejhTVhDGmHq1iong0UsHMvem4XRpE8Nv/rWBCY8u4r01e6lqwH2JGsuyHYcorahidHc7lnCmrCCMMT4Z0rk1b95wLi9eew4twkOZ+cYaLnrqS5ZkHXQ72v9YnJlPRFgIw7oE92m6gcAKwhjjMxFhXM+2zL9tFI9dNoDDR8u56rll/PiF5azadZhAOG1+UWY+w7q0pkVEqNtRgp7di8kY02AhIcL3B6UwqW97Xlm6kycXZDHt6a/o2LoF3+vXgSn929OnQ8tGv0PsviPHycor4TIbDMkvrCCMMactKjyU60d35bKhHflow37eX5fL37/IZtai7QzomMCd53dnVFpioxXFZ1vyABjTww5Q+4NjBSEiLwBTgDxV7etl/lXA3YAAxcBNqrrWMy/HM60SqKjrKj9jTGBoGRXOpekduTS9I4eOlvHBun3MWpTNj19YztDU1twxsbvjt+44UV7JrIXb6ZccT1rbWEffq7lw8hjEHOCCeubvAMaoaj/g98DsWvPHqepAKwdjgkvrmAiuHp7K53eN4fdT+5BTcJTLZ3/N/fM2OnrW0ytLd7L3yHHumdTTBj/yE8cKQlUXA4fqmf+Vqh72PP0aSHEqizGm8UWGhXL18FQW/3IcPxmZypyvcrj1jdWUVvh/iNPCY+U8uSCLMd2TGHG2nd7qL4FyDGI68GGN5wp8IiIKPKuqtbcujDFBIio8lPsu7EOH+BY8OH8zBSWlzP5xOi0bOMJbfZ5elEXRiXJ+Namn317TBMBpriIyjuqCuLvG5PNUdTAwCbhZREbXs/4MEckQkYz8/HyH0xpjTtf1o7vy18sGsnLnYS6dtZTFmfl+OS1235HjvLgkh+8PSqZX+6Yx2FGgcLUgRKQ/8BwwVVULTk5X1b2eP/OAd4Ghdb2Gqs5W1XRVTU9KsjMXjAlkFw9K5oVrz+FgSRk/fmE5Ex9bzKvLdnK87PR3Oz36aSYo3HF+8A7tGahc28UkIp2Ad4CrVTWzxvQYIERViz0/TwQecCmmMcbPRqUlseRX4/j32lxeXLKDe9/dwEMfbuF7/dpz8aBkhqa2JiRE2HagmPfX5fLxxv1EhYcyolsbRnRLZEjnVuw9coxlOw6xfMch5q3dx0/P60JKq8AeuS0YOTZgkIi8DowFEoEDwH1AOICqzhKR54AfADs9q1SoarqIdKV6qwGqC+w1VX3Ql/e0AYOMCS6qyoqcw7yxfBcfbdzPsbJKOsRHERsVRuaBEkRgaGprKqqUtbuPUFHrLKikuEhGpSVy34V9iG/hv2MazYmNKGeMCXjHyir4dNMB3luzj2NlFUzq255Jfc+ibcsoAEpKK1iRc4hVOw+T0qoFQ7u0IbVNtJ3SeoasIIwxxnhlQ44aY4xpMCsIY4wxXllBGGOM8coKwhhjjFdWEMYYY7yygjDGGOOVFYQxxhivrCCMMcZ41aQulBORQmBbjUnxQKGPPycCB0/jbWu+VkPme5tee9qpMp9p9vrynWr+qfLX9Vka87uvb5n6vuvaz+279z2bL8v467uH5vnv1t/ffYKqer/Tqao2mQcwu67np/oZyPDHe/o639v0huY/0+xO5q/rszTmd9+Q/PbdB99372T+QP536+R3X/vR1HYx/bue57787I/39HW+t+kNzX+m2X15jdPNX9dnaczvvr5l6vuuaz+37963DL4u05S/+9rPncjv5Hf/P5rULqYzISIZGqTjXwdzdgju/MGcHSy/m4Ihe1PbgjgTwTysaTBnh+DOH8zZwfK7KeCz2xaEMcYYr2wLwhhjjFdWEMYYY7yygjDGGOOVFYQPRGSUiMwSkedE5Cu38zSEiISIyIMi8oSIXON2noYSkbEi8oXn+x/rdp6GEpEYEckQkSluZ2koEenl+d7fFpGb3M7TECJysYj8XUTeFJGJbudpKBHpKiLPi8jbbuZo8gUhIi+ISJ6IbKg1/QIR2SoiWSLyq/peQ1W/UNUbgfeBl5zMW5M/sgNTgRSgHNjjVFZv/JRfgRIgikbM76fsAHcDbzmTsm5++nu/2fP3/lJgpJN5a/JT9n+p6vXAjcBlTuatzU/5s1V1urNJT63Jn8UkIqOp/gXzsqr29UwLBTKB86n+pbMCuAIIBf5U6yWuU9U8z3pvAdNVtThYsnseh1X1WRF5W1UvaYzsfsx/UFWrRKQd8KiqXhVE2QcAbagut4Oq+n5jZPdk9cvfexG5CLgJeEVVXwum7J71HgFeVdVVjZHd857+zN+o/2ZrC3PrjRuLqi4WkdRak4cCWaqaDSAibwBTVfVPgNddASLSCShsrHIA/2QXkT1AmedppXNpv81f373HYSDSiZze+Om7HwvEAL2B4yIyX1WrnMx9kr++e1WdB8wTkQ+ARikIP333AjwEfNiY5QB+/3vvqiZfEHVIBnbXeL4HGHaKdaYDLzqWyHcNzf4O8ISIjAIWOxnMRw3KLyLTgO8CCcCTzkY7pQZlV9V7AUTkWjxbQo6mO7WGfvdjgWlUF/N8R5OdWkP/3t8KTADiReRsVZ3lZDgfNPS7bwM8CAwSkXs8RdLommtBNJiq3ud2htOhqseoLregpKrvUF1yQUtV57id4XSo6kJgocsxTouqPg487naO06WqBVQfP3FVkz9IXYe9QMcaz1M804JBMGeH4M4fzNkhuPMHc3YI0vzNtSBWAGki0kVEIoDLgXkuZ/JVMGeH4M4fzNkhuPMHc3YI1vyncz/yYHoArwO5/Pc0z+me6ZOpPqtgO3Cv2zmbWvZgzx/M2YM9fzBnbwr5az6a/GmuxhhjTk9z3cVkjDHmFKwgjDHGeGUFYYwxxisrCGOMMV5ZQRhjjPHKCsIYY4xXVhCmSRORkkZ+P7+MFyLV42AUisgaEdkiIn/xYZ2LRaS3P97fGLCCMKZBRKTe+5ep6gg/vt0XqjoQGARMEZFTjclwMdV3jjXGL6wgTLMjIt1E5CMRWSnVo9X19Ey/UESWichqEfmPZwwKROR+EXlFRJYAr3ievyAiC0UkW0Ruq/HaJZ4/x3rmv+3ZAnjVcwtqRGSyZ9pKEXlcROodJ0JVjwNrqL4jKCJyvYisEJG1IjJXRKJFZARwEfCwZ6ujW12f0xhfWUGY5mg2cKuqDgHuAp72TP8SOFdVBwFvAL+ssU5vYIKqXuF53pPq25APBe4TkXAv7zMIuN2zbldgpIhEAc8Ckzzvn3SqsCLSCkjjv7drf0dVz1HVAcBmqm/l8BXV9/b5haoOVNXt9XxOY3xit/s2zYqIxAIjgH96/kMP/x2IKAV4U0TaAxHAjhqrzvP8T/6kD1S1FCgVkTygHd8eEnW5qu7xvO8aIJXqkcayVfXka78OzKgj7igRWUt1OfxVVfd7pvcVkT9QPUZGLPBxAz+nMT6xgjDNTQhwxLNvv7YnqB7WdJ5nsJz7a8w7WmvZ0ho/V+L935Ivy9TnC1WdIiJdgK9F5C1VXQPMAS5W1bWewYjGelm3vs9pjE9sF5NpVlS1CNghIj+E6qEpRWSAZ3Y8/71H/zUORdgKdK0xJOVlp1rBs7XxEHC3Z1IckOvZrVVzjO5iz7xTfU5jfGIFYZq6aBHZU+NxB9W/VKd7dt9sBKZ6lr2f6l0yK4GDToTx7Kb6GfCR532KgUIfVp0FjPYUy2+AZcASYEuNZd4AfuE5yN6Nuj+nMT6x230b08hEJFZVSzxnNT0FbFPVx9zOZUxttgVhTOO73nPQeiPVu7WedTmPMV7ZFoQxxhivbAvCGGOMV1YQxhhjvLKCMMYY45UVhDHGGK+sIIwxxnhlBWGMMcar/w/xRj4YcCPZkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.302354</td>\n",
       "      <td>0.226072</td>\n",
       "      <td>0.934595</td>\n",
       "      <td>0.388186</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.375510</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.131199</td>\n",
       "      <td>0.126418</td>\n",
       "      <td>0.964324</td>\n",
       "      <td>0.713080</td>\n",
       "      <td>0.637736</td>\n",
       "      <td>0.673307</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.071447</td>\n",
       "      <td>0.116839</td>\n",
       "      <td>0.973784</td>\n",
       "      <td>0.725738</td>\n",
       "      <td>0.735043</td>\n",
       "      <td>0.730361</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max= 3e-5, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      PER       0.94      0.89      0.91        53\n",
      "      LOC       0.85      0.69      0.76        58\n",
      "      ORG       0.75      0.67      0.71        67\n",
      "      OTH       0.52      0.71      0.60        31\n",
      " LOCderiv       0.89      0.70      0.78        23\n",
      "  LOCpart       0.33      1.00      0.50         2\n",
      "\n",
      "micro avg       0.73      0.74      0.73       234\n",
      "macro avg       0.80      0.74      0.76       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_TokenClassInput, y:HF_TokenTensorCategory, samples, outs, learner=None, \n",
    "                 ctxs=None, max_n=6, **kwargs):    \n",
    "    # grab tokenizer\n",
    "    hf_textblock_tfm = learner.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x[0], y, samples, outs):\n",
    "        inp_trg_preds = [ (hf_tokenizer.ids_to_tokens[tok_id.item()], lbl_id.item(), pred_lbl) \n",
    "                         for tok_id, lbl_id, pred_lbl in zip(inp, trg, ast.literal_eval(pred[0])) \n",
    "                         if (tok_id not in hf_tokenizer.all_special_ids) and lbl_id != -100 ]\n",
    "        \n",
    "        res.append([f'{[ (itp[0], lbl, itp[2]) for itp, lbl in zip(inp_trg_preds, ast.literal_eval(sample[1])) ]}'])\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Damit', 'O', 'O'), ('konnte', 'O', 'O'), ('man', 'O', 'O'), ('allerdings', 'O', 'O'), ('nichts', 'O', 'O'), ('an', 'O', 'O'), ('«', 'O', 'O'), (',', 'O', 'O'), ('mein', 'O', 'O'), ('Helmut', 'B-PER', 'B-PER'), ('Bit', 'I-PER', 'I-PER'), ('und', 'O', 'O'), ('lac', 'O', 'O'), ('.', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Verlag', 'O', 'O'), ('sich', 'O', 'O'), ('die', 'O', 'O'), ('Ko', 'O', 'O'), ('weg', 'O', 'O'), ('von', 'O', 'O'), ('einer', 'O', 'O'), ('Ko', 'O', 'O'), ('zwischen', 'O', 'O'), ('Unternehmen', 'O', 'O'), ('einer', 'O', 'O'), ('Branch', 'O', 'O'), ('hin', 'O', 'O'), ('zu', 'O', 'O'), ('einer', 'O', 'O'), ('Ko', 'O', 'O'), ('zwischen', 'O', 'O'), ('kapital', 'O', 'O'), ('National', 'O', 'O'), ('und', 'O', 'O'), ('Kap', 'O', 'O'), (',', 'O', 'O'), ('nimmt', 'O', 'O'), ('sie', 'O', 'O'), ('mehr', 'O', 'O'), ('und', 'O', 'O'), ('mehr', 'O', 'O'), ('auch', 'O', 'O'), ('militärische', 'O', 'O'), ('Formen', 'O', 'O'), ('an', 'O', 'O'), ('.', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict_tokens(self:Learner, inp, **kargs):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
    "    get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input\n",
    "    \"\"\"\n",
    "    pred_lbls, pred_lbl_ids, probs = self.blurr_predict(inp)\n",
    "\n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_textblock_tfm.kwargs\n",
    "    \n",
    "    # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "    # return\n",
    "    subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity)))) for entity in inp ]\n",
    "    \n",
    "    # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "    # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "    # (e.g., [CLS], [SEP], etc...)\n",
    "    res = hf_tokenizer(inp, None, \n",
    "                       max_length=hf_textblock_tfm.max_length,\n",
    "                       padding=hf_textblock_tfm.padding,\n",
    "                       truncation=hf_textblock_tfm.truncation,\n",
    "                       is_pretokenized=hf_textblock_tfm.is_pretokenized,\n",
    "                       **tok_kwargs)\n",
    "\n",
    "    special_toks_msk = L(res['special_tokens_mask'])\n",
    "    actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "    # using the indexes to the actual tokens, get that info from the results returned above\n",
    "    pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "    actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "    actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "    actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "    # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "    # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "    offset = 0\n",
    "    raw_trg_idxs = []\n",
    "    for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "        raw_trg_idxs.append(idx+offset)\n",
    "        offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "\n",
    "    return inp, actual_pred_lbls[raw_trg_idxs], actual_pred_lbl_ids[raw_trg_idxs], actual_probs[raw_trg_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict_tokens\" class=\"doc_header\"><code>Learner.blurr_predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict_tokens</code>(**`inp`**, **\\*\\*`kargs`**)\n",
       "\n",
       "Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
       "get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "print([(tok, lbl) for tok,lbl in zip(res[0],res[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-language-modeling.ipynb.\n",
      "Converted 01c_data-question-answering.ipynb.\n",
      "Converted 01d_data-token-classification.ipynb.\n",
      "Converted 01e_data-summarization.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-language-modeling.ipynb.\n",
      "Converted 02c_modeling-question-answering.ipynb.\n",
      "Converted 02d_modeling-token-classification.ipynb.\n",
      "Converted 02e_modeling-summarization.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
