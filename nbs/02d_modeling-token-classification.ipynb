{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai2.text.all import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from seqeval import metrics as seq_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>nested-labels</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>welt.de vom 29.10.2005 [2005-10-29]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stern.de vom 21.03.2006 [2006-03-21]</td>\n",
       "      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>\n",
       "      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>\n",
       "      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                        source  \\\n",
       "0                                                                                                                                                         n-tv.de vom 26.02.2005 [2005-02-26]    \n",
       "1                                                                                                                                                         welt.de vom 29.10.2005 [2005-10-29]    \n",
       "2  http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&utm_medium=rss-feed&utm_campaign=sport [2010-03-25]    \n",
       "3                                                                                                                                                        stern.de vom 21.03.2006 [2006-03-21]    \n",
       "4                                                                         http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]    \n",
       "\n",
       "                                                                                                                                                                  tokens  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "2   [Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]   \n",
       "3                                                  [Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]   \n",
       "4                                                                  [Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]   \n",
       "\n",
       "                                                                                    labels  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "2             [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                              [B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]   \n",
       "4                                               [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                 nested-labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  \n",
       "2   train  \n",
       "3   train  \n",
       "4   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensures these cols are represented as lists (rather than string)\n",
    "df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval, 'nested-labels': ast.literal_eval}\n",
    "\n",
    "# full nlp dataset\n",
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner_cleaned.csv', converters=df_converters)\n",
    "\n",
    "# demo nlp dataset\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv', converters=df_converters)\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-ORG', 'I-ORGpart', 'I-OTH', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.configuration_bert.BertConfig,\n",
       " transformers.tokenization_bert.BertTokenizer,\n",
       " transformers.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_batch_tfm = HF_TokenClassBatchTransform(hf_arch, hf_tokenizer)\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(hf_arch, hf_tokenizer, hf_batch_tfm=hf_batch_tfm, max_length=128, is_pretokenized=True,\n",
    "                 tok_kwargs={ 'return_special_tokens_mask': True }), \n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('tokens'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Lane', 'B-PER'), ('änderte', 'O'), ('aber', 'O'), ('seine', 'O'), ('Meinung', 'O'), ('und', 'O'), ('trat', 'O'), ('dieser', 'O'), ('Partei', 'O'), ('nicht', 'O'), ('bei', 'O'), ('.', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Es', 'O'), ('geht', 'O'), ('dar', 'O'), (',', 'O'), ('die', 'O'), ('Bauten', 'O'), ('zu', 'O'), ('s', 'O'), (',', 'O'), ('die', 'O'), ('bei', 'O'), ('für', 'O'), ('ihre', 'O'), ('Bau', 'O'), ('sind', 'O'), ('.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for token classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_token_class_metrics(pred_toks, targ_toks, metric_key):\n",
    "    if (metric_key == 'accuracy'): return seq_metrics.accuracy_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'precision'): return seq_metrics.precision_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'recall'): return seq_metrics.recall_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'f1'): return seq_metrics.f1_score(targ_toks, pred_toks)\n",
    "        \n",
    "    if (metric_key == 'classification_report'): return seq_metrics.classification_report(targ_toks, pred_toks)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_TokenClassCallback(HF_BaseModelCallback):\n",
    "    \"\"\"A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the\n",
    "    `seqeval` library.  Additionally, this metric knows how to *not* include your 'ignore_token' in it's\n",
    "    calculations.\n",
    "    \n",
    "    See [here](https://github.com/chakki-works/seqeval) for more information on `seqeval`.\n",
    "    \"\"\"\n",
    "    def __init__(self, tok_metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self, 'tok_metrics, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in tok_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the target's HF_TokenizerTransform (used for rouge metrics)\n",
    "        hf_textblock_tfm = self.dls.tfms[0]\n",
    "        self.hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "        self.ignore_label_token_id = self.dls.tfms[1].ignore_token_id\n",
    "        self.tok_special_symbols = list(self.hf_tokenizer.special_tokens_map.values())\n",
    "        self.tok_kwargs = hf_textblock_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        self.learn.token_classification_report = None\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def begin_fit(self): self.setup()\n",
    "    \n",
    "    \n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # do this only for validation set\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0] # yb is TensorText tuple, item 0 is the data\n",
    "        \n",
    "        preds_list, targets_list = [], []   \n",
    "        for i in range(targs.shape[0]):\n",
    "            item_targs, item_preds = [], []\n",
    "            \n",
    "            for j in range(targs.shape[1]):\n",
    "                if (targs[i, j] != self.ignore_label_token_id):\n",
    "                    item_preds.append(self.dls.vocab[preds[i][j].item()])\n",
    "                    item_targs.append(self.dls.vocab[targs[i][j].item()])\n",
    "                    \n",
    "            preds_list.append(item_preds)\n",
    "            targets_list.append(item_targs)\n",
    "            \n",
    "        self.results += [ (res[0], res[1]) for res in zip(preds_list, targets_list) ]\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def begin_validate(self): self.results = []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        if (len(self.results) < 1): return\n",
    "        \n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        for k in self.custom_metrics_dict.keys(): \n",
    "            self.custom_metrics_dict[k] = calculate_token_class_metrics(targs, preds, metric_key=k)\n",
    "        \n",
    "        self.learn.token_classification_report = calculate_token_class_metrics(targs, preds, 'classification_report')\n",
    "        \n",
    "        \n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                cbs=[HF_TokenClassCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([4, 128, 18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([4, 128]), 4, torch.Size([4, 128]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 18]) torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.002290867641568184, lr_steep=1.4454397387453355e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.315009</td>\n",
       "      <td>0.217179</td>\n",
       "      <td>0.944855</td>\n",
       "      <td>0.494585</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.514071</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.116868</td>\n",
       "      <td>0.127294</td>\n",
       "      <td>0.965435</td>\n",
       "      <td>0.693141</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.067731</td>\n",
       "      <td>0.114642</td>\n",
       "      <td>0.968074</td>\n",
       "      <td>0.732852</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.711033</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max= 3e-5, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      ORG       0.78      0.51      0.62        74\n",
      "      PER       0.92      0.88      0.90        83\n",
      "      LOC       0.81      0.72      0.76        82\n",
      " LOCderiv       0.88      0.66      0.75        35\n",
      "      OTH       0.36      0.50      0.42        20\n",
      "\n",
      "micro avg       0.73      0.69      0.71       294\n",
      "macro avg       0.81      0.69      0.74       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_TokenClassInput, y:HF_TokenTensorCategory, samples, outs, learner=None, \n",
    "                 ctxs=None, max_n=6, **kwargs):    \n",
    "    # grab tokenizer\n",
    "    hf_textblock_tfm = learner.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x[0], y, samples, outs):\n",
    "        inp_trg_preds = [ (hf_tokenizer.ids_to_tokens[tok_id.item()], lbl_id.item(), pred_lbl) \n",
    "                         for tok_id, lbl_id, pred_lbl in zip(inp, trg, ast.literal_eval(pred[0])) \n",
    "                         if (tok_id not in hf_tokenizer.all_special_ids) and lbl_id != -100 ]\n",
    "        \n",
    "        res.append([f'{[ (itp[0], lbl, itp[2]) for itp, lbl in zip(inp_trg_preds, ast.literal_eval(sample[1])) ]}'])\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Chrysler', 'B-ORG', 'B-ORG'), ('ist', 'O', 'O'), ('der', 'O', 'O'), ('dr', 'O', 'O'), ('US', 'B-LOCpart', 'B-LOCderiv'), ('und', 'O', 'O'), ('gehörte', 'O', 'O'), ('einst', 'O', 'O'), ('Daimler', 'B-ORG', 'B-ORG'), ('.', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Ihre', 'O', 'O'), ('Haupt', 'O', 'O'), ('ist', 'O', 'O'), ('der', 'O', 'O'), ('Vert', 'O', 'O'), ('der', 'O', 'O'), ('von', 'O', 'O'), ('der', 'O', 'O'), ('DE', 'B-ORG', 'B-ORG'), ('ver', 'O', 'O'), ('Dokumentarfilm', 'O', 'O'), ('.', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'B-LOC']\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict_tokens(self:Learner, inp, **kargs):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
    "    get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input\n",
    "    \"\"\"\n",
    "    pred_lbls, pred_lbl_ids, probs = self.blurr_predict(inp)\n",
    "\n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_textblock_tfm.kwargs\n",
    "    \n",
    "    # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "    # return\n",
    "    subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity)))) for entity in inp ]\n",
    "    \n",
    "    # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "    # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "    # (e.g., [CLS], [SEP], etc...)\n",
    "    res = hf_tokenizer(inp, None, \n",
    "                       max_length=hf_textblock_tfm.max_length,\n",
    "                       padding=hf_textblock_tfm.padding,\n",
    "                       truncation=hf_textblock_tfm.truncation,\n",
    "                       is_pretokenized=hf_textblock_tfm.is_pretokenized,\n",
    "                       **tok_kwargs)\n",
    "\n",
    "    special_toks_msk = L(res['special_tokens_mask'])\n",
    "    actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "    # using the indexes to the actual tokens, get that info from the results returned above\n",
    "    pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "    actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "    actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "    actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "    # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "    # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "    offset = 0\n",
    "    raw_trg_idxs = []\n",
    "    for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "        raw_trg_idxs.append(idx+offset)\n",
    "        offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "\n",
    "    return inp, actual_pred_lbls[raw_trg_idxs], actual_pred_lbl_ids[raw_trg_idxs], actual_probs[raw_trg_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict_tokens\" class=\"doc_header\"><code>Learner.blurr_predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict_tokens</code>(**`inp`**, **\\*\\*`kargs`**)\n",
       "\n",
       "Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
       "get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "print([(tok, lbl) for tok,lbl in zip(res[0],res[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-language-modeling.ipynb.\n",
      "Converted 01c_data-question-answering.ipynb.\n",
      "Converted 01d_data-token-classification.ipynb.\n",
      "Converted 01e_data-text-generation.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-language-modeling.ipynb.\n",
      "Converted 02c_modeling-question-answering.ipynb.\n",
      "Converted 02d_modeling-token-classification.ipynb.\n",
      "Converted 02e_modeling-text-generation.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
