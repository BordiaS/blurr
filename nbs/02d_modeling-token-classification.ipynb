{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai2.text.all import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>nested-labels</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>welt.de vom 29.10.2005 [2005-10-29]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stern.de vom 21.03.2006 [2006-03-21]</td>\n",
       "      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>\n",
       "      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>\n",
       "      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                        source  \\\n",
       "0                                                                                                                                                         n-tv.de vom 26.02.2005 [2005-02-26]    \n",
       "1                                                                                                                                                         welt.de vom 29.10.2005 [2005-10-29]    \n",
       "2  http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&utm_medium=rss-feed&utm_campaign=sport [2010-03-25]    \n",
       "3                                                                                                                                                        stern.de vom 21.03.2006 [2006-03-21]    \n",
       "4                                                                         http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]    \n",
       "\n",
       "                                                                                                                                                                  tokens  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "2   [Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]   \n",
       "3                                                  [Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]   \n",
       "4                                                                  [Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]   \n",
       "\n",
       "                                                                                    labels  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "2             [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                              [B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]   \n",
       "4                                               [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                 nested-labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  \n",
       "2   train  \n",
       "3   train  \n",
       "4   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensures these cols are represented as lists (rather than string)\n",
    "df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval, 'nested-labels': ast.literal_eval}\n",
    "\n",
    "# full nlp dataset\n",
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner_cleaned.csv', converters=df_converters)\n",
    "\n",
    "# demo nlp dataset\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv', converters=df_converters)\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGderiv', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-LOCpart', 'I-ORG', 'I-ORGderiv', 'I-ORGpart', 'I-OTH', 'I-OTHderiv', 'I-OTHpart', 'I-PER', 'I-PERderiv', 'I-PERpart', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.ForTokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.tokenization_bert.BertTokenizer,\n",
       " transformers.configuration_bert.BertConfig,\n",
       " transformers.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_tokenizer, hf_config, hf_model = BLURR_MODEL_HELPER.get_auto_hf_objects(pretrained_model_name, \n",
    "                                                                                    task=task, \n",
    "                                                                                    config=config)\n",
    "hf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "blocks = (\n",
    "    HF_TextBlock(hf_arch, hf_tokenizer, task=ForTokenClassificationTask(), max_seq_len=128),\n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('tokens'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Band', 'O'), ('1', 'O'), (':', 'O'), ('November', 'O'), ('1918', 'O'), ('-', 'O'), ('November', 'O'), ('1923', 'O'), ('P', 'B-ORG'), ('Verlag', 'I-ORG'), (',', 'O'), ('Landau', 'B-LOC'), ('1992', 'O'), (',', 'O'), ('ISBN', 'O'), ('3', 'O'), ('*', 'O'), ('Gerhard', 'B-PER'), ('G', 'I-PER'), (',', 'O'), ('Matthias', 'B-PER'), ('Spin', 'I-PER'), (':', 'O'), ('Die', 'B-OTH'), ('Pfalz', 'I-OTH'), (':', 'I-OTH'), ('Volk', 'I-OTH'), ('Zo', 'I-OTH'), ('und', 'I-OTH'), ('Staat', 'I-OTH'), ('im', 'I-OTH'), ('be', 'I-OTH'), ('Kampf', 'I-OTH'), ('gegen', 'I-OTH'), ('den', 'I-OTH'), ('p', 'I-OTH'), ('Sep', 'I-OTH'), ('1923', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Sc', 'O'), ('ge', 'O'), ('Jack', 'O'), ('in', 'O'), ('Schwarz', 'O'), ('zu', 'O'), ('Reiter', 'O'), ('und', 'O'), ('hoch', 'O'), ('St', 'O'), (',', 'O'), ('Pel', 'O'), ('mit', 'O'), ('Fell', 'O'), ('zu', 'O'), ('fl', 'O'), ('Marlene', 'O'), ('und', 'O'), ('super', 'O'), ('St', 'O'), ('mit', 'O'), ('hohe', 'O'), ('Fell', 'O'), ('erg', 'O'), ('den', 'O'), ('Look', 'O'), ('einer', 'O'), ('selbst', 'O'), ('s', 'O'), ('Lady', 'O'), ('.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(hf_tokenizer=hf_tokenizer, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                metrics=[accuracy],\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([4, 128, 25]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([4, 128]), 4, torch.Size([4, 128]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0][0].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 25]) torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.002754228748381138, lr_steep=2.0892961401841603e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.072441</td>\n",
       "      <td>0.075325</td>\n",
       "      <td>0.143746</td>\n",
       "      <td>11:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.041070</td>\n",
       "      <td>0.072799</td>\n",
       "      <td>0.144196</td>\n",
       "      <td>11:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.029287</td>\n",
       "      <td>0.066592</td>\n",
       "      <td>0.144572</td>\n",
       "      <td>11:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max= 3e-5, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_TokenClassInput, y:HF_TokenTensorCategory, samples, outs, hf_tokenizer, skip_special_tokens=True,\n",
    "                 ctxs=None, max_n=6, **kwargs):        \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x[0], y, samples, outs):\n",
    "        inp_trg_preds = [ (hf_tokenizer.ids_to_tokens[tok_id.item()], lbl_id.item(), pred_lbl) \n",
    "                         for tok_id, lbl_id, pred_lbl in zip(inp, trg, ast.literal_eval(pred[0])) \n",
    "                         if (tok_id not in hf_tokenizer.all_special_ids) and lbl_id != -100 ]\n",
    "        \n",
    "        res.append(f'{[ (itp[0], lbl, itp[2]) for itp, lbl in zip(inp_trg_preds, ast.literal_eval(sample[1])) ]}')\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Technik', 'B-OTH', 'O'), ('der', 'I-OTH', 'I-OTH'), ('Se', 'I-OTH', 'I-OTH'), ('bei', 'I-OTH', 'I-OTH'), ('der', 'I-OTH', 'I-OTH'), ('Lösung', 'I-OTH', 'I-OTH'), ('pers', 'I-OTH', 'I-OTH'), ('Probleme', 'I-OTH', 'I-OTH'), ('.', 'O', 'O'), (',', 'O', 'O'), ('Row', 'B-ORG', 'B-ORG'), (',', 'O', 'O'), ('Rein', 'B-LOC', 'B-LOC'), ('1998', 'O', 'O'), (',', 'O', 'O'), ('ISBN', 'O', 'O'), ('3', 'O', 'O'), ('*', 'O', 'O'), ('Eugene', 'B-PER', 'B-PER'), ('T', 'I-PER', 'I-PER'), ('Gen', 'I-PER', 'I-PER'), (':', 'O', 'O'), ('Dei', 'B-OTH', 'B-OTH'), ('Körper', 'I-OTH', 'I-OTH'), (',', 'I-OTH', 'I-OTH'), ('dei', 'I-OTH', 'I-OTH'), ('Tra', 'I-OTH', 'I-OTH'), (',', 'O', 'O'), ('Müller', 'B-PER', 'B-ORG'), (',', 'O', 'O'), ('Salzburg', 'B-LOC', 'B-LOC'), ('1998', 'O', 'O'), (',', 'O', 'O'), ('ISBN', 'O', 'O'), ('3', 'O', 'O'), ('*', 'O', 'O'), ('Ann', 'B-PER', 'B-PER'), ('Weise', 'I-PER', 'I-PER'), ('Cornell', 'I-PER', 'I-PER'), (':', 'O', 'O'), ('Der', 'B-OTH', 'B-OTH'), ('Stimme', 'I-OTH', 'I-OTH'), ('des', 'I-OTH', 'I-OTH'), ('Körper', 'I-OTH', 'I-OTH'), ('folgen', 'I-OTH', 'I-OTH'), ('.', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Den', 'O', 'O'), ('rich', 'O', 'O'), ('Fl', 'O', 'O'), ('Erde', 'O', 'O'), ('finden', 'O', 'O'), ('als', 'O', 'O'), ('Pos', 'O', 'O'), ('w', 'O', 'O'), (',', 'O', 'O'), ('konser', 'O', 'O'), ('denken', 'O', 'O'), ('aus', 'O', 'O'), ('Luft', 'O', 'O'), ('und', 'O', 'O'), ('Wasser', 'O', 'O'), ('PS', 'O', 'O'), ('und', 'O', 'O'), ('Ku', 'O', 'O'), (':', 'O', 'O'), ('Cor', 'B-OTH', 'B-OTH'), ('C', 'I-OTH', 'I-OTH'), ('Co', 'I-OTH', 'I-OTH'), ('Union', 'B-ORG', 'I-ORG'), ('will', 'O', 'O'), ('45', 'O', 'O'), ('Prozent', 'O', 'O'), ('die', 'O', 'O'), ('Münchner', 'B-LOCderiv', 'B-LOCderiv'), ('wa', 'O', 'O'), ('?', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(hf_tokenizer=hf_tokenizer, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'I-PER', 'O', 'I-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-LOC']\n"
     ]
    }
   ],
   "source": [
    "res = learn.predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def predict_tokens(self:Learner, inp, **kargs):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
    "    get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input\n",
    "    \"\"\"\n",
    "    pred_lbls, pred_lbl_ids, probs = self.predict(inp)\n",
    "    \n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    add_prefix_space = hf_textblock_tfm.add_prefix_space\n",
    "    \n",
    "    # grab the HF_BatchTransform as well\n",
    "    learn_hf_batch_transform = learn.dls.before_batch.hf__batch_transform\n",
    "    \n",
    "    # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "    # return\n",
    "    subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity), add_prefix_space=add_prefix_space))) \n",
    "                           for entity in inp ]\n",
    "    \n",
    "    # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "    # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "    # (e.g., [CLS], [SEP], etc...)\n",
    "    txt_toks = [ sub_toks for entity in inp \n",
    "                for sub_toks in hf_tokenizer.tokenize(entity, add_prefix_space=add_prefix_space) ]\n",
    "    \n",
    "    txt_tok_ids = hf_tokenizer.convert_tokens_to_ids(txt_toks)\n",
    "    \n",
    "    res = hf_tokenizer.prepare_for_model(txt_tok_ids, None, \n",
    "                                         max_length=learn_hf_batch_transform.max_seq_len, \n",
    "                                         pad_to_max_length=True,\n",
    "                                         truncation_strategy=None, \n",
    "                                         return_special_tokens_mask=True)\n",
    "    \n",
    "    special_toks_msk = L(res['special_tokens_mask'])\n",
    "    actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "    # using the indexes to the actual tokens, get that info from the results returned above\n",
    "    pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "    actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "    actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "    actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "    # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "    # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "    offset = 0\n",
    "    raw_trg_idxs = []\n",
    "    for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "        raw_trg_idxs.append(idx+offset)\n",
    "        offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "\n",
    "    return inp, actual_pred_lbls[raw_trg_idxs], actual_pred_lbl_ids[raw_trg_idxs], actual_probs[raw_trg_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.predict_tokens\" class=\"doc_header\"><code>Learner.predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.predict_tokens</code>(**`inp`**, **\\*\\*`kargs`**)\n",
       "\n",
       "Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
       "get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-OTH')]\n"
     ]
    }
   ],
   "source": [
    "res = learn.predict_tokens(txt.split())\n",
    "print([(tok, lbl) for tok,lbl in zip(res[0],res[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-language-modeling.ipynb.\n",
      "Converted 01c_data-question-answering.ipynb.\n",
      "Converted 01d_data-token-classification.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-language-modeling.ipynb.\n",
      "Converted 02c_modeling-question-answering.ipynb.\n",
      "Converted 02d_modeling-token-classification.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
