{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "import torch\n",
    "from transformers import *\n",
    "from fastai2.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag1</th>\n",
       "      <th>tag2</th>\n",
       "      <th>ds_type</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Schartau</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>sagte</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>dem</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tagesspiegel</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos         token   tag1 tag2 ds_type  seq_id  n_tokens\n",
       "0    1      Schartau  B-PER    O   train       1         3\n",
       "1    2         sagte      O    O   train       1         1\n",
       "2    3           dem      O    O   train       1         1\n",
       "3    4             \"      O    O   train       1         1\n",
       "4    5  Tagesspiegel  B-ORG    O   train       1         3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner/germeval2014ner_cleaned.csv')\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv')\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag1</th>\n",
       "      <th>tag2</th>\n",
       "      <th>ds_type</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pos, token, tag1, tag2, ds_type, seq_id, n_tokens]\n",
       "Index: []"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "germ_eval_df.dropna(inplace=True)\n",
    "germ_eval_df[germ_eval_df.token.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGpart', 'B-OTH', 'B-PER', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-ORG', 'I-ORGpart', 'I-OTH', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(germ_eval_df.tag1.unique())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag1</th>\n",
       "      <th>tag2</th>\n",
       "      <th>ds_type</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train]</td>\n",
       "      <td>[3, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train]</td>\n",
       "      <td>[3, 1, 1, 2, 1, 1, 1, 3, 1, 1, 4, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seq_id  \\\n",
       "0       1   \n",
       "1       2   \n",
       "\n",
       "                                                                                           pos  \\\n",
       "0  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]   \n",
       "1              [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]   \n",
       "\n",
       "                                                                                                                                                                   token  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "\n",
       "                                                                                      tag1  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "\n",
       "                                                                          tag2  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                                                                                                                           ds_type  \\\n",
       "0  [train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train]   \n",
       "1                       [train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train]   \n",
       "\n",
       "                                                                      n_tokens  \n",
       "0  [3, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1]  \n",
       "1           [3, 1, 1, 2, 1, 1, 1, 3, 1, 1, 4, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "germ_eval_df = germ_eval_df.groupby(by='seq_id').agg(list).reset_index()\n",
    "germ_eval_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting rid of troublesom NaNs and getting my labels, the code above converts my input datafame into something I can model by making the token and tag1 columns represent a list of tokens (or labels) for a give sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.ForTokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.tokenization_bert.BertTokenizer,\n",
       " transformers.configuration_bert.BertConfig,\n",
       " transformers.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_tokenizer, hf_config, hf_model = BLURR_MODEL_HELPER.get_auto_hf_objects(pretrained_model_name, \n",
    "                                                                                    task=task, \n",
    "                                                                                    config=config)\n",
    "hf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "blocks = (\n",
    "    HF_TextBlock.from_df(text_cols_lists=[['token']], \n",
    "                         hf_arch=hf_arch, \n",
    "                         hf_tokenizer=hf_tokenizer, \n",
    "                         tok_func_mode='list', \n",
    "                         task=ForTokenClassificationTask(), max_seq_len=128),\n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.token, inp.tag1) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=lambda x: x.text0,\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Das SS - Freiwilligen - Grenadier - Regiment 88 wurde im März aus einer Kampfgruppe der SS - Führerschule des Wirtschafts - und Verwaltungsdienstes und Teilen des I. / SS - Polizei - Regiments 34 der Ordnungspolizei, Heeresangehörigen und Volkssturm gebildet.</td>\n",
       "      <td>['O', 'B-ORGpart', 'I-ORGpart', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORGpart', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORGpart', 'I-ORGpart', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ausbildung In der Bundesrepublik Deutschland können die Befähigungszeugnisse „ Kapitän BK ( Kleine Hochseefischerei ) und „ Kapitän BG ( Große Hochseefischerei ) im Rahmen einer bundeseinheitlichen Regelung erworben werden.</td>\n",
       "      <td>['O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(hf_tokenizer=hf_tokenizer, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, \n",
    "                hf_model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                metrics=[accuracy],\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([4, 128, 15]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(*b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([4, 128]), 4, torch.Size([4, 128]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0][0].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 15]) torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.0006309573538601399, lr_steep=1.737800812406931e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.588395</td>\n",
       "      <td>0.583252</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.976230</td>\n",
       "      <td>0.569537</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.718055</td>\n",
       "      <td>0.555735</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max= 3e-5, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_BaseInput, y:HF_TokenTensorCategory, samples, outs, hf_tokenizer, skip_special_tokens=True, \n",
    "                 ctxs=None, max_n=6, **kwargs):        \n",
    "    \n",
    "    if ctxs is None: ctxs = get_empty_df(min(len(samples), max_n))\n",
    "        \n",
    "    samples = samples = L((TitledStr(hf_tokenizer.decode(inp, skip_special_tokens=skip_special_tokens).replace(hf_tokenizer.pad_token, '')), *s[1:]) \n",
    "                          for inp, s in zip(x[0], samples))\n",
    "    \n",
    "    ctxs = show_batch[object](x, y, samples, max_n=max_n, ctxs=ctxs, **kwargs)\n",
    "    for i,ctx in enumerate(ctxs): \n",
    "        preds = ast.literal_eval(outs[i][0])\n",
    "        ctx['target'] = [pred for idx, pred in enumerate(preds) if (y[i][idx] != -100)]\n",
    "        \n",
    "    display_df(pd.DataFrame(ctxs))\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scenes of a Sexual Nature ( GB 2006 ) - Regie : Ed Blum Shortbus ( USA 2006 ) - Regie : John Cameron Mitchell : Film über den gleichnamigen New Yorker Club, der verschiedensten Paaren eine Plattform zur Aufarbeitung ihrer Probleme bietet.</td>\n",
       "      <td>['B-OTH', 'I-OTH', 'I-OTH', 'I-OTH', 'I-OTH', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'B-OTH', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-LOCderiv', 'I-LOCderiv', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neben einem 4 - in - 1 Kartenleser und Bluetooth 2. 0 hat Medion einen 8 - fach DVD - und CD - Brenner eingebaut, der auch Double - Layer - Medien unterstützt.</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Im Herbst 1945 erfolgte seine Berufung an die Universität Jena zum ordentlichen Professor auf den Lehrstuhl für Acker - und Pflanzenbau und die Ernennung zum Direktor des Instituts für Pflanzenbau und Pflanzenzucht.</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O']</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" Es wird also nicht einfach \", meint \" ManU \" - Teammanager Sir Alex Ferguson : \" Aber wir sind es gewohnt, die Ersten zu sein und müssen gewinnen.</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(hf_tokenizer=hf_tokenizer, max_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "res = learn.predict('My name is Wayde and I live in San Diego')\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def predict_tokens(self:Learner, inp, **kargs):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
    "    get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input\n",
    "    \"\"\"\n",
    "    pred_lbls, pred_lbl_ids, probs = self.predict(inp)\n",
    "    \n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    learn_hf_tokenizer = self.dls.tfms[0].tokenizer.filter(lambda tok: isinstance(tok, HF_Tokenizer))[0]\n",
    "    hf_tokenizer = learn_hf_tokenizer.hf_tokenizer\n",
    "    add_prefix_space = learn_hf_tokenizer.hf_arch in ['gpt2', 'roberta']\n",
    "    \n",
    "    # grab the HF_BatchTransform as well\n",
    "    learn_hf_batch_transform = learn.dls.before_batch.hf__batch_transform\n",
    "    \n",
    "    # convert the `inp` to a list if necessary\n",
    "    txt_split = inp if isinstance(inp, list) else learn_hf_tokenizer.list_split_func(inp) \n",
    "\n",
    "    # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "    # return\n",
    "    subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity), add_prefix_space=add_prefix_space))) \n",
    "                           for entity in txt_split ]\n",
    "    \n",
    "    # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "    # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "    # (e.g., [CLS], [SEP], etc...)\n",
    "    txt_toks = [ sub_toks for entity in txt_split \n",
    "                for sub_toks in hf_tokenizer.tokenize(entity, add_prefix_space=add_prefix_space) ]\n",
    "    \n",
    "    txt_tok_ids = hf_tokenizer.convert_tokens_to_ids(txt_toks)\n",
    "    \n",
    "    res = hf_tokenizer.prepare_for_model(txt_tok_ids, None, \n",
    "                                         max_length=learn_hf_batch_transform.max_seq_len, \n",
    "                                         pad_to_max_length=True,\n",
    "                                         truncation_strategy=None, \n",
    "                                         return_special_tokens_mask=True)\n",
    "    \n",
    "    special_toks_msk = L(res['special_tokens_mask'])\n",
    "    actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "    # using the indexes to the actual tokens, get that info from the results returned above\n",
    "    pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "    actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "    actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "    actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "    # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "    # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "    offset = 0\n",
    "    raw_trg_idxs = []\n",
    "    for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "        raw_trg_idxs.append(idx+offset)\n",
    "        offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "\n",
    "    return txt_split, actual_pred_lbls[raw_trg_idxs], actual_pred_lbl_ids[raw_trg_idxs], actual_probs[raw_trg_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.predict_tokens\" class=\"doc_header\"><code>Learner.predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.predict_tokens</code>(**`inp`**, **\\*\\*`kargs`**)\n",
       "\n",
       "Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
       "get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'O'), ('Gilliam', 'O'), ('from', 'O'), ('ohmeow.com.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "res = learn.predict_tokens(txt)\n",
    "print([(tok, lbl) for tok,lbl in zip(res[0],res[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-language-modeling.ipynb.\n",
      "Converted 01c_data-question-answering.ipynb.\n",
      "Converted 01d_data-token-classification.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-language-modeling.ipynb.\n",
      "Converted 02c_modeling-question-answering.ipynb.\n",
      "Converted 02d_modeling-token-classification.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
