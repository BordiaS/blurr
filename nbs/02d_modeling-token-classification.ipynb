{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai2.text.all import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>nested-labels</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>welt.de vom 29.10.2005 [2005-10-29]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stern.de vom 21.03.2006 [2006-03-21]</td>\n",
       "      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>\n",
       "      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>\n",
       "      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                        source  \\\n",
       "0                                                                                                                                                         n-tv.de vom 26.02.2005 [2005-02-26]    \n",
       "1                                                                                                                                                         welt.de vom 29.10.2005 [2005-10-29]    \n",
       "2  http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&utm_medium=rss-feed&utm_campaign=sport [2010-03-25]    \n",
       "3                                                                                                                                                        stern.de vom 21.03.2006 [2006-03-21]    \n",
       "4                                                                         http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]    \n",
       "\n",
       "                                                                                                                                                                  tokens  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "2   [Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]   \n",
       "3                                                  [Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]   \n",
       "4                                                                  [Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]   \n",
       "\n",
       "                                                                                    labels  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "2             [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                              [B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]   \n",
       "4                                               [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                 nested-labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  \n",
       "2   train  \n",
       "3   train  \n",
       "4   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensures these cols are represented as lists (rather than string)\n",
    "df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval, 'nested-labels': ast.literal_eval}\n",
    "\n",
    "# full nlp dataset\n",
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner_cleaned.csv', converters=df_converters)\n",
    "\n",
    "# demo nlp dataset\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv', converters=df_converters)\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-ORG', 'I-ORGpart', 'I-OTH', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.configuration_bert.BertConfig,\n",
       " transformers.tokenization_bert.BertTokenizer,\n",
       " transformers.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_batch_tfm = HF_TokenClassBatchTransform(hf_arch, hf_tokenizer)\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(hf_arch, hf_tokenizer, hf_batch_tfm=hf_batch_tfm, max_length=128, is_pretokenized=True,\n",
    "                 tok_kwargs={ 'return_special_tokens_mask': True }), \n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('tokens'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Mit', 'O'), ('Einführung', 'O'), ('eines', 'O'), ('Fl', 'O'), ('auf', 'O'), ('Basis', 'O'), ('der', 'O'), ('Arbeiten', 'O'), ('von', 'O'), ('Johann', 'B-PER'), ('Georg', 'I-PER'), ('Otto', 'I-PER'), ('Sc', 'I-PER'), ('hat', 'O'), ('die', 'O'), ('Bundeswehr', 'B-ORG'), ('1990', 'O'), ('ein', 'O'), ('Tarn', 'O'), ('eingeführt', 'O'), (',', 'O'), ('das', 'O'), ('heute', 'O'), ('weit', 'O'), ('Verbreitung', 'O'), ('gefunden', 'O'), ('hat', 'O'), ('.', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Neben', 'O'), ('der', 'O'), ('guten', 'O'), ('„', 'O'), ('International', 'B-ORG'), ('Music', 'I-ORG'), ('Band', 'I-ORG'), ('sorgte', 'O'), ('auch', 'O'), ('eine', 'O'), ('Bar', 'O'), ('für', 'O'), ('gute', 'O'), ('Lau', 'O'), ('.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(hf_tokenizer=hf_tokenizer, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval import metrics as seq_metrics\n",
    "\n",
    "class HF_TokenClassMetricsCallback(Callback):\n",
    "    \"\"\"A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the\n",
    "    `seqeval` library.  Additionally, this metric knows how to *not* include your 'ignore_token' in it's\n",
    "    calculations.\n",
    "    \n",
    "    See [here](https://github.com/chakki-works/seqeval) for more information on `seqeval`.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        if (not self.do_setup): return    \n",
    "\n",
    "        # one time setup code here.\n",
    "        self.hf_tokenizer = self.dls.tfms[0].hf_tokenizer\n",
    "        self.ignore_label_token_id = self.dls.tfms[1].ignore_token_id\n",
    "        self.tok_special_symbols = list(self.hf_tokenizer.special_tokens_map.values())\n",
    "        \n",
    "        self.results = []\n",
    "        self.seq_accuracy, self.seq_precision, self.seq_recall, self.seq_f1 = 0.,0.,0.,0.\n",
    "        \n",
    "        seq_metrics = L(ValueMetric(self.seq_accuracy_value, 'accuracy'), \n",
    "                        ValueMetric(self.seq_precision_value, 'precision'),\n",
    "                        ValueMetric(self.seq_recall_value, 'recall'),\n",
    "                        ValueMetric(self.seq_f1_value, 'f1'))\n",
    "        \n",
    "        self.learn.metrics = self.learn.metrics + seq_metrics\n",
    "        self.do_setup = False\n",
    "        \n",
    "    # these HAVE to be functions\n",
    "    def seq_accuracy_value(self): return self.seq_accuracy\n",
    "    def seq_precision_value(self): return self.seq_precision\n",
    "    def seq_recall_value(self): return self.seq_recall\n",
    "    def seq_f1_value(self): return self.seq_f1\n",
    "    \n",
    "    # ----callbacks ----\n",
    "    def begin_fit(self): self.setup()\n",
    "    def begin_epoch(self): self.results = []\n",
    "    \n",
    "    def after_batch(self):\n",
    "        if (self.model.training): return\n",
    "        \n",
    "        # do this only for validation set\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0] # yb is TensorText tuple, item 0 is the data\n",
    "        \n",
    "        preds_list, targets_list = [], []   \n",
    "        for i in range(targs.shape[0]):\n",
    "            item_targs, item_preds = [], []\n",
    "            \n",
    "            for j in range(targs.shape[1]):\n",
    "                if (targs[i, j] != self.ignore_label_token_id):\n",
    "                    item_preds.append(self.dls.vocab[preds[i][j].item()])\n",
    "                    item_targs.append(self.dls.vocab[targs[i][j].item()])\n",
    "                    \n",
    "            preds_list.append(item_preds)\n",
    "            targets_list.append(item_targs)\n",
    "            \n",
    "        self.results += [ (res[0], res[1]) for res in zip(preds_list, targets_list) ]\n",
    "        \n",
    "    def after_validate(self):\n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        \n",
    "        accuracy = seq_metrics.accuracy_score(targs, preds)\n",
    "        precision = seq_metrics.precision_score(targs, preds)\n",
    "        recall = seq_metrics.recall_score(targs, preds)\n",
    "        f1 = seq_metrics.f1_score(targs, preds)\n",
    "        \n",
    "        self.seq_accuracy, self.seq_precision, self.seq_recall, self.seq_f1 = accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([4, 128, 18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([4, 128]), 4, torch.Size([4, 128]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 18]) torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.002754228748381138, lr_steep=1.737800812406931e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.300333</td>\n",
       "      <td>0.255811</td>\n",
       "      <td>0.936028</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>0.450549</td>\n",
       "      <td>0.509317</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.133578</td>\n",
       "      <td>0.156507</td>\n",
       "      <td>0.959315</td>\n",
       "      <td>0.654485</td>\n",
       "      <td>0.721612</td>\n",
       "      <td>0.686411</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.072386</td>\n",
       "      <td>0.151491</td>\n",
       "      <td>0.960118</td>\n",
       "      <td>0.667785</td>\n",
       "      <td>0.728938</td>\n",
       "      <td>0.697023</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max= 3e-5, moms=(0.8,0.7,0.8), cbs=[HF_TokenClassMetricsCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_TokenClassInput, y:HF_TokenTensorCategory, samples, outs, hf_tokenizer, \n",
    "                 ctxs=None, max_n=6, **kwargs):        \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x[0], y, samples, outs):\n",
    "        inp_trg_preds = [ (hf_tokenizer.ids_to_tokens[tok_id.item()], lbl_id.item(), pred_lbl) \n",
    "                         for tok_id, lbl_id, pred_lbl in zip(inp, trg, ast.literal_eval(pred[0])) \n",
    "                         if (tok_id not in hf_tokenizer.all_special_ids) and lbl_id != -100 ]\n",
    "        \n",
    "        res.append([f'{[ (itp[0], lbl, itp[2]) for itp, lbl in zip(inp_trg_preds, ast.literal_eval(sample[1])) ]}'])\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Die', 'O', 'O'), ('ps', 'O', 'O'), ('Abteilung', 'O', 'O'), ('umfasst', 'O', 'O'), ('drei', 'O', 'O'), ('Stationen', 'O', 'O'), ('und', 'O', 'O'), ('eine', 'O', 'O'), ('Tages', 'O', 'O'), ('mit', 'O', 'O'), ('insgesamt', 'O', 'O'), ('240', 'O', 'O'), ('Bet', 'O', 'O'), ('.', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Ein', 'O', 'O'), ('eigenständige', 'O', 'O'), ('Ta', 'O', 'O'), ('ohne', 'O', 'O'), ('Lo', 'O', 'O'), ('und', 'O', 'O'), ('Arbeit', 'O', 'O'), ('macht', 'O', 'O'), ('jedoch', 'O', 'O'), ('keinen', 'O', 'O'), ('Sinn', 'O', 'O'), ('.', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(hf_tokenizer=hf_tokenizer, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC']\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict_tokens(self:Learner, inp, **kargs):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
    "    get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input\n",
    "    \"\"\"\n",
    "    pred_lbls, pred_lbl_ids, probs = self.blurr_predict(inp)\n",
    "\n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_textblock_tfm.tok_kwargs\n",
    "    \n",
    "    # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "    # return\n",
    "    subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity)))) for entity in inp ]\n",
    "    \n",
    "    # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "    # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "    # (e.g., [CLS], [SEP], etc...)\n",
    "    res = hf_tokenizer(inp, None, \n",
    "                       max_length=hf_textblock_tfm.max_length,\n",
    "                       padding=hf_textblock_tfm.padding,\n",
    "                       truncation=hf_textblock_tfm.truncation,\n",
    "                       is_pretokenized=hf_textblock_tfm.is_pretokenized,\n",
    "                       **tok_kwargs)\n",
    "\n",
    "    special_toks_msk = L(res['special_tokens_mask'])\n",
    "    actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "    # using the indexes to the actual tokens, get that info from the results returned above\n",
    "    pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "    actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "    actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "    actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "    # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "    # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "    offset = 0\n",
    "    raw_trg_idxs = []\n",
    "    for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "        raw_trg_idxs.append(idx+offset)\n",
    "        offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "\n",
    "    return inp, actual_pred_lbls[raw_trg_idxs], actual_pred_lbl_ids[raw_trg_idxs], actual_probs[raw_trg_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict_tokens\" class=\"doc_header\"><code>Learner.blurr_predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict_tokens</code>(**`inp`**, **\\*\\*`kargs`**)\n",
       "\n",
       "Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
       "get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "print([(tok, lbl) for tok,lbl in zip(res[0],res[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-language-modeling.ipynb.\n",
      "Converted 01c_data-question-answering.ipynb.\n",
      "Converted 01d_data-token-classification.ipynb.\n",
      "Converted 01e_data-text-generation.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02_training-summarization.ipynb.\n",
      "Converted 02a_modeling-language-modeling.ipynb.\n",
      "Converted 02c_modeling-question-answering.ipynb.\n",
      "Converted 02d_modeling-token-classification.ipynb.\n",
      "Converted 02e_modeling-text-generation.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
