{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai2.text.all import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from seqeval import metrics as seq_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>nested-labels</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>welt.de vom 29.10.2005 [2005-10-29]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stern.de vom 21.03.2006 [2006-03-21]</td>\n",
       "      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>\n",
       "      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>\n",
       "      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                        source  \\\n",
       "0                                                                                                                                                         n-tv.de vom 26.02.2005 [2005-02-26]    \n",
       "1                                                                                                                                                         welt.de vom 29.10.2005 [2005-10-29]    \n",
       "2  http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&utm_medium=rss-feed&utm_campaign=sport [2010-03-25]    \n",
       "3                                                                                                                                                        stern.de vom 21.03.2006 [2006-03-21]    \n",
       "4                                                                         http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]    \n",
       "\n",
       "                                                                                                                                                                  tokens  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "2   [Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]   \n",
       "3                                                  [Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]   \n",
       "4                                                                  [Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]   \n",
       "\n",
       "                                                                                    labels  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "2             [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                              [B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]   \n",
       "4                                               [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                 nested-labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  \n",
       "2   train  \n",
       "3   train  \n",
       "4   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensures these cols are represented as lists (rather than string)\n",
    "df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval, 'nested-labels': ast.literal_eval}\n",
    "\n",
    "# full nlp dataset\n",
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner_cleaned.csv', converters=df_converters)\n",
    "\n",
    "# demo nlp dataset\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv', converters=df_converters)\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-ORG', 'I-ORGpart', 'I-OTH', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.configuration_bert.BertConfig,\n",
       " transformers.tokenization_bert.BertTokenizer,\n",
       " transformers.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_batch_tfm = HF_TokenClassBatchTransform(hf_arch, hf_tokenizer)\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(hf_arch, hf_tokenizer, hf_batch_tfm=hf_batch_tfm, max_length=128, is_pretokenized=True,\n",
    "                 tok_kwargs={ 'return_special_tokens_mask': True }), \n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('tokens'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('He', 'B-OTH'), ('et', 'I-OTH'), ('al', 'I-OTH'), ('.', 'O'), ('(', 'O'), ('1994', 'O'), (')', 'O'), ('S', 'O'), ('593', 'O'), ('Win', 'B-OTH'), ('&amp;', 'I-OTH'), ('Sei', 'I-OTH'), ('et', 'I-OTH'), ('al', 'I-OTH'), ('.', 'O'), ('(', 'O'), ('1998', 'O'), (')', 'O'), ('S', 'O'), ('32', 'O'), ('In', 'O'), ('noch', 'O'), ('andere', 'O'), ('Falk', 'O'), (',', 'O'), ('wie', 'O'), ('der', 'O'), ('Afrikan', 'B-LOCderiv'), ('Baum', 'O'), ('(', 'O'), ('Falco', 'O'), ('cu', 'O'), (')', 'O'), ('oder', 'O'), ('der', 'O'), ('Mala', 'O'), ('(', 'O'), ('Falco', 'O'), ('server', 'O'), (')', 'O'), ('dieser', 'O'), ('Gruppe', 'O'), ('zu', 'O'), ('sind', 'O'), (',', 'O'), ('ist', 'O'), ('Gegen', 'O'), ('der', 'O'), ('Forschung', 'O'), ('.', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Bus', 'B-PER'), ('weiß', 'O'), (':', 'O'), ('Das', 'O'), ('wird', 'O'), ('der', 'O'), ('Tech', 'O'), ('Del', 'O'), ('genau', 'O'), ('kontroll', 'O'), ('.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for token classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_token_class_metrics(pred_toks, targ_toks, metric_key):\n",
    "    if (metric_key == 'accuracy'): return seq_metrics.accuracy_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'precision'): return seq_metrics.precision_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'recall'): return seq_metrics.recall_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'f1'): return seq_metrics.f1_score(targ_toks, pred_toks)\n",
    "        \n",
    "    if (metric_key == 'classification_report'): return seq_metrics.classification_report(targ_toks, pred_toks)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_TokenClassCallback(HF_BaseModelCallback):\n",
    "    \"\"\"A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the\n",
    "    `seqeval` library.  Additionally, this metric knows how to *not* include your 'ignore_token' in it's\n",
    "    calculations.\n",
    "    \n",
    "    See [here](https://github.com/chakki-works/seqeval) for more information on `seqeval`.\n",
    "    \"\"\"\n",
    "    def __init__(self, tok_metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self, 'tok_metrics, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in tok_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the target's HF_TokenizerTransform (used for rouge metrics)\n",
    "        hf_textblock_tfm = self.dls.tfms[0]\n",
    "        self.hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "        self.ignore_label_token_id = self.dls.tfms[1].ignore_token_id\n",
    "        self.tok_special_symbols = list(self.hf_tokenizer.special_tokens_map.values())\n",
    "        self.tok_kwargs = hf_textblock_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        self.learn.token_classification_report = None\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def begin_fit(self): self.setup()\n",
    "    \n",
    "    \n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # do this only for validation set\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0] # yb is TensorText tuple, item 0 is the data\n",
    "        \n",
    "        preds_list, targets_list = [], []   \n",
    "        for i in range(targs.shape[0]):\n",
    "            item_targs, item_preds = [], []\n",
    "            \n",
    "            for j in range(targs.shape[1]):\n",
    "                if (targs[i, j] != self.ignore_label_token_id):\n",
    "                    item_preds.append(self.dls.vocab[preds[i][j].item()])\n",
    "                    item_targs.append(self.dls.vocab[targs[i][j].item()])\n",
    "                    \n",
    "            preds_list.append(item_preds)\n",
    "            targets_list.append(item_targs)\n",
    "            \n",
    "        self.results += [ (res[0], res[1]) for res in zip(preds_list, targets_list) ]\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def begin_validate(self): self.results = []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        if (len(self.results) < 1): return\n",
    "        \n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        for k in self.custom_metrics_dict.keys(): \n",
    "            self.custom_metrics_dict[k] = calculate_token_class_metrics(targs, preds, metric_key=k)\n",
    "        \n",
    "        self.learn.token_classification_report = calculate_token_class_metrics(targs, preds, 'classification_report')\n",
    "        \n",
    "        \n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                cbs=[HF_TokenClassCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([4, 128, 18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([4, 128]), 4, torch.Size([4, 128]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 18]) torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.0005248074419796466, lr_steep=1.4454397387453355e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.321524</td>\n",
       "      <td>0.170603</td>\n",
       "      <td>0.956020</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.534521</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.113167</td>\n",
       "      <td>0.118488</td>\n",
       "      <td>0.973988</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.721030</td>\n",
       "      <td>0.719486</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.062206</td>\n",
       "      <td>0.102343</td>\n",
       "      <td>0.975329</td>\n",
       "      <td>0.747863</td>\n",
       "      <td>0.723140</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max= 3e-5, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      PER       0.92      0.92      0.92        79\n",
      "      LOC       0.82      0.67      0.74        67\n",
      "      ORG       0.72      0.56      0.63        52\n",
      "      OTH       0.64      0.61      0.62        23\n",
      " LOCderiv       0.70      0.67      0.68        21\n",
      "\n",
      "micro avg       0.75      0.72      0.74       242\n",
      "macro avg       0.81      0.72      0.76       242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_TokenClassInput, y:HF_TokenTensorCategory, samples, outs, learner=None, \n",
    "                 ctxs=None, max_n=6, **kwargs):    \n",
    "    # grab tokenizer\n",
    "    hf_textblock_tfm = learner.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x[0], y, samples, outs):\n",
    "        inp_trg_preds = [ (hf_tokenizer.ids_to_tokens[tok_id.item()], lbl_id.item(), pred_lbl) \n",
    "                         for tok_id, lbl_id, pred_lbl in zip(inp, trg, ast.literal_eval(pred[0])) \n",
    "                         if (tok_id not in hf_tokenizer.all_special_ids) and lbl_id != -100 ]\n",
    "        \n",
    "        res.append([f'{[ (itp[0], lbl, itp[2]) for itp, lbl in zip(inp_trg_preds, ast.literal_eval(sample[1])) ]}'])\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Das', 'O', 'O'), ('SE', 'B-ORG', 'B-ORG'), ('r', 'O', 'O'), ('an', 'O', 'O'), (',', 'O', 'O'), ('st', 'O', 'O'), ('die', 'O', 'O'), ('Wohnung', 'O', 'O'), ('ge', 'O', 'O'), ('Mitt', 'O', 'O'), ('um', 'O', 'O'), ('12', 'O', 'O'), ('Uhr', 'O', 'O'), ('.', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Deshalb', 'O', 'O'), ('zeigen', 'O', 'O'), ('viele', 'O', 'O'), ('System', 'O', 'O'), ('dann', 'O', 'O'), ('auch', 'O', 'O'), ('fa', 'O', 'O'), ('Werte', 'O', 'O'), ('an', 'O', 'O'), ('.', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC']\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict_tokens(self:Learner, inp, **kargs):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
    "    get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input\n",
    "    \"\"\"\n",
    "    pred_lbls, pred_lbl_ids, probs = self.blurr_predict(inp)\n",
    "\n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_textblock_tfm.kwargs\n",
    "    \n",
    "    # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "    # return\n",
    "    subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity)))) for entity in inp ]\n",
    "    \n",
    "    # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "    # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "    # (e.g., [CLS], [SEP], etc...)\n",
    "    res = hf_tokenizer(inp, None, \n",
    "                       max_length=hf_textblock_tfm.max_length,\n",
    "                       padding=hf_textblock_tfm.padding,\n",
    "                       truncation=hf_textblock_tfm.truncation,\n",
    "                       is_pretokenized=hf_textblock_tfm.is_pretokenized,\n",
    "                       **tok_kwargs)\n",
    "\n",
    "    special_toks_msk = L(res['special_tokens_mask'])\n",
    "    actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "    # using the indexes to the actual tokens, get that info from the results returned above\n",
    "    pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "    actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "    actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "    actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "    # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "    # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "    offset = 0\n",
    "    raw_trg_idxs = []\n",
    "    for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "        raw_trg_idxs.append(idx+offset)\n",
    "        offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "\n",
    "    return inp, actual_pred_lbls[raw_trg_idxs], actual_pred_lbl_ids[raw_trg_idxs], actual_probs[raw_trg_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict_tokens\" class=\"doc_header\"><code>Learner.blurr_predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict_tokens</code>(**`inp`**, **\\*\\*`kargs`**)\n",
       "\n",
       "Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
       "get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "print([(tok, lbl) for tok,lbl in zip(res[0],res[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-language-modeling.ipynb.\n",
      "Converted 01c_data-question-answering.ipynb.\n",
      "Converted 01d_data-token-classification.ipynb.\n",
      "Converted 01e_data-summarization.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-language-modeling.ipynb.\n",
      "Converted 02c_modeling-question-answering.ipynb.\n",
      "Converted 02d_modeling-token-classification.ipynb.\n",
      "Converted 02e_modeling-text-generation.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
