{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai2.text.all import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591005\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag1</th>\n",
       "      <th>tag2</th>\n",
       "      <th>ds_type</th>\n",
       "      <th>seq_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Schartau</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>sagte</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>dem</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tagesspiegel</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos         token   tag1 tag2 ds_type  seq_id\n",
       "0    1      Schartau  B-PER    O   train       1\n",
       "1    2         sagte      O    O   train       1\n",
       "2    3           dem      O    O   train       1\n",
       "3    4             \"      O    O   train       1\n",
       "4    5  Tagesspiegel  B-ORG    O   train       1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner/germeval2014ner_cleaned.csv')\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv')\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag1</th>\n",
       "      <th>tag2</th>\n",
       "      <th>ds_type</th>\n",
       "      <th>seq_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pos, token, tag1, tag2, ds_type, seq_id]\n",
       "Index: []"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "germ_eval_df.dropna(inplace=True)\n",
    "germ_eval_df[germ_eval_df.token.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGderiv', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-LOCpart', 'I-ORG', 'I-ORGderiv', 'I-ORGpart', 'I-OTH', 'I-OTHderiv', 'I-OTHpart', 'I-PER', 'I-PERderiv', 'I-PERpart', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(germ_eval_df.tag1.unique())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>tag1</th>\n",
       "      <th>tag2</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seq_id  \\\n",
       "0       1   \n",
       "1       2   \n",
       "\n",
       "                                                                                           pos  \\\n",
       "0  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]   \n",
       "1              [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]   \n",
       "\n",
       "                                                                                                                                                                   token  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "\n",
       "                                                                                      tag1  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "\n",
       "                                                                          tag2  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                                                                                                                           ds_type  \n",
       "0  [train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train]  \n",
       "1                       [train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train, train]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "germ_eval_df = germ_eval_df.groupby(by='seq_id').agg(list).reset_index()\n",
    "germ_eval_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting rid of troublesom NaNs and getting my labels, the code above converts my input datafame into something I can model by making the token and tag1 columns represent a list of tokens (or labels) for a give sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.ForTokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.tokenization_bert.BertTokenizer,\n",
       " transformers.configuration_bert.BertConfig,\n",
       " transformers.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_tokenizer, hf_config, hf_model = BLURR_MODEL_HELPER.get_auto_hf_objects(pretrained_model_name, \n",
    "                                                                                    task=task, \n",
    "                                                                                    config=config)\n",
    "hf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "blocks = (\n",
    "    HF_TextBlock(hf_arch, hf_tokenizer, task=ForTokenClassificationTask(), max_seq_len=128),\n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.token, inp.tag1) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('token'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Band', 'O'), ('1', 'O'), (':', 'O'), ('November', 'O'), ('1918', 'O'), ('-', 'O'), ('November', 'O'), ('1923', 'O'), ('P', 'B-ORG'), ('Verlag', 'I-ORG'), (',', 'O'), ('Landau', 'B-LOC'), ('1992', 'O'), (',', 'O'), ('ISBN', 'O'), ('3', 'O'), ('*', 'O'), ('Gerhard', 'B-PER'), ('G', 'I-PER'), (',', 'O'), ('Matthias', 'B-PER'), ('Spin', 'I-PER'), (':', 'O'), ('Die', 'B-OTH'), ('Pfalz', 'I-OTH'), (':', 'I-OTH'), ('Volk', 'I-OTH'), ('Zo', 'I-OTH'), ('und', 'I-OTH'), ('Staat', 'I-OTH'), ('im', 'I-OTH'), ('be', 'I-OTH'), ('Kampf', 'I-OTH'), ('gegen', 'I-OTH'), ('den', 'I-OTH'), ('p', 'I-OTH'), ('Sep', 'I-OTH'), ('1923', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Die', 'O'), ('bekannten', 'O'), ('Herrscher', 'O'), ('Ar', 'B-LOC'), ('*', 'O'), ('Kuba', 'B-PER'), (',', 'O'), ('um', 'O'), ('1400', 'O'), ('*', 'O'), ('Ta', 'B-PER'), (',', 'O'), ('um', 'O'), ('1370', 'O'), ('*', 'O'), ('An', 'B-PER'), (',', 'O'), ('um', 'O'), ('1350', 'O'), ('*', 'O'), ('U', 'B-PER'), (',', 'O'), ('bis', 'O'), ('ca', 'O'), ('1316', 'O'), ('Literatur', 'O'), ('*', 'O'), ('H', 'B-PER'), ('C', 'I-PER'), ('Mel', 'I-PER'), ('(', 'O'), ('Hrsg', 'O'), (')', 'O'), (':', 'O'), ('The', 'B-OTH'), ('Lu', 'I-OTH'), ('.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(hf_tokenizer=hf_tokenizer, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                metrics=[accuracy],\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([4, 128, 25]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([4, 128]), 4, torch.Size([4, 128]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0][0].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 25]) torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.002754228748381138, lr_steep=6.30957365501672e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.076996</td>\n",
       "      <td>0.143263</td>\n",
       "      <td>10:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.035977</td>\n",
       "      <td>0.067766</td>\n",
       "      <td>0.143782</td>\n",
       "      <td>10:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.023393</td>\n",
       "      <td>0.062158</td>\n",
       "      <td>0.143962</td>\n",
       "      <td>10:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max= 3e-5, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_TokenClassInput, y:HF_TokenTensorCategory, samples, outs, hf_tokenizer, skip_special_tokens=True,\n",
    "                 ctxs=None, max_n=6, **kwargs):        \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x[0], y, samples, outs):\n",
    "        inp_trg_preds = [ (hf_tokenizer.ids_to_tokens[tok_id.item()], lbl_id.item(), pred_lbl) \n",
    "                         for tok_id, lbl_id, pred_lbl in zip(inp, trg, ast.literal_eval(pred[0])) \n",
    "                         if (tok_id not in hf_tokenizer.all_special_ids) and lbl_id != -100 ]\n",
    "        \n",
    "        res.append(f'{[ (itp[0], lbl, itp[2]) for itp, lbl in zip(inp_trg_preds, ast.literal_eval(sample[1])) ]}')\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('NEWS', 'B-OTH', 'B-OTH'), ('/', 'O', 'O'), (':', 'O', 'O'), ('Пол', 'B-OTH', 'O'), ('С', 'I-OTH', 'O'), ('от', 'I-OTH', 'O'), ('М', 'I-OTH', 'B-PER'), ('в', 'I-OTH', 'O'), ('отс', 'I-OTH', 'O'), ('Die', 'O', 'O'), ('SP', 'B-ORG', 'B-ORG'), ('legte', 'O', 'O'), (',', 'O', 'O'), ('wie', 'O', 'O'), ('auch', 'O', 'O'), ('vier', 'O', 'O'), ('weitere', 'O', 'O'), ('Parteien', 'O', 'O'), (',', 'O', 'O'), ('beim', 'O', 'O'), ('Oberst', 'O', 'O'), ('Gericht', 'O', 'O'), ('der', 'O', 'O'), ('Ukraine', 'B-LOC', 'B-LOC'), ('Be', 'O', 'O'), ('gegen', 'O', 'O'), ('den', 'O', 'O'), ('Ab', 'O', 'O'), ('der', 'O', 'O'), ('Wahl', 'O', 'O'), ('ein', 'O', 'O'), ('und', 'O', 'O'), ('be', 'O', 'O'), (',', 'O', 'O'), ('es', 'O', 'O'), ('sei', 'O', 'O'), ('bei', 'O', 'O'), ('der', 'O', 'O'), ('Aus', 'O', 'O'), ('zu', 'O', 'O'), ('Un', 'O', 'O'), ('gekommen', 'O', 'O'), ('.', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Der', 'O', 'O'), ('FC', 'B-ORG', 'B-ORG'), ('Ober', 'I-ORG', 'I-ORG'), (',', 'O', 'O'), ('der', 'O', 'O'), ('SV', 'B-ORG', 'B-ORG'), ('Th', 'I-ORG', 'I-ORG'), ('und', 'O', 'O'), ('die', 'O', 'O'), ('Sp', 'B-ORG', 'B-ORG'), ('Hank', 'I-ORG', 'I-ORG'), ('II', 'I-ORG', 'I-ORG'), (',', 'O', 'O'), ('die', 'O', 'O'), ('sich', 'O', 'O'), ('neben', 'O', 'O'), ('dem', 'O', 'O'), ('FC', 'B-ORG', 'B-ORG'), ('Wall', 'I-ORG', 'I-ORG'), ('(', 'O', 'O'), ('Bezirk', 'B-ORG', 'O'), (')', 'O', 'O'), ('und', 'O', 'O'), ('dem', 'O', 'O'), ('FC', 'B-ORG', 'B-ORG'), ('Te', 'I-ORG', 'I-ORG'), ('(', 'O', 'O'), ('Bezirk', 'O', 'O'), (')', 'O', 'O'), ('als', 'O', 'O'), ('weitere', 'O', 'O'), ('Kreis', 'O', 'O'), ('in', 'O', 'O'), ('dieser', 'O', 'O'), ('Gruppe', 'O', 'O'), ('befanden', 'O', 'O'), (',', 'O', 'O'), ('zogen', 'O', 'O'), ('sich', 'O', 'O'), ('einde', 'O', 'O'), ('besser', 'O', 'O'), ('aus', 'O', 'O'), ('der', 'O', 'O'), ('Af', 'O', 'O'), ('.', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(hf_tokenizer=hf_tokenizer, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'B-PER', 'O', 'I-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'B-LOC']\n"
     ]
    }
   ],
   "source": [
    "res = learn.predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def predict_tokens(self:Learner, inp, **kargs):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
    "    get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input\n",
    "    \"\"\"\n",
    "    pred_lbls, pred_lbl_ids, probs = self.predict(inp)\n",
    "    \n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    add_prefix_space = hf_textblock_tfm.add_prefix_space\n",
    "    \n",
    "    # grab the HF_BatchTransform as well\n",
    "    learn_hf_batch_transform = learn.dls.before_batch.hf__batch_transform\n",
    "    \n",
    "    # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "    # return\n",
    "    subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity), add_prefix_space=add_prefix_space))) \n",
    "                           for entity in inp ]\n",
    "    \n",
    "    # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "    # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "    # (e.g., [CLS], [SEP], etc...)\n",
    "    txt_toks = [ sub_toks for entity in inp \n",
    "                for sub_toks in hf_tokenizer.tokenize(entity, add_prefix_space=add_prefix_space) ]\n",
    "    \n",
    "    txt_tok_ids = hf_tokenizer.convert_tokens_to_ids(txt_toks)\n",
    "    \n",
    "    res = hf_tokenizer.prepare_for_model(txt_tok_ids, None, \n",
    "                                         max_length=learn_hf_batch_transform.max_seq_len, \n",
    "                                         pad_to_max_length=True,\n",
    "                                         truncation_strategy=None, \n",
    "                                         return_special_tokens_mask=True)\n",
    "    \n",
    "    special_toks_msk = L(res['special_tokens_mask'])\n",
    "    actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "    # using the indexes to the actual tokens, get that info from the results returned above\n",
    "    pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "    actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "    actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "    actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "    # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "    # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "    offset = 0\n",
    "    raw_trg_idxs = []\n",
    "    for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "        raw_trg_idxs.append(idx+offset)\n",
    "        offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "\n",
    "    return inp, actual_pred_lbls[raw_trg_idxs], actual_pred_lbl_ids[raw_trg_idxs], actual_probs[raw_trg_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.predict_tokens\" class=\"doc_header\"><code>Learner.predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.predict_tokens</code>(**`inp`**, **\\*\\*`kargs`**)\n",
       "\n",
       "Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
       "get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-OTH')]\n"
     ]
    }
   ],
   "source": [
    "res = learn.predict_tokens(txt.split())\n",
    "print([(tok, lbl) for tok,lbl in zip(res[0],res[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-language-modeling.ipynb.\n",
      "Converted 01c_data-question-answering.ipynb.\n",
      "Converted 01d_data-token-classification.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-language-modeling.ipynb.\n",
      "Converted 02c_modeling-question-answering.ipynb.\n",
      "Converted 02d_modeling-token-classification.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
