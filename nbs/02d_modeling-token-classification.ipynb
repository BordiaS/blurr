{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.token_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.token_classification\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for token classification tasks like named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai2.text.all import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from seqeval import metrics as seq_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token classification\n",
    "\n",
    "The objective of token classification is to predict the correct label for each token provided in the input. In the computer vision world, this is akin to what we do in segmentation tasks whereby we attempt to predict the class/label for each pixel in an image. Named entity recognition (NER) is an example of token classification in the NLP space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>nested-labels</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n-tv.de vom 26.02.2005 [2005-02-26]</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]</td>\n",
       "      <td>[B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>welt.de vom 29.10.2005 [2005-10-29]</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&amp;utm_medium=rss-feed&amp;utm_campaign=sport [2010-03-25]</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stern.de vom 21.03.2006 [2006-03-21]</td>\n",
       "      <td>[Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]</td>\n",
       "      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]</td>\n",
       "      <td>[B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]</td>\n",
       "      <td>[Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                        source  \\\n",
       "0                                                                                                                                                         n-tv.de vom 26.02.2005 [2005-02-26]    \n",
       "1                                                                                                                                                         welt.de vom 29.10.2005 [2005-10-29]    \n",
       "2  http://www.stern.de/sport/fussball/krawalle-in-der-fussball-bundesliga-dfb-setzt-auf-falsche-konzepte-1553657.html#utm_source=standard&utm_medium=rss-feed&utm_campaign=sport [2010-03-25]    \n",
       "3                                                                                                                                                        stern.de vom 21.03.2006 [2006-03-21]    \n",
       "4                                                                         http://www.fr-online.de/in_und_ausland/sport/aktuell/1618625_Frings-schaut-finster-in-die-Zukunft.html [2008-10-24]    \n",
       "\n",
       "                                                                                                                                                                  tokens  \\\n",
       "0        [Schartau, sagte, dem, \", Tagesspiegel, \", vom, Freitag, ,, Fischer, sei, \", in, einer, Weise, aufgetreten, ,, die, alles, andere, als, überzeugend, war, \", .]   \n",
       "1  [Firmengründer, Wolf, Peter, Bree, arbeitete, Anfang, der, siebziger, Jahre, als, Möbelvertreter, ,, als, er, einen, fliegenden, Händler, aus, dem, Libanon, traf, .]   \n",
       "2   [Ob, sie, dabei, nach, dem, Runden, Tisch, am, 23., April, in, Berlin, durch, ein, pädagogisches, Konzept, unterstützt, wird, ,, ist, allerdings, zu, bezweifeln, .]   \n",
       "3                                                  [Bayern, München, ist, wieder, alleiniger, Top-, Favorit, auf, den, Gewinn, der, deutschen, Fußball-Meisterschaft, .]   \n",
       "4                                                                  [Dabei, hätte, der, tapfere, Schlussmann, allen, Grund, gehabt, ,, sich, viel, früher, aufzuregen, .]   \n",
       "\n",
       "                                                                                    labels  \\\n",
       "0  [B-PER, O, O, O, B-ORG, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1       [O, B-PER, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O]   \n",
       "2             [O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                              [B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, B-LOCderiv, O, O]   \n",
       "4                                               [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                 nested-labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1           [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3                           [B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                                   [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  \n",
       "2   train  \n",
       "3   train  \n",
       "4   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensures these cols are represented as lists (rather than string)\n",
    "df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval, 'nested-labels': ast.literal_eval}\n",
    "\n",
    "# full nlp dataset\n",
    "# germ_eval_df = pd.read_csv('./data/task-token-classification/germeval2014ner_cleaned.csv', converters=df_converters)\n",
    "\n",
    "# demo nlp dataset\n",
    "germ_eval_df = pd.read_csv('./germeval2014_sample.csv', converters=df_converters)\n",
    "\n",
    "print(len(germ_eval_df))\n",
    "germ_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to be working with small sample from the [GermEval 2014](https://sites.google.com/site/germeval2014ner/data) data set ... so the results might not be all that great :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER', 'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-ORG', 'I-ORGpart', 'I-OTH', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "pretrained_model_name = \"bert-base-multilingual-cased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "\n",
    "config.num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I set the `config.num_labels` attribute to the number of labels we want *our* model to be able to predict. The model will update its last layer accordingly (this concept is essentially transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.configuration_bert.BertConfig,\n",
       " transformers.tokenization_bert.BertTokenizer,\n",
       " transformers.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(hf_config.num_labels, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_batch_tfm = HF_TokenClassBatchTransform(hf_arch, hf_tokenizer)\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(hf_arch, hf_tokenizer, hf_batch_tfm=hf_batch_tfm, max_length=128, is_pretokenized=True,\n",
    "                 tok_kwargs={ 'return_special_tokens_mask': True }), \n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp):\n",
    "    return [ (label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels) ]\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('tokens'),\n",
    "                   get_y=get_y,\n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define a `get_y` that creates the same number of labels as there are subtokens for a particular token. For example, my name \"Wayde\" gets split up into two subtokens, \"Way\" and \"##de\". The label for \"Wayde\" is \"B-PER\" and we just repeat it for the subtokens.  This all get cleaned up when we show results and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(germ_eval_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Eine', 'O'), ('kleinere', 'O'), (',', 'O'), ('spring', 'O'), ('Figur', 'O'), ('mit', 'O'), ('ge', 'O'), ('Helm', 'O'), ('hält', 'O'), ('ebenfalls', 'O'), ('den', 'O'), ('Rand', 'O'), ('des', 'O'), ('Rad', 'O'), ('.', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Seit', 'O'), ('1987', 'O'), ('ist', 'O'), ('die', 'O'), ('Disk', 'O'), ('von', 'O'), ('Sc', 'O'), ('und', 'O'), ('Les', 'O'), ('als', 'O'), ('St', 'O'), ('im', 'O'), ('St', 'O'), ('gel', 'O'), ('.', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for token classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_token_class_metrics(pred_toks, targ_toks, metric_key):\n",
    "    if (metric_key == 'accuracy'): return seq_metrics.accuracy_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'precision'): return seq_metrics.precision_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'recall'): return seq_metrics.recall_score(targ_toks, pred_toks)\n",
    "    if (metric_key == 'f1'): return seq_metrics.f1_score(targ_toks, pred_toks)\n",
    "        \n",
    "    if (metric_key == 'classification_report'): return seq_metrics.classification_report(targ_toks, pred_toks)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_TokenClassCallback(HF_BaseModelCallback):\n",
    "    \"\"\"A fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the\n",
    "    `seqeval` library.  Additionally, this metric knows how to *not* include your 'ignore_token' in it's\n",
    "    calculations.\n",
    "    \n",
    "    See [here](https://github.com/chakki-works/seqeval) for more information on `seqeval`.\n",
    "    \"\"\"\n",
    "    def __init__(self, tok_metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self, 'tok_metrics, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in tok_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the target's HF_TokenizerTransform (used for rouge metrics)\n",
    "        hf_textblock_tfm = self.dls.tfms[0]\n",
    "        self.hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "        self.ignore_label_token_id = self.dls.tfms[1].ignore_token_id\n",
    "        self.tok_special_symbols = list(self.hf_tokenizer.special_tokens_map.values())\n",
    "        self.tok_kwargs = hf_textblock_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        self.learn.token_classification_report = None\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "    \n",
    "    \n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # do this only for validation set\n",
    "        preds = self.pred.argmax(dim=-1)\n",
    "        targs = self.yb[0] # yb is TensorText tuple, item 0 is the data\n",
    "        \n",
    "        preds_list, targets_list = [], []   \n",
    "        for i in range(targs.shape[0]):\n",
    "            item_targs, item_preds = [], []\n",
    "            \n",
    "            for j in range(targs.shape[1]):\n",
    "                if (targs[i, j] != self.ignore_label_token_id):\n",
    "                    item_preds.append(self.dls.vocab[preds[i][j].item()])\n",
    "                    item_targs.append(self.dls.vocab[targs[i][j].item()])\n",
    "                    \n",
    "            preds_list.append(item_preds)\n",
    "            targets_list.append(item_targs)\n",
    "            \n",
    "        self.results += [ (res[0], res[1]) for res in zip(preds_list, targets_list) ]\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.results = []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        if (len(self.results) < 1): return\n",
    "        \n",
    "        preds, targs = map(list, zip(*self.results))\n",
    "        for k in self.custom_metrics_dict.keys(): \n",
    "            self.custom_metrics_dict[k] = calculate_token_class_metrics(targs, preds, metric_key=k)\n",
    "        \n",
    "        self.learn.token_classification_report = calculate_token_class_metrics(targs, preds, 'classification_report')\n",
    "        \n",
    "        \n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                cbs=[HF_TokenClassCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([4, 49, 18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([4, 49]), 4, torch.Size([4, 49]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([196, 18]) torch.Size([196])\n"
     ]
    }
   ],
   "source": [
    "print(preds[0].view(-1, preds[0].shape[-1]).shape, b[1].view(-1).shape)\n",
    "test_eq(preds[0].view(-1, preds[0].shape[-1]).shape[0], b[1].view(-1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.001096478197723627, lr_steep=2.0892961401841603e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.unfreeze()\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.304110</td>\n",
       "      <td>0.229341</td>\n",
       "      <td>0.939138</td>\n",
       "      <td>0.419847</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.515222</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.101803</td>\n",
       "      <td>0.136008</td>\n",
       "      <td>0.963155</td>\n",
       "      <td>0.732824</td>\n",
       "      <td>0.713755</td>\n",
       "      <td>0.723164</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.059089</td>\n",
       "      <td>0.126163</td>\n",
       "      <td>0.966976</td>\n",
       "      <td>0.782443</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.763501</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max= 3e-5, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      OTH       0.43      0.65      0.52        23\n",
      "      PER       0.95      0.85      0.90        86\n",
      "      ORG       0.73      0.64      0.68        59\n",
      " LOCderiv       0.96      0.68      0.79        34\n",
      "      LOC       0.90      0.76      0.82        71\n",
      "  ORGpart       0.40      1.00      0.57         2\n",
      "\n",
      "micro avg       0.78      0.75      0.76       275\n",
      "macro avg       0.84      0.75      0.79       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "print(learn.token_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_TokenClassInput, y:HF_TokenTensorCategory, samples, outs, learner=None, \n",
    "                 ctxs=None, max_n=6, **kwargs):    \n",
    "    # grab tokenizer\n",
    "    hf_textblock_tfm = learner.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    \n",
    "    res = L()\n",
    "    for inp, trg, sample, pred in zip(x[0], y, samples, outs):\n",
    "        inp_trg_preds = [ (hf_tokenizer.ids_to_tokens[tok_id.item()], lbl_id.item(), pred_lbl) \n",
    "                         for tok_id, lbl_id, pred_lbl in zip(inp, trg, ast.literal_eval(pred[0])) \n",
    "                         if (tok_id not in hf_tokenizer.all_special_ids) and lbl_id != -100 ]\n",
    "        \n",
    "        res.append([f'{[ (itp[0], lbl, itp[2]) for itp, lbl in zip(inp_trg_preds, ast.literal_eval(sample[1])) ]}'])\n",
    "        \n",
    "    display_df(pd.DataFrame(res, columns=['token / target label / predicted label'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label / predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('Brenda', 'B-PER', 'B-PER'), ('(', 'O', 'O'), ('Karen', 'B-PER', 'B-PER'), ('Young', 'I-PER', 'I-PER'), (',', 'O', 'O'), ('rechts', 'O', 'O'), (')', 'O', 'O'), ('such', 'O', 'O'), ('am', 'O', 'O'), ('Strand', 'O', 'O'), ('von', 'O', 'O'), ('Haiti', 'B-LOC', 'B-LOC'), ('mehr', 'O', 'O'), ('als', 'O', 'O'), ('Sex', 'O', 'O'), ('.', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('In', 'O', 'O'), ('dieser', 'O', 'O'), ('Zeit', 'O', 'O'), ('mussten', 'O', 'O'), ('die', 'O', 'O'), ('Liga', 'O', 'O'), ('mange', 'O', 'O'), ('regel', 'O', 'O'), ('Halle', 'O', 'O'), ('in', 'O', 'O'), ('Essen', 'B-LOC', 'B-LOC'), ('(', 'O', 'O'), ('Oldenburg', 'B-LOC', 'B-LOC'), (')', 'O', 'O'), ('ausgetragen', 'O', 'O'), ('werden', 'O', 'O'), ('.', 'O', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict('My name is Wayde and I live in San Diego'.split())\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `Learner.predict` method returns a prediction per subtoken, including the special tokens for each architecture's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict_tokens(self:Learner, inp, **kargs):\n",
    "    \"\"\"Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
    "    get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input\n",
    "    \"\"\"\n",
    "    pred_lbls, pred_lbl_ids, probs = self.blurr_predict(inp)\n",
    "\n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_textblock_tfm.kwargs\n",
    "    \n",
    "    # calculate the number of subtokens per raw/input token so that we can determine what predictions to\n",
    "    # return\n",
    "    subtoks_per_raw_tok = [ (entity, len(hf_tokenizer.tokenize(str(entity)))) for entity in inp ]\n",
    "    \n",
    "    # very similar to what HF_BatchTransform does with the exception that we are also grabbing\n",
    "    # the `special_tokens_mask` to help with getting rid or irelevant predicts for any special tokens\n",
    "    # (e.g., [CLS], [SEP], etc...)\n",
    "    res = hf_tokenizer(inp, None, \n",
    "                       max_length=hf_textblock_tfm.max_length,\n",
    "                       padding=hf_textblock_tfm.padding,\n",
    "                       truncation=hf_textblock_tfm.truncation,\n",
    "                       is_pretokenized=hf_textblock_tfm.is_pretokenized,\n",
    "                       **tok_kwargs)\n",
    "\n",
    "    special_toks_msk = L(res['special_tokens_mask'])\n",
    "    actual_tok_idxs = special_toks_msk.argwhere(lambda el: el != 1)\n",
    "    \n",
    "    # using the indexes to the actual tokens, get that info from the results returned above\n",
    "    pred_lbls_list = ast.literal_eval(pred_lbls)\n",
    "    actual_pred_lbls = L(pred_lbls_list)[actual_tok_idxs]\n",
    "    actual_pred_lbl_ids = pred_lbl_ids[actual_tok_idxs]\n",
    "    actual_probs = probs[actual_tok_idxs]\n",
    "    \n",
    "    # now, because a raw token can be mapped to multiple subtokens, we need to build a list of indexes composed\n",
    "    # of the *first* subtoken used to represent each raw token (that is where the prediction is)\n",
    "    offset = 0\n",
    "    raw_trg_idxs = []\n",
    "    for idx, (raw_tok, sub_tok_count) in enumerate(subtoks_per_raw_tok): \n",
    "        raw_trg_idxs.append(idx+offset)\n",
    "        offset += sub_tok_count-1 if (sub_tok_count > 1) else 0\n",
    "\n",
    "    return inp, actual_pred_lbls[raw_trg_idxs], actual_pred_lbl_ids[raw_trg_idxs], actual_probs[raw_trg_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict_tokens\" class=\"doc_header\"><code>Learner.blurr_predict_tokens</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict_tokens</code>(**`inp`**, **\\*\\*`kargs`**)\n",
       "\n",
       "Remove all the unnecessary predicted tokens after calling `Learner.predict`, so that you only\n",
       "get the predicted labels, label ids, and probabilities for what you passed into it in addition to the input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt =\"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi!', 'O'), ('My', 'O'), ('name', 'O'), ('is', 'O'), ('Wayde', 'B-PER'), ('Gilliam', 'I-PER'), ('from', 'O'), ('ohmeow.com.', 'B-ORG'), ('I', 'O'), ('live', 'O'), ('in', 'O'), ('California.', 'B-LOC')]\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict_tokens(txt.split())\n",
    "print([(tok, lbl) for tok,lbl in zip(res[0],res[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting (and very cool) how well this model performs on English even thought it was trained against a German corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-language-modeling.ipynb.\n",
      "Converted 01c_data-question-answering.ipynb.\n",
      "Converted 01d_data-token-classification.ipynb.\n",
      "Converted 01e_data-summarization.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-language-modeling.ipynb.\n",
      "Converted 02c_modeling-question-answering.ipynb.\n",
      "Converted 02d_modeling-token-classification.ipynb.\n",
      "Converted 02e_modeling-summarization.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
