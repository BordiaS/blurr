{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils\n",
    "\n",
    "> Various utility functions used by the blurr package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb, sys, inspect\n",
    "from enum import Enum\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from transformers import *\n",
    "from fastai2.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def str_to_class(classname):\n",
    "    \"converts string representation to class\"\n",
    "    return getattr(sys.modules[__name__], classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Singleton:\n",
    "    def __init__(self,cls):\n",
    "        self._cls, self._instance = cls, None\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        if self._instance == None: self._instance = self._cls(*args, **kwargs)\n",
    "        return self._instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Singleton` functions as python decorator.  Use this above any class to turn that class into a singleton (see [here](https://python-3-patterns-idioms-test.readthedocs.io/en/latest/Singleton.html) for more info on the singleton pattern)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Singleton\n",
    "class TestSingleton: pass\n",
    "\n",
    "a = TestSingleton()\n",
    "b = TestSingleton()\n",
    "test_eq(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@Singleton\n",
    "class ModelHelper():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # get hf classes (tokenizers, configs, models, etc...)\n",
    "        transformer_classes = inspect.getmembers(sys.modules[__name__], \n",
    "                                                 lambda member: inspect.isclass(member)\n",
    "                                                 and member.__module__.startswith('transformers.'))\n",
    "        \n",
    "        # build a df that we can query against to get various transformers objects/info\n",
    "        self._df = pd.DataFrame(transformer_classes, columns=['class_name', 'class_location'])\n",
    "        \n",
    "        # add the module each class is included in\n",
    "        self._df['module'] = self._df.class_location.apply(lambda v: v.__module__)\n",
    "        \n",
    "        # remove class_location (don't need it anymore)\n",
    "        self._df.drop(labels=['class_location'], axis=1, inplace=True)\n",
    "        \n",
    "        # break up the module into separate cols\n",
    "        module_parts_df = self._df.module.str.split(\".\", n = -1, expand = True) \n",
    "        for i in range(len(module_parts_df.columns)):\n",
    "            self._df[f'module_part_{i}'] = module_parts_df[i]\n",
    "\n",
    "        # using module part 1, break up the functional area and arch into separate cols\n",
    "        module_part_1_df = self._df.module_part_1.str.split(\"_\", n = 1, expand = True) \n",
    "        self._df[['functional_area', 'arch']] = module_part_1_df\n",
    "        \n",
    "        # if functional area = modeling, pull out the task it is built for\n",
    "        model_type_df = self._df[(self._df.functional_area == 'modeling')].class_name.str.split('For', n=1, expand=True)\n",
    "        \n",
    "        model_type_df[1] = np.where(model_type_df[1].notnull(), \n",
    "                                    'For' + model_type_df[1].astype(str), \n",
    "                                    model_type_df[1])\n",
    "        \n",
    "        self._df['model_task'] = model_type_df[1]\n",
    "        \n",
    "        model_type_df[1] = np.where(model_type_df[1].notnull(), \n",
    "                                    'With' + model_type_df[1].astype(str), \n",
    "                                    self._df[(self._df.functional_area == 'modeling')].model_task)\n",
    "        \n",
    "        self._df['model_task'] = model_type_df[1]\n",
    "        \n",
    "        # look at what we're going to remove (use to verify we're just getting rid of stuff we want too)\n",
    "        # df[~df['hf_class_type'].isin(['modeling', 'configuration', 'tokenization'])]\n",
    "        \n",
    "        # only need these 3 functional areas for our querying purposes\n",
    "        self._df = self._df[self._df['functional_area'].isin(['modeling', 'configuration', 'tokenization'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelHelper` is a `Singleton` (there exists only one instance, and the same instance is returned upon subsequent instantiation requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh = ModelHelper()\n",
    "mh2 = ModelHelper()\n",
    "test_eq(mh, mh2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>module</th>\n",
       "      <th>module_part_0</th>\n",
       "      <th>module_part_1</th>\n",
       "      <th>module_part_2</th>\n",
       "      <th>module_part_3</th>\n",
       "      <th>functional_area</th>\n",
       "      <th>arch</th>\n",
       "      <th>model_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaptiveEmbedding</td>\n",
       "      <td>transformers.modeling_transfo_xl</td>\n",
       "      <td>transformers</td>\n",
       "      <td>modeling_transfo_xl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>modeling</td>\n",
       "      <td>transfo_xl</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AlbertConfig</td>\n",
       "      <td>transformers.configuration_albert</td>\n",
       "      <td>transformers</td>\n",
       "      <td>configuration_albert</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>configuration</td>\n",
       "      <td>albert</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AlbertForMaskedLM</td>\n",
       "      <td>transformers.modeling_albert</td>\n",
       "      <td>transformers</td>\n",
       "      <td>modeling_albert</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>modeling</td>\n",
       "      <td>albert</td>\n",
       "      <td>WithForMaskedLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AlbertForQuestionAnswering</td>\n",
       "      <td>transformers.modeling_albert</td>\n",
       "      <td>transformers</td>\n",
       "      <td>modeling_albert</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>modeling</td>\n",
       "      <td>albert</td>\n",
       "      <td>WithForQuestionAnswering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AlbertForSequenceClassification</td>\n",
       "      <td>transformers.modeling_albert</td>\n",
       "      <td>transformers</td>\n",
       "      <td>modeling_albert</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>modeling</td>\n",
       "      <td>albert</td>\n",
       "      <td>WithForSequenceClassification</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, nan, 'WithForMaskedLM', 'WithForQuestionAnswering', 'WithForSequenceClassification', 'WithForTokenClassification', 'WithForPreTraining', 'WithForConditionalGeneration', 'WithForMultipleChoice', 'WithForNextSentencePrediction', 'WithForQuestionAnsweringSimple', 'WithForClassification']\n",
      "\n",
      "['modeling', 'configuration', 'tokenization']\n",
      "\n",
      "[None]\n",
      "\n",
      "[None]\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "display_df(mh._df.head())\n",
    "\n",
    "print(list(mh._df.model_task.unique()))\n",
    "print('')\n",
    "print(list(mh._df.functional_area.unique()))\n",
    "print('')\n",
    "print(list(mh._df.module_part_2.unique()))\n",
    "print('')\n",
    "print(list(mh._df.module_part_3.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
