{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.core\n",
    "\n",
    "> This module contains core custom models, loss functions, and a default layer group splitter for use in applying discriminiative learning rates to your huggingface models trained via fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, nlp\n",
    "from transformers import *\n",
    "\n",
    "from fastai2.text.all import *\n",
    "from fastai2.callback.hook import _print_shapes\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base splitter, model wrapper, and model callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hf_splitter(m):\n",
    "    \"\"\"Splits the huggingface model based on various model architecture conventions\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, 'hf_model')) else m\n",
    "    root_modules = list(model.named_children())\n",
    "    top_module_name, top_module = root_modules[0]\n",
    "    \n",
    "    groups = L([ m for m_name, m in list(top_module.named_children()) ])\n",
    "    groups += L([ m for m_name, m in root_modules[1:] ])\n",
    "\n",
    "    return groups.map(params).filter(lambda el: len(el) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"hf_splitter\" class=\"doc_header\"><code>hf_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>hf_splitter</code>(**`m`**)\n",
       "\n",
       "Splits the huggingface model based on various model architecture conventions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(hf_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_BaseModelWrapper(Module):\n",
    "    def __init__(self, hf_model):\n",
    "        super().__init__()\n",
    "        self.hf_model = hf_model\n",
    "        \n",
    "        n_fwd_args = self.hf_model.forward.__code__.co_argcount\n",
    "        self.hf_model_fwd_args = self.hf_model.forward.__code__.co_varnames[:n_fwd_args][1:]\n",
    "        \n",
    "    def forward(self, x): \n",
    "        for k in list(x): \n",
    "            if k not in self.hf_model_fwd_args: del x[k]         \n",
    "                \n",
    "        return self.hf_model(**x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `HF_baseModelWrapper` includes some nifty code for just passing in the things your model needs, as not all transformer architectures require/use the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_BaseModelCallback(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a `Callback` for handling what is returned from the huggingface model ... \"the huggingface model will return a tuple in outputs, with the actual predictions and some additional activations (should we want to use them is some regularization scheme)\" - from the fastai [Transformer's Tutorial](http://dev.fast.ai/tutorial.transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_summary_patch():\n",
    "    \"\"\"This is the ONLY way to get rid of the \"@patch\" methods we don't want to use!\n",
    "    \n",
    "    We do this here because:\n",
    "        a) we include our own summary methods and \n",
    "        b) because there is a conflict with huggingface's XMLForSequenceClassification models\n",
    "    \n",
    "    This effectively only needs to be called when using models like flaubert, or any other XLM flavored models\n",
    "    (see https://forums.fast.ai/t/bug-issue-with-patched-summary-method-in-hook-py/74846/8)\n",
    "    \"\"\"\n",
    "    delattr(Learner, 'summary')\n",
    "    delattr(nn.Module, 'summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"remove_summary_patch\" class=\"doc_header\"><code>remove_summary_patch</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>remove_summary_patch</code>()\n",
       "\n",
       "This is the ONLY way to get rid of the \"@patch\" methods we don't want to use!\n",
       "\n",
       "We do this here because:\n",
       "    a) we include our own summary methods and \n",
       "    b) because there is a conflict with huggingface's XMLForSequenceClassification models\n",
       "\n",
       "This effectively only needs to be called when using models like flaubert, or any other XLM flavored models\n",
       "(see https://forums.fast.ai/t/bug-issue-with-patched-summary-method-in-hook-py/74846/8)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(remove_summary_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence classification\n",
    "\n",
    "Below demonstrates how to setup your `blurr` pipeline for a sequence classification task (e.g., a model that requires a single text input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "imdb_df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.&lt;br /&gt;&lt;br /&gt;But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.&lt;br /&gt;&lt;br /&gt;Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.&lt;br /&gt;&lt;br /&gt;Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  \\\n",
       "0  negative   \n",
       "1  positive   \n",
       "2  negative   \n",
       "3  positive   \n",
       "4  negative   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                    Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!   \n",
       "1  This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...   \n",
       "2  Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.<br /><br />Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...   \n",
       "3  Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.<br /><br />Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...   \n",
       "4  This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "\n",
    "pretrained_model_name = \"roberta-base\" # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "blocks = (HF_TextBlock(hf_arch=hf_arch, hf_tokenizer=hf_tokenizer), CategoryBlock)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('text'), get_y=ColReader('label'), \n",
    "                   splitter=ColSplitter(col='is_valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(imdb_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is the one movie to see if you are to wed or are a married couple. The movie portrais a couple in Italy and deals with such difficult topics as abortion, infidelity, juggling work and family.&lt;br /&gt;&lt;br /&gt;The so called \"culture of death\" that we are experiencing nowadays in the world is terrible and this movie will surely make you think.&lt;br /&gt;&lt;br /&gt;A must see. I hope it gets distributed as it should.&lt;br /&gt;&lt;br /&gt;Congratulations on the cast and director.&lt;br /&gt;&lt;br /&gt;Two thumbs up and a 10 star evaluation from me!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We'll also add in custom summary methods for blurr learners/models that work with dictionary inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                loss_func=CrossEntropyLossFlat(),\n",
    "                metrics=[accuracy],\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.to_fp16()` requires a GPU so had to remove for tests to run on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_summary(self:nn.Module, *xb):\n",
    "    \"Print a summary of `self` using `xb`\"\n",
    "    sample_inputs,infos = layer_info(self, *xb)\n",
    "    n,bs = 64,find_bs(xb)\n",
    "    inp_sz = _print_shapes(apply(lambda x:x.shape, xb[0]['input_ids']), bs)\n",
    "    res = f\"{self.__class__.__name__} (Input shape: {inp_sz})\\n\"\n",
    "    res += \"=\" * n + \"\\n\"\n",
    "    res += f\"{'Layer (type)':<20} {'Output Shape':<20} {'Param #':<10} {'Trainable':<10}\\n\"\n",
    "    res += \"=\" * n + \"\\n\"\n",
    "    ps,trn_ps = 0,0\n",
    "    infos = [o for o in infos if o is not None] #see comment in previous cell\n",
    "    for typ,np,trn,sz in infos:\n",
    "        if sz is None: continue\n",
    "        ps += np\n",
    "        if trn: trn_ps += np\n",
    "        res += f\"{typ:<20} {_print_shapes(sz, bs)[:19]:<20} {np:<10,} {str(trn):<10}\\n\"\n",
    "        res += \"_\" * n + \"\\n\"\n",
    "    res += f\"\\nTotal params: {ps:,}\\n\"\n",
    "    res += f\"Total trainable params: {trn_ps:,}\\n\"\n",
    "    res += f\"Total non-trainable params: {ps - trn_ps:,}\\n\\n\"\n",
    "    return PrettyString(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_summary(self:Learner):\n",
    "    \"Print a summary of the model, optimizer and loss function.\"\n",
    "    xb = self.dls.train.one_batch()[:self.dls.train.n_inp]\n",
    "    res = self.model.blurr_summary(*xb)\n",
    "    res += f\"Optimizer used: {self.opt_func}\\nLoss function: {self.loss_func}\\n\\n\"\n",
    "    if self.opt is not None:\n",
    "        res += f\"Model \" + (\"unfrozen\\n\\n\" if self.opt.frozen_idx==0 else f\"frozen up to parameter group number {self.opt.frozen_idx}\\n\\n\")\n",
    "    res += \"Callbacks:\\n\" + '\\n'.join(f\"  - {cb}\" for cb in sort_by_run(self.cbs))\n",
    "    return PrettyString(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to create our own `summary` methods above because fastai only works where things are represented by a *single tensor*.  But in the case of huggingface transformers, a *single* sequence is represented by *multiple tensors* (in a dictionary).  \n",
    "\n",
    "The change to make this work is so minor I think that the fastai library can/will hopefully be updated to support this use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.0003019951749593019, lr_steep=0.002511886414140463)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.682027</td>\n",
       "      <td>0.624071</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.601941</td>\n",
       "      <td>0.547015</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.491119</td>\n",
       "      <td>0.510218</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "And here we creat a @typedispatched impelmentation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_BaseInput, y, samples, outs, learner=None, ctxs=None, max_n=6, **kwargs):        \n",
    "    \n",
    "    if ctxs is None: ctxs = get_empty_df(min(len(samples), max_n))\n",
    "    ctxs = show_batch[object](x, y, samples, max_n=max_n, ctxs=ctxs, **kwargs)\n",
    "    \n",
    "    n_preds_per_input = len(outs[0])\n",
    "    if (n_preds_per_input == 1): \n",
    "        for i,ctx in enumerate(ctxs): ctx['target'] = outs[i][0]\n",
    "    else:\n",
    "        for pred_idx in range(n_preds_per_input):\n",
    "            for i,ctx in enumerate(ctxs):  ctx[f'target{pred_idx+1}'] = outs[i][pred_idx]\n",
    "\n",
    "    display_df(pd.DataFrame(ctxs))\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&lt;br /&gt;&lt;br /&gt;Stanley Holloway is excellent as the minor city politician who suddenly finds himself leading one of the world's tiniest nations. Dame Margaret Rutherford is a delight as the history professor who sides with Pimlico. Others in the stand-out cast include Hermione Baddeley, Paul Duplis, Naughton Wayne, Basil Radford &amp; Sir Michael Hordern.&lt;br /&gt;&lt;br /&gt;Welcome to Burgundy!</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The movie and acting are not bad and Jay Hernandez does a good job playing Calito Brigante but the movie forgets it's suppose to be a prequel to a hit movie. The makers of this prequel clearly did not watch the original Carlito's Way or at least did not care about continuity. This movie is a prequel which means the original movie has already laid out some history for us and this movie should end where the original begins or at least lead up to it. Not one of Carlito's close old friends from the original make an appearance in this movie, they're not even mentioned. Luis Guzman, Pachanga in the original, is in the movie but he plays a completely different character. The original takes place in 1975 and the prequel takes place in 1969-70. Considering this movie takes place less than 5 years earlier, wouldn't you think one of Carlito's long time friends would make an appearance? In the original, Carlito start's out being released from jail after spending 5 years in jail. That's only a few month's between the end of the prequel and the start of the original! ***Semi Spoiler*** We know from the beginning of the original, Carlito has spent 5 years in prison so when the prequel gives us this Hollywood happy ending it's an insult to the intelligence of fans of the original. What happen to Gail? It's the lack of continuity that made this film go direct to video release.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict(self:Learner, item, rm_type_tfms=None, with_input=False):\n",
    "    dl = self.dls.test_dl([item], rm_type_tfms=rm_type_tfms, num_workers=0)\n",
    "    \n",
    "    # this is where we have to change things up since a blurr \"input\" is represented by a dictionary of\n",
    "    # tensors (input_ids, attention_mask, token_type_ids, etc...) and not a single tensor (which fastai assumes\n",
    "    # in a number of places)\n",
    "    b = dl.one_batch()\n",
    "    inp = b[0]\n",
    "    preds, _, dec_preds = self.get_preds(dl=dl, with_input=False, with_decoded=True)\n",
    "    \n",
    "    i = getattr(self.dls, 'n_inp', -1)\n",
    "    inp = (inp,) if i==1 else tuplify(inp)\n",
    "    dec = self.dls.decode_batch(inp + tuplify(dec_preds))[0]\n",
    "    dec_inp,dec_targ = map(detuplify, [dec[:i],dec[i:]])\n",
    "    res = dec_targ,dec_preds[0],preds[0]\n",
    "    if with_input: res = (dec_inp,) + res\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as with `summary`, we need to replace fastai's `Learner.predict` method with the one above which is able to work with inputs that are represented by multiple tensors included in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('positive', tensor(1), tensor([0.4562, 0.5438]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict('I really liked the movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.336187</td>\n",
       "      <td>0.253885</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.126690</td>\n",
       "      <td>0.302692</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.111218</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=slice(1e-6, 1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&lt;br /&gt;&lt;br /&gt;Stanley Holloway is excellent as the minor city politician who suddenly finds himself leading one of the world's tiniest nations. Dame Margaret Rutherford is a delight as the history professor who sides with Pimlico. Others in the stand-out cast include Hermione Baddeley, Paul Duplis, Naughton Wayne, Basil Radford &amp; Sir Michael Hordern.&lt;br /&gt;&lt;br /&gt;Welcome to Burgundy!</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So, Todd Sheets once stated that he considers his 1993, shot-on-video Z-epic, Zombie Bloodbath to be his first feature film. Anyone who's ever seen a little beauty called Zombie Rampage knows exactly how untrue that statement is. I mean, what makes this one that much more superior? Well, then again, Zombie Rampage doesn't include that mullet guy, now does it? &lt;br /&gt;&lt;br /&gt;For one to comprehend exactly why Zombie Bloodbath is actually considered worth a damn, one must remember what the 90's were like for lovers of bad horror. A decade that all but said goodbye to B and Z-cinema as we knew it. Technological advances, awkward trends, and the internet would abolish the mysterious charms of the s.o.v.'s big-boxed golden years. And anything remotely resembling quality schlock was all too self-aware for it's own good, basically defeating the purpose. Luckily, not everyone changes with the times. Enter Zombie Bloodbath.&lt;br /&gt;&lt;br /&gt;And I guess this is the part where I explain the same exact premise from 500 other zombie flicks from the last 40 years. Alright, so, Some kind of accident at a nuclear plant infects everyone in sight, turning them into flesh-eating zombies, who go on a rampage, inflicting some of the most gruesome, yet humorous gore-scenes of the 90's. The first 20 minutes are cluttered with the most awkward-sounding conversations you could imagine. Conversations that let you know that this isn't just a low-budget zombie flick, this is a Z-grade disasterpiece, fella. plenty Hysterical, non-existent acting to go around, and that goes triple for Mr. Mullet. That guy is truly the highlight of the night.&lt;br /&gt;&lt;br /&gt;The fact that Todd Sheets seriously considers Zombie Bloodbath to be THAT superior to Zombie Rampage, amuses me to no end. I mean really, both are complete jokes on celluloid, but then again, so is Redneck Zombies, so, obviously Todd Sheets is in the company of awsomeness. By 1993, a movie this bad would no doubt, be a full-blast spoof, but Mr. Sheets stands his ground, giving us some good old fashion schlock, the way it was meant to be, unaware, clueless, and pointless. God bless Todd Sheets. For anyone seeking surprisingly worthwhile 90's B-Horror, Leif</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('positive', tensor(1), tensor([0.0862, 0.9138]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('negative', tensor(0), tensor([0.9948, 0.0052]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"Acting was so bad it was almost funny.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname='seq_class_learn_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('negative', tensor(0), tensor([0.9772, 0.0228]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname='seq_class_learn_export.pkl')\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('negative', tensor(0), tensor([0.9772, 0.0228]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the core training code above works for **all** pretrained sequence classification models available in huggingface.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained classification models you are working with ... and if any of your pretrained sequence classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.modeling_albert.AlbertForSequenceClassification,\n",
       " transformers.modeling_auto.AutoModelForSequenceClassification,\n",
       " transformers.modeling_bart.BartForSequenceClassification,\n",
       " transformers.modeling_bert.BertForSequenceClassification,\n",
       " transformers.modeling_camembert.CamembertForSequenceClassification,\n",
       " transformers.modeling_distilbert.DistilBertForSequenceClassification,\n",
       " transformers.modeling_electra.ElectraForSequenceClassification,\n",
       " transformers.modeling_flaubert.FlaubertForSequenceClassification,\n",
       " transformers.modeling_longformer.LongformerForSequenceClassification,\n",
       " transformers.modeling_mobilebert.MobileBertForSequenceClassification,\n",
       " transformers.modeling_roberta.RobertaForSequenceClassification,\n",
       " transformers.modeling_xlm.XLMForSequenceClassification,\n",
       " transformers.modeling_xlm_roberta.XLMRobertaForSequenceClassification,\n",
       " transformers.modeling_xlnet.XLNetForSequenceClassification]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLURR_MODEL_HELPER.get_models(task='SequenceClassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'albert-base-v1',\n",
    "    'facebook/bart-base',\n",
    "    'bert-base-uncased',\n",
    "    'camembert-base',\n",
    "    'distilbert-base-uncased',\n",
    "    'monologg/electra-small-finetuned-imdb',\n",
    "    'flaubert/flaubert_small_cased', \n",
    "    'allenai/longformer-base-4096',\n",
    "    'google/mobilebert-uncased',\n",
    "    'roberta-base',\n",
    "    'xlm-mlm-en-2048',\n",
    "    'xlm-roberta-base',\n",
    "    'xlnet-base-cased'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "\n",
    "model_path = Path('models')\n",
    "imdb_df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we can test XMLForSequenceClassification models\n",
    "remove_summary_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== albert-base-v1 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v1 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizer\n",
      "model:\t\tAlbertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.704615</td>\n",
       "      <td>0.666968</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post-war restrictions. merry mayhem is what would happen.br /br /the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall.br</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a grade-z horror filmmaker carl monson was one of the most prolific directors operating within the field of the low-budget gory mayhem.his movies are full of inept gore,laughable acting,boring sub-plots and woeful dialogue.a mysterious black clad figure is savagely murdering guests staying at the family mansion.unfortunately this film is almost bloodless.you don't actually see the murders except with shadows and a few blood splatters.the pace is lethargic and the plot is rather uninteresting.the acting is merely competent,but the</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/bart-base were not used when initializing BartForSequenceClassification: ['final_logits_bias']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.weight', 'classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizer\n",
      "model:\t\tBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.591572</td>\n",
       "      <td>0.651860</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This review contains spoilers for those who are not aware of the details of the true story on which this movie is based.&lt;br /&gt;&lt;br /&gt;The right to be presumed \"Innocent until proven guilty\" is a basic entitlement of anyone in a civilised society; but according to Fred Schepisi's partisan but sadly convincing story of a famous Australian murder trial, it was not granted to Lindy Chamberlain, accused of killing her baby. The story suggesting her innocence was unlikely (a dingo was alleged to have taken it), but those implying her guilt even more so, and there was no solid evidence against her. But</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bert-base-uncased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizer\n",
      "model:\t\tBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.672972</td>\n",
       "      <td>0.661931</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>although a film with bruce willis is always worth watching, you better skip this one. i watched this one on television, so i didn't have to plunk down cash for it. lucky me. &lt; br / &gt; &lt; br / &gt; the plot develops slowly, very slowly. although the first 30 minutes or so are quite believable, it gets more and more unbelievable towards the end. it is highly questionable, if a seasoned soldier like lt. waters would disobey direct orders. and even if he would, if the rest of his platoon would. they know he puts them in direct danger, and they know</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizer\n",
      "model:\t\tCamembertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.693074</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I f you thought Sam Mendes' first film, the much heralded American BEAUTY was a movie with style to spare, wait until you see his highly anticipated second effort, the unrelentingly grim 30's gangster melodrama ROAD TO PERDITION. Some critics have hailed this new movie as a worthy successor to THE GODFATHER, a rash judgment made by several reviewers taken with Mr. Mendes' extraordinary</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== distilbert-base-uncased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizer\n",
      "model:\t\tDistilBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.682602</td>\n",
       "      <td>0.681696</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i saw this movie once as a kid on the late - late show and fell in love with it. &lt; br / &gt; &lt; br / &gt; it took 30 + years, but i recently did find it on dvd - it wasn't cheap, either - in a catalog that specialized in war movies. we watched it last night for the first time. the audio was good, however it was grainy and had the trailers between reels. even so, it was better than i remembered it. i was also impressed at how true it was to the play. &lt; br / &gt; &lt; br / &gt; the catalog is around here</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== monologg/electra-small-finetuned-imdb ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/electra-small-finetuned-imdb were not used when initializing ElectraForSequenceClassification: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/electra-small-finetuned-imdb and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizer\n",
      "model:\t\tElectraForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.232003</td>\n",
       "      <td>0.307336</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i saw this movie once as a kid on the late - late show and fell in love with it. &lt; br / &gt; &lt; br / &gt; it took 30 + years, but i recently did find it on dvd - it wasn't cheap, either - in a catalog that specialized in war movies. we watched it last night for the first time. the audio was good, however it was grainy and had the trailers between reels. even so, it was better than i remembered it. i was also impressed at how true it was to the play. &lt; br / &gt; &lt; br / &gt; the catalog is around here</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== flaubert/flaubert_small_cased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at flaubert/flaubert_small_cased were not used when initializing FlaubertForSequenceClassification: ['pred_layer.proj.bias', 'pred_layer.proj.weight']\n",
      "- This IS expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaubertForSequenceClassification were not initialized from the model checkpoint at flaubert/flaubert_small_cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "model:\t\tFlaubertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.770631</td>\n",
       "      <td>0.698855</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since for</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\" A Cry in the Dark \" is a masterful piece of cinema, haunting, and incredibly though provoking. The true story of Lindy Chamberland, who, in 1980, witnessed a horrific sight, seeing her 3-month-old baby being brutally taken from their family' s tent, while camping on the Austrailian outback. Azaria ( the baby ) was never seen again, and the result of her horrendous disappearance caused a true life frenzy</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/longformer-base-4096 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizer\n",
      "model:\t\tLongformerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.669833</td>\n",
       "      <td>0.638257</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am starting this review with a big giant spoiler about this film. Do not read further...here it comes, avert your eyes! The main heroine, the girl who always survives in other slasher films, is murdered here. There, I just saved you 79 minutes of your life.&lt;br /&gt;&lt;br /&gt;This is one of those cheap movies that was thrown together in the middle of the slasher era of the '80's. Despite killing the heroine off, this is just substandard junk.&lt;br /&gt;&lt;br /&gt;Both priests and college students get a bad rap here. They are pictured as oversexed, sociop</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mobilebert-uncased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizer\n",
      "model:\t\tMobileBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>313158.968750</td>\n",
       "      <td>50417.648438</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for anyone who may not know what a one - actor movie was like, this is the best example. this plot is ridiculous, and really makes no sense. it's full of cliched situations, hackneyed lines, melodrama, comedy... you name it! &lt; br / &gt; &lt; br / &gt; but amitabh bachchan can make anything convincing, and this movie is by no means an exception. everyone turns in a decent performance - shashi kapoor, waheeda rehman, ranjit, om prakash, smita patil... but it is the megastar who overshad</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizer\n",
      "model:\t\tRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.675512</td>\n",
       "      <td>0.660753</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I had not seen the movie trailer when I went to see the movie, instead I based my judgments on a friend's opinions. Now I like Chris Rock and his comedy, but this movie just falls flat on its face.&lt;br /&gt;&lt;br /&gt;During the movie Rock delivers a couple of funny jokes, but unfortunately the movie is sorely lacking in comedy. The movie seems want to integrate both laughter and love into one, and it that endeavor it fails. The love story in the movie is straight forward (luckily), but it detracts too much from the movie by making Rock serious and bland. After all, the movie is</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-en-2048 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-mlm-en-2048 were not used when initializing XLMForSequenceClassification: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLMForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMForSequenceClassification were not initialized from the model checkpoint at xlm-mlm-en-2048 and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "model:\t\tXLMForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.929128</td>\n",
       "      <td>0.791031</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post-war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt; br /</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is one of my all-time favorite films, and while it may move too slowly for some, it's well worth seeing. a corporate lawyer ( richard chamberlain ) is dragged into a case involving \" city \" aborigines, and this is no ordinary case. ok, a man has died but it wasn 't exactly a normal killing. there has also been a greater than average amount of rain lately, and the atmosphere of most of the film is somewhat claustrophobic &amp; oppressive. the aborigines are harboring a secret and refuse to spill the beans. this has a lot to do with white men making assumptions about</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizer\n",
      "model:\t\tXLMRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.698996</td>\n",
       "      <td>0.680010</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This has to be the cheapest film made in 21st century. It is all the way low quality, but at the end it falls below... everything. All the cheap tricks - like flashing and darkness - are used to hide those crappy computer effects.&lt;br /&gt;&lt;br /&gt;All the actors are below average, especially the main character Anne Fletcher (Simmone Mackinnon). There is a scene, where Anne is asked: \"Why you seem so careless?\" The correct answer is, because she can't act. No matter what happens (the world is about to be destroy</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizer\n",
      "model:\t\tXLNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.625261</td>\n",
       "      <td>0.654717</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This was a terrible film. There was no story line whatsoever. To top it all off, when they couldn't explain the blood and gore (the only good part)... they threw in a few aliens! I hate when directors (or whatever) run out of ideas and then blame the aliens! Watch this film if you like. But don't say I didn't warn you. Two things: How could Vinny say \"welcome\" when he didn't have a tongue? Its a pity Mr Jones didn't have a bigger role. Second thing that bugged</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "test_results = []\n",
    "\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    del learn \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(model_name, \n",
    "                                                                                   task=task, \n",
    "                                                                                   config_kwargs={'num_labels': 2})\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n')\n",
    "\n",
    "    blocks = (HF_TextBlock(hf_arch=hf_arch, hf_tokenizer=hf_tokenizer, max_length=128), CategoryBlock)\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                       get_x=ColReader('text'), \n",
    "                       get_y=ColReader('label'), \n",
    "                       splitter=ColSplitter(col='is_valid'))\n",
    "    \n",
    "    dls = dblock.dataloaders(imdb_df, bs=4)\n",
    "    \n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    learn = Learner(dls, \n",
    "                    model,\n",
    "                    opt_func=partial(Adam, decouple_wd=True),\n",
    "                    loss_func=CrossEntropyLossFlat(),\n",
    "                    metrics=[accuracy],\n",
    "                    cbs=[HF_BaseModelCallback],\n",
    "                    splitter=hf_splitter)\n",
    "\n",
    "    learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "    learn.freeze()\n",
    "    \n",
    "    b = dls.one_batch()\n",
    "    \n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), 4)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([4, 128]))\n",
    "        test_eq(len(b[1]), 4)\n",
    "\n",
    "        print('*** TESTING One pass through the model ***')\n",
    "        preds = learn.model(b[0])\n",
    "        test_eq(len(preds[0]), 4)\n",
    "        test_eq(preds[0].shape, torch.Size([4, 2]))\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(max_n=2)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizer</td>\n",
       "      <td>AlbertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizer</td>\n",
       "      <td>BartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizer</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizer</td>\n",
       "      <td>CamembertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizer</td>\n",
       "      <td>DistilBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizer</td>\n",
       "      <td>ElectraForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizer</td>\n",
       "      <td>LongformerForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizer</td>\n",
       "      <td>MobileBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizer</td>\n",
       "      <td>RobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizer</td>\n",
       "      <td>XLMRobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizer</td>\n",
       "      <td>XLNetForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Multi-label classification\n",
    "\n",
    "Below demonstrates how to setup your `blurr` pipeline for a multi-label classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18049"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a dataset with the first 10% of training set\n",
    "raw_data = nlp.load_dataset('civil_comments', split='train[:1%]') \n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is such an urgent design problem; kudos to you for taking it on. Very impressive!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this something I'll be able to install on my site? When will you be releasing it?</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 text  \\\n",
       "0               This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!   \n",
       "1  Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!   \n",
       "2                              This is such an urgent design problem; kudos to you for taking it on. Very impressive!   \n",
       "3                                Is this something I'll be able to install on my site? When will you be releasing it?   \n",
       "4                                                                                haha you guys are a bunch of losers.   \n",
       "\n",
       "   toxicity  severe_toxicity  obscene  threat   insult  identity_attack  \\\n",
       "0  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "1  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "2  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "3  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "4  0.893617         0.021277      0.0     0.0  0.87234         0.021277   \n",
       "\n",
       "   sexual_explicit  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df = pd.DataFrame(raw_data)\n",
    "toxic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['severe_toxicity',\n",
       " 'obscene',\n",
       " 'threat',\n",
       " 'insult',\n",
       " 'identity_attack',\n",
       " 'sexual_explicit']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_cols = list(toxic_df.columns[2:]); lbl_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is such an urgent design problem; kudos to you for taking it on. Very impressive!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this something I'll be able to install on my site? When will you be releasing it?</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 text  \\\n",
       "0               This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!   \n",
       "1  Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!   \n",
       "2                              This is such an urgent design problem; kudos to you for taking it on. Very impressive!   \n",
       "3                                Is this something I'll be able to install on my site? When will you be releasing it?   \n",
       "4                                                                                haha you guys are a bunch of losers.   \n",
       "\n",
       "   toxicity  severe_toxicity  obscene  threat  insult  identity_attack  \\\n",
       "0  0.000000                0        0       0       0                0   \n",
       "1  0.000000                0        0       0       0                0   \n",
       "2  0.000000                0        0       0       0                0   \n",
       "3  0.000000                0        0       0       0                0   \n",
       "4  0.893617                0        0       0       1                0   \n",
       "\n",
       "   sexual_explicit  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df = toxic_df.round({col: 0 for col in lbl_cols})\n",
    "toxic_df = toxic_df.convert_dtypes()\n",
    "\n",
    "toxic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "\n",
    "pretrained_model_name = \"roberta-base\" # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = len(lbl_cols)\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we have to configure the `num_labels` to the number of labels we are predicting. Given that our labels are already encoded, we use a `MultiCategoryBlock` with `encoded=True` and `vocab` equal to the columns with our 1's and 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "blocks = (\n",
    "    HF_TextBlock(hf_arch=hf_arch, hf_tokenizer=hf_tokenizer), \n",
    "    MultiCategoryBlock(encoded=True, vocab=lbl_cols)\n",
    ")\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('text'), get_y=ColReader(lbl_cols), \n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(toxic_df, bs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([8, 512]), torch.Size([8, 6]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You don't speak for \"most Alaskans\".</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great article! Definitely concur with you about the experience and what people are missing out on. I also wrote an article on my personal blog. Feel free to check it out. https://hingpotter.wordpress.com/  Thanks for coming to Boise!!!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                loss_func=BCEWithLogitsLossFlat(),\n",
    "                metrics=[partial(accuracy_multi, thresh=0.2)],\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "learn.loss_func.thresh = 0.2\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're doing multi-label classification, we adjust our loss function to use binary cross-entropy and our metrics to use the multi-label friendly version of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(b[0])\n",
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.010000000149011612, lr_steep=1.3182567358016968)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.029778</td>\n",
       "      <td>0.036622</td>\n",
       "      <td>0.992379</td>\n",
       "      <td>05:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.029847</td>\n",
       "      <td>0.032721</td>\n",
       "      <td>0.992887</td>\n",
       "      <td>05:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.029638</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>0.992611</td>\n",
       "      <td>05:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>None</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>And The Lord spoke, get thee a fine silken tie and matching shoes to go with your 1000 dollar suit and too expensive haircut, do this in my name and ye shall be rewarded... From the Scriptures of Deacon Hawker, chapter 11, verse 13.  Most High &amp; Pious Edition</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a much-needed article, it could be longer. As a 20+ year freelancer, one would think that things such as getting paid would get better with more people doing contract work. But I am having problems getting paid and thisand it's created a huge amount of stress and financial difficulties for me.  I even worked for 3 months with a nonprofit organization that is supposed to help small businesses and contractors yet they didn't pay me one cent! When I applied for small claims court settlement they put two lawyers on me and asked for a jury trial. I would have loved to have continued this but I could't afford the time and stress. So now I am  the average freelancer is owed $5000 or more (according to Freelancers Union). \\n\\nI am a female and I have also experienced organizations assuming women are volunteers.\\n\\nAt the very least there is a huge need for trainings on how to work with freelancers in non profits and for profits. Some legal recourse would be great too.</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func.thresh = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((#1) ['insult'],\n",
       " tensor([False, False, False,  True, False, False]),\n",
       " tensor([1.3623e-06, 5.1205e-03, 3.5144e-04, 3.1536e-02, 4.8273e-03, 1.0864e-03]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"\"\"\n",
    "Those damned affluent white people should only eat their own food, like cod cakes and boiled potatoes. \n",
    "No enchiladas for them!\n",
    "\"\"\"\n",
    "learn.blurr_predict(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-language-modeling.ipynb.\n",
      "Converted 01c_data-question-answering.ipynb.\n",
      "Converted 01d_data-token-classification.ipynb.\n",
      "Converted 01e_data-text-generation.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-language-modeling.ipynb.\n",
      "Converted 02c_modeling-question-answering.ipynb.\n",
      "Converted 02d_modeling-token-classification.ipynb.\n",
      "Converted 02e_modeling-text-generation.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
