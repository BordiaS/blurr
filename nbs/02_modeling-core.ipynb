{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.core\n",
    "\n",
    "> This module contains core custom models, loss functions, and a default layer group splitter for use in applying discriminiative learning rates to your huggingface models trained via fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, nlp\n",
    "from transformers import *\n",
    "\n",
    "from fastai2.text.all import *\n",
    "from fastai2.callback.hook import _print_shapes\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base splitter, model wrapper, and model callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hf_splitter(m):\n",
    "    \"\"\"Splits the huggingface model based on various model architecture conventions\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, 'hf_model')) else m\n",
    "    root_modules = list(model.named_children())\n",
    "    top_module_name, top_module = root_modules[0]\n",
    "    \n",
    "    groups = L([ m for m_name, m in list(top_module.named_children()) ])\n",
    "    groups += L([ m for m_name, m in root_modules[1:] ])\n",
    "\n",
    "    return groups.map(params).filter(lambda el: len(el) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"hf_splitter\" class=\"doc_header\"><code>hf_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>hf_splitter</code>(**`m`**)\n",
       "\n",
       "Splits the huggingface model based on various model architecture conventions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(hf_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_BaseModelWrapper(Module):\n",
    "    def __init__(self, hf_model):\n",
    "        super().__init__()\n",
    "        self.hf_model = hf_model\n",
    "        \n",
    "        n_fwd_args = self.hf_model.forward.__code__.co_argcount\n",
    "        self.hf_model_fwd_args = self.hf_model.forward.__code__.co_varnames[:n_fwd_args][1:]\n",
    "        \n",
    "    def forward(self, x): \n",
    "        for k in list(x): \n",
    "            if k not in self.hf_model_fwd_args: del x[k]         \n",
    "                \n",
    "        return self.hf_model(**x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `HF_baseModelWrapper` includes some nifty code for just passing in the things your model needs, as not all transformer architectures require/use the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_BaseModelCallback(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a `Callback` for handling what is returned from the huggingface model ... \"the huggingface model will return a tuple in outputs, with the actual predictions and some additional activations (should we want to use them is some regularization scheme)\" - from the fastai [Transformer's Tutorial](http://dev.fast.ai/tutorial.transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_summary_patch():\n",
    "    \"\"\"This is the ONLY way to get rid of the \"@patch\" methods we don't want to use!\n",
    "    \n",
    "    We do this here because:\n",
    "        a) we include our own summary methods and \n",
    "        b) because there is a conflict with huggingface's XMLForSequenceClassification models\n",
    "    \n",
    "    This effectively only needs to be called when using models like flaubert, or any other XLM flavored models\n",
    "    (see https://forums.fast.ai/t/bug-issue-with-patched-summary-method-in-hook-py/74846/8)\n",
    "    \"\"\"\n",
    "    delattr(Learner, 'summary')\n",
    "    delattr(nn.Module, 'summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"remove_summary_patch\" class=\"doc_header\"><code>remove_summary_patch</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>remove_summary_patch</code>()\n",
       "\n",
       "This is the ONLY way to get rid of the \"@patch\" methods we don't want to use!\n",
       "\n",
       "We do this here because:\n",
       "    a) we include our own summary methods and \n",
       "    b) because there is a conflict with huggingface's XMLForSequenceClassification models\n",
       "\n",
       "This effectively only needs to be called when using models like flaubert, or any other XLM flavored models\n",
       "(see https://forums.fast.ai/t/bug-issue-with-patched-summary-method-in-hook-py/74846/8)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(remove_summary_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence classification\n",
    "\n",
    "Below demonstrates how to setup your `blurr` pipeline for a sequence classification task (e.g., a model that requires a single text input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "imdb_df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.&lt;br /&gt;&lt;br /&gt;But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.&lt;br /&gt;&lt;br /&gt;Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.&lt;br /&gt;&lt;br /&gt;Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  \\\n",
       "0  negative   \n",
       "1  positive   \n",
       "2  negative   \n",
       "3  positive   \n",
       "4  negative   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                    Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!   \n",
       "1  This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...   \n",
       "2  Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.<br /><br />Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...   \n",
       "3  Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.<br /><br />Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...   \n",
       "4  This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "\n",
    "pretrained_model_name = \"roberta-base\" # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "blocks = (HF_TextBlock(hf_arch=hf_arch, hf_tokenizer=hf_tokenizer), CategoryBlock)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('text'), get_y=ColReader('label'), \n",
    "                   splitter=ColSplitter(col='is_valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(imdb_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Moon Child is the story of two brothers and a friend trying to make it in a futuristic, economically-unstable Japan. After a cunning disaster gone wrong, someone new enters young Sho's life, a special friend by the name of Kei. Years later they have grown rather close, and have found ways to combine both their talents into one unstoppable team. During another escapade, they encounter a new friend and his mute sister who become part of their band of friends. Before long disaster again strikes and the group falls apart. Alliances turn to enemies and their worlds are all turned upside down. Regrets and hopelessness claim some while power and success take others. Tragedy claims still others. Truths are revealed and lives are forever changed. &lt;br /&gt;&lt;br /&gt;And you will never see a more beautiful sunrise.&lt;br /&gt;&lt;br /&gt;This movie is a gripping tale of undying friendships, webs of relationships, and a team that not even death can keep apart for too long. Moon child combines sci-fi, drama, and action with the perfect cast and talent to create the most sensationally moving movie of the time, and great for most audiences. It minimizes the everyday romances and puts more emphasis on the important values we can all relate to such as friendships, loyalty, and believing in yourself. Nothing could possibly compare. I personally have never seen anything quite like it, and I don't suspect I ever will again.&lt;br /&gt;&lt;br /&gt;It appeals to the wider population in many ways and is a must see for all.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We'll also add in custom summary methods for blurr learners/models that work with dictionary inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                loss_func=CrossEntropyLossFlat(),\n",
    "                metrics=[accuracy],\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.to_fp16()` requires a GPU so had to remove for tests to run on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_summary(self:nn.Module, *xb):\n",
    "    \"Print a summary of `self` using `xb`\"\n",
    "    sample_inputs,infos = layer_info(self, *xb)\n",
    "    n,bs = 64,find_bs(xb)\n",
    "    inp_sz = _print_shapes(apply(lambda x:x.shape, xb[0]['input_ids']), bs)\n",
    "    res = f\"{self.__class__.__name__} (Input shape: {inp_sz})\\n\"\n",
    "    res += \"=\" * n + \"\\n\"\n",
    "    res += f\"{'Layer (type)':<20} {'Output Shape':<20} {'Param #':<10} {'Trainable':<10}\\n\"\n",
    "    res += \"=\" * n + \"\\n\"\n",
    "    ps,trn_ps = 0,0\n",
    "    infos = [o for o in infos if o is not None] #see comment in previous cell\n",
    "    for typ,np,trn,sz in infos:\n",
    "        if sz is None: continue\n",
    "        ps += np\n",
    "        if trn: trn_ps += np\n",
    "        res += f\"{typ:<20} {_print_shapes(sz, bs)[:19]:<20} {np:<10,} {str(trn):<10}\\n\"\n",
    "        res += \"_\" * n + \"\\n\"\n",
    "    res += f\"\\nTotal params: {ps:,}\\n\"\n",
    "    res += f\"Total trainable params: {trn_ps:,}\\n\"\n",
    "    res += f\"Total non-trainable params: {ps - trn_ps:,}\\n\\n\"\n",
    "    return PrettyString(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_summary(self:Learner):\n",
    "    \"Print a summary of the model, optimizer and loss function.\"\n",
    "    xb = self.dls.train.one_batch()[:self.dls.train.n_inp]\n",
    "    res = self.model.blurr_summary(*xb)\n",
    "    res += f\"Optimizer used: {self.opt_func}\\nLoss function: {self.loss_func}\\n\\n\"\n",
    "    if self.opt is not None:\n",
    "        res += f\"Model \" + (\"unfrozen\\n\\n\" if self.opt.frozen_idx==0 else f\"frozen up to parameter group number {self.opt.frozen_idx}\\n\\n\")\n",
    "    res += \"Callbacks:\\n\" + '\\n'.join(f\"  - {cb}\" for cb in sort_by_run(self.cbs))\n",
    "    return PrettyString(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to create our own `summary` methods above because fastai only works where things are represented by a *single tensor*.  But in the case of huggingface transformers, a *single* sequence is represented by *multiple tensors* (in a dictionary).  \n",
    "\n",
    "The change to make this work is so minor I think that the fastai library can/will hopefully be updated to support this use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=1.58489319801447e-07, lr_steep=0.010964781977236271)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.706807</td>\n",
       "      <td>0.648764</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.574071</td>\n",
       "      <td>0.555427</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500811</td>\n",
       "      <td>0.507838</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "And here we creat a @typedispatched impelmentation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_BaseInput, y, samples, outs, learner=None, ctxs=None, max_n=6, **kwargs):        \n",
    "    \n",
    "    if ctxs is None: ctxs = get_empty_df(min(len(samples), max_n))\n",
    "    ctxs = show_batch[object](x, y, samples, max_n=max_n, ctxs=ctxs, **kwargs)\n",
    "    \n",
    "    n_preds_per_input = len(outs[0])\n",
    "    if (n_preds_per_input == 1): \n",
    "        for i,ctx in enumerate(ctxs): ctx['target'] = outs[i][0]\n",
    "    else:\n",
    "        for pred_idx in range(n_preds_per_input):\n",
    "            for i,ctx in enumerate(ctxs):  ctx[f'target{pred_idx+1}'] = outs[i][pred_idx]\n",
    "\n",
    "    display_df(pd.DataFrame(ctxs))\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&lt;br /&gt;&lt;br /&gt;Stanley Holloway is excellent as the minor city politician who suddenly finds himself leading one of the world's tiniest nations. Dame Margaret Rutherford is a delight as the history professor who sides with Pimlico. Others in the stand-out cast include Hermione Baddeley, Paul Duplis, Naughton Wayne, Basil Radford &amp; Sir Michael Hordern.&lt;br /&gt;&lt;br /&gt;Welcome to Burgundy!</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As part of the celebration of the release of Casino Royale, this film with the new Bond starring in it was shown, from director Roger Michell (Notting Hill). I almost turned it off for being a bit boring, but I'm glad I stuck with it. Basically May (Anne Reid) is a single mother of Helen (Anna Wilson-Jones) who hardly sees anyone and has not had a boyfriend in years. Her daughter says that she might want to get married to her new boyfriend, Darren (Daniel Craig, of course). After knowing each other only a few days, May and Darren have a secret affair. And at her age, with a 30-something, and the new Bond?! Anyway, they obviously want to keep it a secret, but May has regrets and wonders if Helen will find out. When she does, Darren gets less hassle than May. In fact, Helen asks her permission to hit her. Also starring Peter Vaughan as Toots, Danira Govich as Au Pair, Harry Michell as Harry, Rosie Michell as Rosie and Johnny English's Oliver Ford Davies as Bruce. Very good!</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict(self:Learner, item, rm_type_tfms=None, with_input=False):\n",
    "    dl = self.dls.test_dl([item], rm_type_tfms=rm_type_tfms, num_workers=0)\n",
    "    \n",
    "    # this is where we have to change things up since a blurr \"input\" is represented by a dictionary of\n",
    "    # tensors (input_ids, attention_mask, token_type_ids, etc...) and not a single tensor (which fastai assumes\n",
    "    # in a number of places)\n",
    "    b = dl.one_batch()\n",
    "    inp = b[0]\n",
    "    preds, _, dec_preds = self.get_preds(dl=dl, with_input=False, with_decoded=True)\n",
    "    \n",
    "    i = getattr(self.dls, 'n_inp', -1)\n",
    "    inp = (inp,) if i==1 else tuplify(inp)\n",
    "    dec = self.dls.decode_batch(inp + tuplify(dec_preds))[0]\n",
    "    dec_inp,dec_targ = map(detuplify, [dec[:i],dec[i:]])\n",
    "    res = dec_targ,dec_preds[0],preds[0]\n",
    "    if with_input: res = (dec_inp,) + res\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as with `summary`, we need to replace fastai's `Learner.predict` method with the one above which is able to work with inputs that are represented by multiple tensors included in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('positive', tensor(1), tensor([0.4819, 0.5181]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict('I really liked the movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.352554</td>\n",
       "      <td>0.456833</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.137963</td>\n",
       "      <td>0.259805</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.085340</td>\n",
       "      <td>0.301668</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=slice(1e-6, 1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&lt;br /&gt;&lt;br /&gt;Stanley Holloway is excellent as the minor city politician who suddenly finds himself leading one of the world's tiniest nations. Dame Margaret Rutherford is a delight as the history professor who sides with Pimlico. Others in the stand-out cast include Hermione Baddeley, Paul Duplis, Naughton Wayne, Basil Radford &amp; Sir Michael Hordern.&lt;br /&gt;&lt;br /&gt;Welcome to Burgundy!</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I simply could not finish this movie. I tuned out after what I would say is my nomination for the most wretched attempt at sexual suggestion award: a scene in which Pia Zadora, at a picnic, stands between two boys who want her. One (the good boy) pleads for her to see the error of her ways. The other (the bad boy) simply asks if she'd like a hot dog, which he then holds out for her. At crotch level. I hope I'm not spoiling anything to say she turns, and takes the hot dog, with a smile. Just pathetic.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('positive', tensor(1), tensor([0.0733, 0.9267]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('negative', tensor(0), tensor([0.9968, 0.0032]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"Acting was so bad it was almost funny.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname='seq_class_learn_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('negative', tensor(0), tensor([0.9527, 0.0473]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname='seq_class_learn_export.pkl')\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('negative', tensor(0), tensor([0.9527, 0.0473]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the core training code above works for **all** pretrained sequence classification models available in huggingface.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained classification models you are working with ... and if any of your pretrained sequence classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.modeling_albert.AlbertForSequenceClassification,\n",
       " transformers.modeling_auto.AutoModelForSequenceClassification,\n",
       " transformers.modeling_bart.BartForSequenceClassification,\n",
       " transformers.modeling_bert.BertForSequenceClassification,\n",
       " transformers.modeling_camembert.CamembertForSequenceClassification,\n",
       " transformers.modeling_distilbert.DistilBertForSequenceClassification,\n",
       " transformers.modeling_electra.ElectraForSequenceClassification,\n",
       " transformers.modeling_flaubert.FlaubertForSequenceClassification,\n",
       " transformers.modeling_longformer.LongformerForSequenceClassification,\n",
       " transformers.modeling_mobilebert.MobileBertForSequenceClassification,\n",
       " transformers.modeling_roberta.RobertaForSequenceClassification,\n",
       " transformers.modeling_xlm.XLMForSequenceClassification,\n",
       " transformers.modeling_xlm_roberta.XLMRobertaForSequenceClassification,\n",
       " transformers.modeling_xlnet.XLNetForSequenceClassification]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLURR_MODEL_HELPER.get_models(task='SequenceClassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'albert-base-v1',\n",
    "    'facebook/bart-base',\n",
    "    'bert-base-uncased',\n",
    "    'camembert-base',\n",
    "    'distilbert-base-uncased',\n",
    "    'monologg/electra-small-finetuned-imdb',\n",
    "    'flaubert/flaubert_small_cased', \n",
    "    'allenai/longformer-base-4096',\n",
    "    'google/mobilebert-uncased',\n",
    "    'roberta-base',\n",
    "    'xlm-mlm-en-2048',\n",
    "    'xlm-roberta-base',\n",
    "    'xlnet-base-cased'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "\n",
    "model_path = Path('models')\n",
    "imdb_df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we can test XMLForSequenceClassification models\n",
    "remove_summary_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== albert-base-v1 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v1 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizer\n",
      "model:\t\tAlbertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.685780</td>\n",
       "      <td>0.662013</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post-war restrictions. merry mayhem is what would happen.br /br /the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall.br</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>by hook or by crook is a tremendously innovative film from a pair of immensely smart and talented filmmakers, harry dodge and silas howard. they manage to tell an original story in a distinctive cinematic style, and it's beautifully shot by ann t. rosetti, and wonderfully written -- truly poetic. br /br /the lead characters are true heroes and serve as a rare kind of role model/inspiration for butch dykes and trannies everywhere. this film has so much energy, so much poignant passion and scruffy san francisco heart to it.</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/bart-base were not used when initializing BartForSequenceClassification: ['final_logits_bias']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.weight', 'classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizer\n",
      "model:\t\tBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.674496</td>\n",
       "      <td>0.680782</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hmm, IMDb rating of 7.5, good comments, bla, bla... okay, two of my friends and me, we orderd Pizza, sat down and wanted to see something as cool as Ichi or at least something brainless but funny like Versus. But Naked Blood sucked. It's a complete waste. Okay, the scene with the woman who likes to eat is quite outstanding. But that's it. Nothing more, nothing less. I won't summerize the plot, other people did already, I just wanted to stop the hype. But watch it and rate for yourself. Maybe we can push</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bert-base-uncased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizer\n",
      "model:\t\tBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.660854</td>\n",
       "      <td>0.650020</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one of the joys of picking up the recent bela lugosi collection is getting to see delightful movies like the invisible ray. boris karloff and bela lugosi team up in a movie that delves into meteorites and radiation and while the science is all perfectly absurd ( especially the camera technique karloff, as janos rukh, uses to determine the site of a certain meteorite ) and downright laughable, i didn't care in the lease because the movie is thoroughly enjoyable. the effects are done well for the time, the acting is great, and the finish is particularly strong. it reminds me of</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizer\n",
      "model:\t\tCamembertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.684426</td>\n",
       "      <td>0.681060</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie is horrible- in a'so bad it's good' kind of way.&lt;br /&gt;&lt;br /&gt;The storyline is rehashed from so many other films of this kind, that I'm not going to even bother describing it. It's a sword/sorcery picture, has a kid hoping to realize how important he is in this world, has a \"nomadic\" adventurer, an evil aide/sorcerer, a princess, a hairy</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== distilbert-base-uncased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizer\n",
      "model:\t\tDistilBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.679733</td>\n",
       "      <td>0.691479</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this complete mess of a movie was directed by bill rebane, the man partly responsible for the truly infamous anti - classic monster a - go go. as i was nearing the end of the cold i came to the unbelievable conclusion that this film was in fact even worse than that 60's shocker. the story such as it is is about three eccentric millionaires who invite a group of people to their remote mansion to play a series of macabre games. whoever manages to last the pace and survive to the end will win $ 1, 000, 000. it's a very simple plot but rebane still</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== monologg/electra-small-finetuned-imdb ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/electra-small-finetuned-imdb were not used when initializing ElectraForSequenceClassification: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/electra-small-finetuned-imdb and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizer\n",
      "model:\t\tElectraForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.296752</td>\n",
       "      <td>0.316215</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>henri verneuil represented the commercial cinema in france from 1960 - 1980. always strong at the box - office, and usually telling dramatic and suspenseful tales of casino robberies, mafia score - settling and world war ii battles, verneuil could be counted on to give us two solid hours of entertainment on saturday night. he worked with the cream of the male actors of his day : gabin, belmondo, fernandel, delon, sharif, anthony quinn. i... comme icare is the only time he directed yves montand. it's an oddly static film, taking place mainly</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== flaubert/flaubert_small_cased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at flaubert/flaubert_small_cased were not used when initializing FlaubertForSequenceClassification: ['pred_layer.proj.bias', 'pred_layer.proj.weight']\n",
      "- This IS expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaubertForSequenceClassification were not initialized from the model checkpoint at flaubert/flaubert_small_cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "model:\t\tFlaubertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.766456</td>\n",
       "      <td>0.693509</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since for</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A beautiful shopgirl in London is swept off her feet by a millionaire tea plantation owner and soon finds herself married and living with him at his villa in British Ceylon. Although based upon the book by Robert Standish, this initial set-up is highly reminiscent of Hitchock' s \" Rebecca \", with leading lady Elizabeth Taylor clashing with the imposing chief of staff at the mansion and ( almost immediately ) her own husband, who is still under the thum</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/longformer-base-4096 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizer\n",
      "model:\t\tLongformerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.650738</td>\n",
       "      <td>0.641759</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The pre-release version of 1933's \"Baby Face\" would make an ideal introduction to a corporate seminar on sexual harassment. Mentored by a Nietszchean professor, Lily Powers rises from a life of easy virtue at her father's speakeasy to a rapid climb up the corporate ladder at a large bank. Because each rung of the ladder is an executive with his brain below his belt and his ethics locked in the vault, the film has no victims, except Lily's childhood, which was destroyed by an abusive exploitative father. The destructive relationship with her father suggests Lily's hidden motive for using men to advance</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mobilebert-uncased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizer\n",
      "model:\t\tMobileBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>240910.562500</td>\n",
       "      <td>12987.201172</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>salvage is the worst so called horror film i've ever seen. there is nothing remotely horrific about it. it doesn't deserve to be in a genre so fine. first of all i don't see how so many people can think this piece of crap such a great movie. if i wrote something as boring and utterly ridiculous as this i would be laughed at and too embarrassed to subject others to the stupidity of it. second : the acting is terrible and the lead actress is excruciatingly ugly. third : the story sucks, its been used before, and the excuse that its a cheap movie is no excuse</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizer\n",
      "model:\t\tRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.658109</td>\n",
       "      <td>0.649279</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Going into this I was expecting anything really good, but after the damage this inflexed on me, I'm just happy to think strait. It's hard to think what the film-makers( HA!) this was a good movie. the stories, and I use the world loosely, are incoherent and do make any sense at all. There just stupid things that happen at random. the acting, if can be called acting is horrible I've seen batter acting in toy ads! I know it's a low-budget video-bin garbages, but still even it's not like they tried. Will after st</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-en-2048 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-mlm-en-2048 were not used when initializing XLMForSequenceClassification: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLMForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMForSequenceClassification were not initialized from the model checkpoint at xlm-mlm-en-2048 and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "model:\t\tXLMForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.099294</td>\n",
       "      <td>1.126446</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post-war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt; br /</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for anyone who may not know what a one-actor movie was like, this is the best example. this plot is ridiculous, and really makes no sense. it's full of cliched situations, hackneyed lines, melodrama, comedy... you name it! &lt; br / &gt; &lt; br / &gt; but amitabh bachchan can make anything convincing, and this movie is by no means an exception. everyone turns in a decent performance - shashi kapoor, waheeda rehman, ranjit, om prakash, smita patil... but it is the megastar who overshadows everyone with his towering</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizer\n",
      "model:\t\tXLMRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.691910</td>\n",
       "      <td>0.681456</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Of the three titles from Jess Franco to find their way onto the Official DPP Video Nasty list (Devil Hunter, Bloody Moon and Women Behind Bars) this is perhaps the least deserving of notoriety, being a dreadfully dull jungle clunker enlivened only very slightly by a little inept gore, a gratuitous rape scene, and loads of nudity.&lt;br /&gt;&lt;br /&gt;Gorgeous blonde Ursula Buchfellner plays movie star Laura Crawford who is abducted by a gang of ruthless kidnappers</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizer\n",
      "model:\t\tXLNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.606295</td>\n",
       "      <td>0.582299</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a CGI animated film based upon a French 2D animated series. The series ran briefly on Cartoon Network, but its run was so brief that its inclusion as one of the potential Oscar nominees for best animated film for this year left most people I know going \"Huh?\" This is the story of Lian-Chu, the kind heart muscle, and Gwizdo, the brains of the operation, who along with Hector their fire farting dragon,he's more like a dog. Travel the world offering up their services as dragon hunters but never getting paid. Into their lives comes Zoe, the</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "test_results = []\n",
    "\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    del learn \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(model_name, \n",
    "                                                                                   task=task, \n",
    "                                                                                   config_kwargs={'num_labels': 2})\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n')\n",
    "\n",
    "    blocks = (HF_TextBlock(hf_arch=hf_arch, hf_tokenizer=hf_tokenizer, max_length=128), CategoryBlock)\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                       get_x=ColReader('text'), \n",
    "                       get_y=ColReader('label'), \n",
    "                       splitter=ColSplitter(col='is_valid'))\n",
    "    \n",
    "    dls = dblock.dataloaders(imdb_df, bs=4)\n",
    "    \n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    learn = Learner(dls, \n",
    "                    model,\n",
    "                    opt_func=partial(Adam, decouple_wd=True),\n",
    "                    loss_func=CrossEntropyLossFlat(),\n",
    "                    metrics=[accuracy],\n",
    "                    cbs=[HF_BaseModelCallback],\n",
    "                    splitter=hf_splitter)\n",
    "\n",
    "    learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "    learn.freeze()\n",
    "    \n",
    "    b = dls.one_batch()\n",
    "    \n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), 4)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([4, 128]))\n",
    "        test_eq(len(b[1]), 4)\n",
    "\n",
    "        print('*** TESTING One pass through the model ***')\n",
    "        preds = learn.model(b[0])\n",
    "        test_eq(len(preds[0]), 4)\n",
    "        test_eq(preds[0].shape, torch.Size([4, 2]))\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(max_n=2)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizer</td>\n",
       "      <td>AlbertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizer</td>\n",
       "      <td>BartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizer</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizer</td>\n",
       "      <td>CamembertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizer</td>\n",
       "      <td>DistilBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizer</td>\n",
       "      <td>ElectraForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizer</td>\n",
       "      <td>LongformerForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizer</td>\n",
       "      <td>MobileBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizer</td>\n",
       "      <td>RobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizer</td>\n",
       "      <td>XLMRobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizer</td>\n",
       "      <td>XLNetForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Multi-label classification\n",
    "\n",
    "Below demonstrates how to setup your `blurr` pipeline for a multi-label classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18049"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a dataset with the first 10% of training set\n",
    "raw_data = nlp.load_dataset('civil_comments', split='train[:1%]') \n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is such an urgent design problem; kudos to you for taking it on. Very impressive!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this something I'll be able to install on my site? When will you be releasing it?</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 text  \\\n",
       "0               This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!   \n",
       "1  Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!   \n",
       "2                              This is such an urgent design problem; kudos to you for taking it on. Very impressive!   \n",
       "3                                Is this something I'll be able to install on my site? When will you be releasing it?   \n",
       "4                                                                                haha you guys are a bunch of losers.   \n",
       "\n",
       "   toxicity  severe_toxicity  obscene  threat   insult  identity_attack  \\\n",
       "0  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "1  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "2  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "3  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "4  0.893617         0.021277      0.0     0.0  0.87234         0.021277   \n",
       "\n",
       "   sexual_explicit  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df = pd.DataFrame(raw_data, columns=list(raw_data.features.keys()))\n",
    "toxic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['severe_toxicity',\n",
       " 'obscene',\n",
       " 'threat',\n",
       " 'insult',\n",
       " 'identity_attack',\n",
       " 'sexual_explicit']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_cols = list(toxic_df.columns[2:]); lbl_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is such an urgent design problem; kudos to you for taking it on. Very impressive!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this something I'll be able to install on my site? When will you be releasing it?</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 text  \\\n",
       "0               This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!   \n",
       "1  Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!   \n",
       "2                              This is such an urgent design problem; kudos to you for taking it on. Very impressive!   \n",
       "3                                Is this something I'll be able to install on my site? When will you be releasing it?   \n",
       "4                                                                                haha you guys are a bunch of losers.   \n",
       "\n",
       "   toxicity  severe_toxicity  obscene  threat  insult  identity_attack  \\\n",
       "0  0.000000                0        0       0       0                0   \n",
       "1  0.000000                0        0       0       0                0   \n",
       "2  0.000000                0        0       0       0                0   \n",
       "3  0.000000                0        0       0       0                0   \n",
       "4  0.893617                0        0       0       1                0   \n",
       "\n",
       "   sexual_explicit  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df = toxic_df.round({col: 0 for col in lbl_cols})\n",
    "toxic_df = toxic_df.convert_dtypes()\n",
    "\n",
    "toxic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "\n",
    "pretrained_model_name = \"roberta-base\" # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = len(lbl_cols)\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we have to configure the `num_labels` to the number of labels we are predicting. Given that our labels are already encoded, we use a `MultiCategoryBlock` with `encoded=True` and `vocab` equal to the columns with our 1's and 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "blocks = (\n",
    "    HF_TextBlock(hf_arch=hf_arch, hf_tokenizer=hf_tokenizer), \n",
    "    MultiCategoryBlock(encoded=True, vocab=lbl_cols)\n",
    ")\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('text'), get_y=ColReader(lbl_cols), \n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(toxic_df, bs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([8, 512]), torch.Size([8, 6]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ignore Glenn Beck he feeds off of attention, so don't talk about him.  I personally feel he is unstable and should be evaluated for mental health problems before he's allowed to speak in public  about anything.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok...you got me!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                loss_func=BCEWithLogitsLossFlat(),\n",
    "                metrics=[partial(accuracy_multi, thresh=0.2)],\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "learn.loss_func.thresh = 0.2\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're doing multi-label classification, we adjust our loss function to use binary cross-entropy and our metrics to use the multi-label friendly version of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(b[0])\n",
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.012022644281387329, lr_steep=0.0012022644514217973)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>0.038060</td>\n",
       "      <td>0.992149</td>\n",
       "      <td>05:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.035029</td>\n",
       "      <td>0.031046</td>\n",
       "      <td>0.991964</td>\n",
       "      <td>05:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.022359</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.992334</td>\n",
       "      <td>05:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>None</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I actually saw a photo today of Lauren B and Ben digging into two huge boxes of VooDoo Doughnuts during their date. So there's that? \\n\\nI'd hunt down the link to the photo but my life is rich and full and also I have to go watch me some Vanderpump Rules right now.</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ah, so you're a conservative passionately opposed to unions, i.e. workers rights.\\nIt appears you managed to get those degrees without a proper understanding (a tad shocking for an attorney) of \"freedom of speech.\"</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func.thresh = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((#1) ['insult'],\n",
       " tensor([False, False, False,  True, False, False]),\n",
       " tensor([3.9826e-07, 6.8941e-03, 7.0448e-05, 5.2467e-02, 4.6344e-03, 1.4144e-03]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"\"\"\n",
    "Those damned affluent white people should only eat their own food, like cod cakes and boiled potatoes. \n",
    "No enchiladas for them!\n",
    "\"\"\"\n",
    "learn.blurr_predict(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-language-modeling.ipynb.\n",
      "Converted 01c_data-question-answering.ipynb.\n",
      "Converted 01d_data-token-classification.ipynb.\n",
      "Converted 01e_data-summarization.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-language-modeling.ipynb.\n",
      "Converted 02c_modeling-question-answering.ipynb.\n",
      "Converted 02d_modeling-token-classification.ipynb.\n",
      "Converted 02e_modeling-text-generation.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
