{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.core\n",
    "\n",
    "> This module contains core custom models, loss functions, and a default layer group splitter for use in applying discriminiative learning rates to your huggingface models trained via fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, nlp\n",
    "from transformers import *\n",
    "\n",
    "from fastai2.text.all import *\n",
    "from fastai2.callback.hook import _print_shapes\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base splitter, model wrapper, and model callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hf_splitter(m):\n",
    "    \"\"\"Splits the huggingface model based on various model architecture conventions\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, 'hf_model')) else m\n",
    "    root_modules = list(model.named_children())\n",
    "    top_module_name, top_module = root_modules[0]\n",
    "    \n",
    "    groups = L([ m for m_name, m in list(top_module.named_children()) ])\n",
    "    groups += L([ m for m_name, m in root_modules[1:] ])\n",
    "\n",
    "    return groups.map(params).filter(lambda el: len(el) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"hf_splitter\" class=\"doc_header\"><code>hf_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>hf_splitter</code>(**`m`**)\n",
       "\n",
       "Splits the huggingface model based on various model architecture conventions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(hf_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_BaseModelWrapper(Module):\n",
    "    def __init__(self, hf_model):\n",
    "        super().__init__()\n",
    "        self.hf_model = hf_model.cuda() if torch.cuda.is_available() else hf_model\n",
    "        \n",
    "        n_fwd_args = self.hf_model.forward.__code__.co_argcount\n",
    "        self.hf_model_fwd_args = self.hf_model.forward.__code__.co_varnames[:n_fwd_args][1:]\n",
    "        \n",
    "    def forward(self, x): \n",
    "        for k in list(x): \n",
    "            if k not in self.hf_model_fwd_args: del x[k]         \n",
    "                \n",
    "        return self.hf_model(**x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `HF_baseModelWrapper` includes some nifty code for just passing in the things your model needs, as not all transformer architectures require/use the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_BaseModelCallback(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a `Callback` for handling what is returned from the huggingface model ... \"the huggingface model will return a tuple in outputs, with the actual predictions and some additional activations (should we want to use them is some regularization scheme)\" - from the fastai [Transformer's Tutorial](http://dev.fast.ai/tutorial.transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence classification\n",
    "\n",
    "Below demonstrates how to setup your `blurr` pipeline for a sequence classification task (e.g., a model that requires a single text input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "imdb_df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.&lt;br /&gt;&lt;br /&gt;But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.&lt;br /&gt;&lt;br /&gt;Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.&lt;br /&gt;&lt;br /&gt;Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  \\\n",
       "0  negative   \n",
       "1  positive   \n",
       "2  negative   \n",
       "3  positive   \n",
       "4  negative   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                    Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!   \n",
       "1  This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...   \n",
       "2  Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.<br /><br />Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...   \n",
       "3  Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.<br /><br />Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...   \n",
       "4  This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "\n",
    "pretrained_model_name = \"roberta-base\" # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "blocks = (HF_TextBlock(hf_arch=hf_arch, hf_tokenizer=hf_tokenizer, padding='max_length'), CategoryBlock)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('text'), get_y=ColReader('label'), \n",
    "                   splitter=ColSplitter(col='is_valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(imdb_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That Certain Thing is the story of a gold digger (Viola Dana) from a tenement house. Her mother uses her to take care of her two brothers, but they are a loving family. Although Dana's character has the opportunity to marry a streetcar conductor, she refuses and holds out for a millionaire. Everyone makes fun of her for her fantasy, but are surprised when one day she really does meet a millionaire, son of the owner of the popular ABC restaurant chain. The two marry hastily, but the girl's dreams of wealth are shattered when the rich father disowns his son for marrying a gold digger. However, she truly loves her new husband and the two are unexpectedly successful at making it on their own.&lt;br /&gt;&lt;br /&gt;A rare glimpse of movie star Viola Dana, this film is a lot of fun. Dana's role is accessible, natural, and entertaining. She displays a knack for comedy as well as an ability to do drama.&lt;br /&gt;&lt;br /&gt;The mechanics of the film are a lot of fun too. The camera displays sophisticated late silent techniques like mobility. The title cards are also incredibly clever.&lt;br /&gt;&lt;br /&gt;If you like films like My Best Girl, It, or The Patsy, you will enjoy this film.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We'll also add in custom summary methods for blurr learners/models that work with dictionary inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                loss_func=CrossEntropyLossFlat(),\n",
    "                metrics=[accuracy],\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.to_fp16()` requires a GPU so had to remove for tests to run on github.  Let's check that we can get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0598, 0.0394],\n",
       "         [0.0459, 0.0303],\n",
       "         [0.0461, 0.0393],\n",
       "         [0.0603, 0.0460]], device='cuda:1', grad_fn=<AddmmBackward>),)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_summary(self:nn.Module, *xb):\n",
    "    \"Print a summary of `self` using `xb`\"\n",
    "    sample_inputs,infos = layer_info(self, *xb)\n",
    "    n,bs = 64,find_bs(xb)\n",
    "    inp_sz = _print_shapes(apply(lambda x:x.shape, xb[0]['input_ids']), bs)\n",
    "    res = f\"{self.__class__.__name__} (Input shape: {inp_sz})\\n\"\n",
    "    res += \"=\" * n + \"\\n\"\n",
    "    res += f\"{'Layer (type)':<20} {'Output Shape':<20} {'Param #':<10} {'Trainable':<10}\\n\"\n",
    "    res += \"=\" * n + \"\\n\"\n",
    "    ps,trn_ps = 0,0\n",
    "    infos = [o for o in infos if o is not None] #see comment in previous cell\n",
    "    for typ,np,trn,sz in infos:\n",
    "        if sz is None: continue\n",
    "        ps += np\n",
    "        if trn: trn_ps += np\n",
    "        res += f\"{typ:<20} {_print_shapes(sz, bs)[:19]:<20} {np:<10,} {str(trn):<10}\\n\"\n",
    "        res += \"_\" * n + \"\\n\"\n",
    "    res += f\"\\nTotal params: {ps:,}\\n\"\n",
    "    res += f\"Total trainable params: {trn_ps:,}\\n\"\n",
    "    res += f\"Total non-trainable params: {ps - trn_ps:,}\\n\\n\"\n",
    "    return PrettyString(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_summary(self:Learner):\n",
    "    \"Print a summary of the model, optimizer and loss function.\"\n",
    "    xb = self.dls.train.one_batch()[:self.dls.train.n_inp]\n",
    "    res = self.model.blurr_summary(*xb)\n",
    "    res += f\"Optimizer used: {self.opt_func}\\nLoss function: {self.loss_func}\\n\\n\"\n",
    "    if self.opt is not None:\n",
    "        res += f\"Model \" + (\"unfrozen\\n\\n\" if self.opt.frozen_idx==0 else f\"frozen up to parameter group number {self.opt.frozen_idx}\\n\\n\")\n",
    "    res += \"Callbacks:\\n\" + '\\n'.join(f\"  - {cb}\" for cb in sort_by_run(self.cbs))\n",
    "    return PrettyString(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to create our own `summary` methods above because fastai only works where things are represented by a *single tensor*.  But in the case of huggingface transformers, a *single* sequence is represented by *multiple tensors* (in a dictionary).  \n",
    "\n",
    "The change to make this work is so minor I think that the fastai library can/will hopefully be updated to support this use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=6.918309954926372e-05, lr_steep=0.0030199517495930195)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.447952</td>\n",
       "      <td>0.266641</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.249425</td>\n",
       "      <td>0.223455</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.146838</td>\n",
       "      <td>0.237296</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "And here we creat a @typedispatched impelmentation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_BaseInput, y, samples, outs, learner=None, ctxs=None, max_n=6, **kwargs):        \n",
    "    \n",
    "    if ctxs is None: ctxs = get_empty_df(min(len(samples), max_n))\n",
    "    ctxs = show_batch[object](x, y, samples, max_n=max_n, ctxs=ctxs, **kwargs)\n",
    "    \n",
    "    n_preds_per_input = len(outs[0])\n",
    "    if (n_preds_per_input == 1): \n",
    "        for i,ctx in enumerate(ctxs): ctx['target'] = outs[i][0]\n",
    "    else:\n",
    "        for pred_idx in range(n_preds_per_input):\n",
    "            for i,ctx in enumerate(ctxs):  ctx[f'target{pred_idx+1}'] = outs[i][pred_idx]\n",
    "\n",
    "    display_df(pd.DataFrame(ctxs))\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&lt;br /&gt;&lt;br /&gt;Stanley Holloway is excellent as the minor city politician who suddenly finds himself leading one of the world's tiniest nations. Dame Margaret Rutherford is a delight as the history professor who sides with Pimlico. Others in the stand-out cast include Hermione Baddeley, Paul Duplis, Naughton Wayne, Basil Radford &amp; Sir Michael Hordern.&lt;br /&gt;&lt;br /&gt;Welcome to Burgundy!</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This sure is one comedy I'm not likely to forget for a while.&lt;br /&gt;&lt;br /&gt;Wouldn't normally bother to comment on this movie: it's so minor that no one would watch it anyway, but as it happens, it's kind of popular in p2p sharing networks such as Kazaa, and so this saaad production needs to be exposed for what it is.&lt;br /&gt;&lt;br /&gt;So what is it then? Well, of course it's not really a comedy; instead, it's intended as a horror flick -- \"intended\" very much being the key word here. The script is a totally incoherent and unbalanced mess, the special effects are only special in that they're especially pathetic, and as for the acting, well, let's just say that if this had been my graduating play at primary school, my teachers would have burst out crying at our talent.&lt;br /&gt;&lt;br /&gt;Of course I realise that this is a very low budget film and that in those cases one should lower one's expectations, certainly as far as things like special effects are concerned. Also, even though I'm a big fan of the horror genre, I'm aware that these movies are only rarely the places to look for interesting scripts and top notch acting.&lt;br /&gt;&lt;br /&gt;But still.&lt;br /&gt;&lt;br /&gt;B-movies often have some redeeming features to make up for the lack of funding, such as humour. The only laughs in Cradle to Fear lie in the ridiculous performances. If you can find the humour in that--and I could for the first 20 minutes or so, gradually dozing off after that--then that's going to be the only thing the movie has to offer. Oh, that and two or three pairs of breasts.&lt;br /&gt;&lt;br /&gt;Woohoo, how exciting.&lt;br /&gt;&lt;br /&gt;As for the story, it's not even that it doesn't try to convey anything: the victims either use drugs and/or are involved in serious crime. The lesson: Watch out, naughty boys and girls, because one day you'll be made to pay for what you've done.&lt;br /&gt;&lt;br /&gt;I rest my case.&lt;br /&gt;&lt;br /&gt;So, all in all, a little bit of sex, a fair amount of drugs, but absolutely zero rock 'n roll.&lt;br /&gt;&lt;br /&gt;I rate this one 1 out of 10, but would go to 0 if I could. Or perhaps I wouldn't: it deserves</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict(self:Learner, item, rm_type_tfms=None, with_input=False):\n",
    "    dl = self.dls.test_dl([item], rm_type_tfms=rm_type_tfms, num_workers=0)\n",
    "    \n",
    "    # this is where we have to change things up since a blurr \"input\" is represented by a dictionary of\n",
    "    # tensors (input_ids, attention_mask, token_type_ids, etc...) and not a single tensor (which fastai assumes\n",
    "    # in a number of places)\n",
    "    b = dl.one_batch()\n",
    "    inp = b[0]\n",
    "    preds, _, dec_preds = self.get_preds(dl=dl, with_input=False, with_decoded=True)\n",
    "    \n",
    "    i = getattr(self.dls, 'n_inp', -1)\n",
    "    inp = (inp,) if i==1 else tuplify(inp)\n",
    "    dec = self.dls.decode_batch(inp + tuplify(dec_preds))[0]\n",
    "    dec_inp,dec_targ = map(detuplify, [dec[:i],dec[i:]])\n",
    "    res = dec_targ,dec_preds[0],preds[0]\n",
    "    if with_input: res = (dec_inp,) + res\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as with `summary`, we need to replace fastai's `Learner.predict` method with the one above which is able to work with inputs that are represented by multiple tensors included in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('positive', tensor(1), tensor([0.0653, 0.9347]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict('I really liked the movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.212975</td>\n",
       "      <td>0.415499</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.153193</td>\n",
       "      <td>0.295674</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.098641</td>\n",
       "      <td>0.268445</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=slice(1e-6, 1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&lt;br /&gt;&lt;br /&gt;Stanley Holloway is excellent as the minor city politician who suddenly finds himself leading one of the world's tiniest nations. Dame Margaret Rutherford is a delight as the history professor who sides with Pimlico. Others in the stand-out cast include Hermione Baddeley, Paul Duplis, Naughton Wayne, Basil Radford &amp; Sir Michael Hordern.&lt;br /&gt;&lt;br /&gt;Welcome to Burgundy!</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Following the disasterous Revolution, this film was pretty much the final nail in the coffin of Goldcrest and thus the British Film Industry. The film is absolute pants, it's full of music from the attempted mid-80's jazz revival and based on a book &amp; author that was briefly popular at that time and has deservedly sank back into obscurity. Temple searched for ages trying to find Suzette and came up with 8th Wonders Patsy Kensett another person who was briefly popular at the time. By the time the film came out of post production the Jazz revival was over, as was Kensett's career and the film met a totally uncaring film public.&lt;br /&gt;&lt;br /&gt;Mediocre would be an overstatement for some of the worst/campest/cheesiest acting to ever grace the British silver screen watching it almost 20 years on and the film is truely cringeworthy.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('positive', tensor(1), tensor([0.0048, 0.9952]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('negative', tensor(0), tensor([0.9984, 0.0016]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"Acting was so bad it was almost funny.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname='seq_class_learn_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('negative', tensor(0), tensor([0.9919, 0.0081]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname='seq_class_learn_export.pkl')\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the core training code above works for **all** pretrained sequence classification models available in huggingface.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained classification models you are working with ... and if any of your pretrained sequence classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.modeling_albert.AlbertForSequenceClassification,\n",
       " transformers.modeling_auto.AutoModelForSequenceClassification,\n",
       " transformers.modeling_bart.BartForSequenceClassification,\n",
       " transformers.modeling_bert.BertForSequenceClassification,\n",
       " transformers.modeling_camembert.CamembertForSequenceClassification,\n",
       " transformers.modeling_distilbert.DistilBertForSequenceClassification,\n",
       " transformers.modeling_electra.ElectraForSequenceClassification,\n",
       " transformers.modeling_flaubert.FlaubertForSequenceClassification,\n",
       " transformers.modeling_longformer.LongformerForSequenceClassification,\n",
       " transformers.modeling_mobilebert.MobileBertForSequenceClassification,\n",
       " transformers.modeling_roberta.RobertaForSequenceClassification,\n",
       " transformers.modeling_xlm.XLMForSequenceClassification,\n",
       " transformers.modeling_xlm_roberta.XLMRobertaForSequenceClassification,\n",
       " transformers.modeling_xlnet.XLNetForSequenceClassification]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLURR_MODEL_HELPER.get_models(task='SequenceClassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'albert-base-v1',\n",
    "    'facebook/bart-base',\n",
    "    'bert-base-uncased',\n",
    "    'camembert-base',\n",
    "    'distilbert-base-uncased',\n",
    "    'monologg/electra-small-finetuned-imdb',\n",
    "    'flaubert/flaubert_small_cased', \n",
    "    'allenai/longformer-base-4096',\n",
    "    'google/mobilebert-uncased',\n",
    "    'roberta-base',\n",
    "    'xlm-mlm-en-2048',\n",
    "    'xlm-roberta-base',\n",
    "    'xlnet-base-cased'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "\n",
    "model_path = Path('models')\n",
    "imdb_df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== albert-base-v1 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v1 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizer\n",
      "model:\t\tAlbertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.663266</td>\n",
       "      <td>0.647257</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post-war restrictions. merry mayhem is what would happen.br /br /the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall.br</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>someone has already mentioned \"being at the right time at the right place\" it was so true for this documentary that i had doubts about the genuineness of the scenes and thought it included perhaps some acting but it is not. it is all real. the story is nothing new for the people of the developing and/or poor countries. it sheds light on the manipulation of the people by corporate media, the misinformation, the artificial polarization of the people by deliberately creating tension on the streets, sometimes to the point that the army, intelligence agency or even the government(many believe,led by the us) uses agents who</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/bart-base were not used when initializing BartForSequenceClassification: ['final_logits_bias']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.weight', 'classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizer\n",
      "model:\t\tBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.369171</td>\n",
       "      <td>0.426324</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wow! Stacy Peralta has followed up Dogtown and Z-Boys with an equally stunning documentary about the history of the big-wave surfing culture in America. Piecing together insider archival footage along with interviews from surfing legends, we are transported into the daring and free-spirited life of the early pioneers whose sheer passion for the sport spawned an industry that today touches the lives of millions.&lt;br /&gt;&lt;br /&gt;It's getting to know these icons and their stories that gives the film its warmth. You can feel the respect Peralta has for this group as we hear accounts of Greg Noll striding from</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bert-base-uncased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizer\n",
      "model:\t\tBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.470769</td>\n",
       "      <td>0.508828</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this has to be the cheapest film made in 21st century. it is all the way low quality, but at the end it falls below... everything. all the cheap tricks - like flashing and darkness - are used to hide those crappy computer effects. &lt; br / &gt; &lt; br / &gt; all the actors are below average, especially the main character anne fletcher ( simmone mackinnon ). there is a scene, where anne is asked : \" why you seem so careless? \" the correct answer is, because she can't act. no matter what happens ( the world is about to be destroyed,</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizer\n",
      "model:\t\tCamembertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.690805</td>\n",
       "      <td>0.690891</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How viewers react to this new \"adaption\" of Shirley Jackson's book, which was promoted as NOT being a remake of the original 1963 movie (true enough), will be based, I suspect, on the following: those who were big fans of either the book or original movie are not going to think much of this one...and those who have never been exposed to either, and who are big fans of Hollywood's current trend towards \"special eff</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== distilbert-base-uncased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizer\n",
      "model:\t\tDistilBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.476771</td>\n",
       "      <td>0.498461</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i never understood why some people dislike bollywood films : they've got charismatic actors, great dance numbers, and heightened emotion - - what's not to like? what i didn't realize was that i had only seen the upper - crust of bollywood. then i watched \" garam masala \". i could tell from the first scene that this was not a movie i was going to like ( the film opens with a montage of the two leads driving around a city and apparently happening serendipitously on a series of photo setups populated with gyrating models ), but i kept hoping things would improve</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== monologg/electra-small-finetuned-imdb ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/electra-small-finetuned-imdb were not used when initializing ElectraForSequenceClassification: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/electra-small-finetuned-imdb and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizer\n",
      "model:\t\tElectraForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.196735</td>\n",
       "      <td>0.305599</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>those who have given this production such a low rating probably have never seen the celebrated george balanchine production live onstage, or are letting their disdain for the star casting of macaulay culkin influence their judgement. the atlanta ballet was fortunate enough, from the 1960's to the 1980's, to be the first ballet company authorized to stage this production other than the new york city ballet, and i have seen it live onstage several times. i can assure readers that the film is a quite accurate rendering of this production, and that the use of a child with limited dancing abilities in the title role is not a cheap stunt</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== flaubert/flaubert_small_cased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at flaubert/flaubert_small_cased were not used when initializing FlaubertForSequenceClassification: ['pred_layer.proj.bias', 'pred_layer.proj.weight']\n",
      "- This IS expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaubertForSequenceClassification were not initialized from the model checkpoint at flaubert/flaubert_small_cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "model:\t\tFlaubertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.700924</td>\n",
       "      <td>0.696990</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since for</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I really wanted to like this movie - the location shots were mostly filmed in Pittsburgh and the trailer had some wonderful photography. But, even for a filmed cartoon, it was a really badly-made movie. The continuity and pacing were both simply awful. The best bits in the movie are under the ending credits, so it' s ( almost ) worth sticking it out to the end ( though, oddly, it does pick up a little over the last half h</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/longformer-base-4096 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizer\n",
      "model:\t\tLongformerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.356499</td>\n",
       "      <td>0.385995</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>02:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Possible spoilers re: late-appearing cameos &lt;br /&gt;&lt;br /&gt;Seldom does one see so many fine &amp; memorable character actors (almost entirely actresses to be precise) in one film. Even though a few only appear for cameos, each one is a gem. The British do this mix of comedy and real-life pathos better than anyone IMO, so it is no surprise that most of the actors are Brits.&lt;br /&gt;&lt;br /&gt;The music is great; no doubt much had to be dubbed (does Leslie Caron *really* play the bass so well? maybe - who knew?) But</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mobilebert-uncased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizer\n",
      "model:\t\tMobileBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>157189.312500</td>\n",
       "      <td>70476.671875</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a beautiful shopgirl in london is swept off her feet by a millionaire tea plantation owner and soon finds herself married and living with him at his villa in british ceylon. although based upon the book by robert standish, this initial set - up is highly reminiscent of hitchock's \" rebecca \", with leading lady elizabeth taylor clashing with the imposing chief of staff at the mansion and ( almost immediately ) her own husband, who is still under the thumb of his deceased - but - dominant father. taylor, a last - minute substitute for an ailing vivien leigh, looks creamy - smooth in her high fashion wardrobe,</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizer\n",
      "model:\t\tRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.396376</td>\n",
       "      <td>0.432945</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Of the elements that make this the best at this point, I have to say #1 is Christine McIntire. Shemp's scene when poisoned and her reaction are truly magnificent. I imagine that, as one poster suggested, Christine was trying to hold back laughter during that scene, but it actually made her seem even more deliciously evil, to be smiling at Shemp's possibly dying.&lt;br /&gt;&lt;br /&gt;Another character who helps this stand out is the Goon. His look was a great cross between horrific and comedic goof-ball. Hardly a character I would choose to meet in a dark alley or, for that</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-en-2048 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-mlm-en-2048 were not used when initializing XLMForSequenceClassification: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLMForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMForSequenceClassification were not initialized from the model checkpoint at xlm-mlm-en-2048 and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "model:\t\tXLMForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0.883580</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post-war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt; br /</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in 17th century japan, there lived a samurai who would set the standard for the ages. his name was mayeda. he is sent on an epic journey across the world to acquire 5,000 muscats from the king of spain. whilst at sea a violent storm swallows their precious gold intended to buy the weapons and almost takes their lives. mayeda must battle all odds to survive and the secure the fate of his beloved japan. shogun mayeda is a multi million dollar action adventure epic set across three continents. &lt; br / &gt; &lt; br / &gt; starring cinema legends sho kosugi ( tenchu : stealth assassins ),</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizer\n",
      "model:\t\tXLMRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.711807</td>\n",
       "      <td>0.686050</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forget the campy'religious' movies that have monopolized the television/film market... this movie has a real feel to it. While it may be deemed as a movie that has cheap emotional draws, it also has that message of forgiveness, and overall good morals. However, I did not like the lighting in this movie... for a movie dealing with such subject matter, it was too bright. I felt it took away from the overall appeal of the movie, which is almost an unforgivable sin, but the recognizable cast, and their performances counteract this</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizer\n",
      "model:\t\tXLNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/transformers/modeling_xlnet.py:283: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
      "  attn_score = (ac + bd + ef) * self.scale\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.536080</td>\n",
       "      <td>0.523089</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Come on. The new twist is nearly ok, but from avenging the Elm Street children Freddy is just killing people now. More of the same: Special effects with no actual character development or anything. Simply bad and insulting. SCARY..? Nope. Not at all. Just bad.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "bsz = 2\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    del learn; torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(model_name, \n",
    "                                                                                   task=task, \n",
    "                                                                                   config_kwargs={'num_labels': 2})\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n')\n",
    "\n",
    "    blocks = (HF_TextBlock(hf_arch=hf_arch, hf_tokenizer=hf_tokenizer, max_length=128, padding='max_length'), \n",
    "              CategoryBlock)\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                       get_x=ColReader('text'), \n",
    "                       get_y=ColReader('label'), \n",
    "                       splitter=ColSplitter(col='is_valid'))\n",
    "    \n",
    "    dls = dblock.dataloaders(imdb_df, bs=bsz)\n",
    "    \n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    learn = Learner(dls, \n",
    "                    model,\n",
    "                    opt_func=partial(Adam, decouple_wd=True),\n",
    "                    loss_func=CrossEntropyLossFlat(),\n",
    "                    metrics=[accuracy],\n",
    "                    cbs=[HF_BaseModelCallback],\n",
    "                    splitter=hf_splitter)\n",
    "\n",
    "    learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "    learn.freeze()\n",
    "    \n",
    "    b = dls.one_batch()\n",
    "    \n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***')\n",
    "        test_eq(len(b), bsz)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, 128]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        print('*** TESTING One pass through the model ***')\n",
    "        preds = learn.model(b[0])\n",
    "        test_eq(len(preds[0]), bsz)\n",
    "        test_eq(preds[0].shape, torch.Size([bsz, 2]))\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(max_n=2)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "        \n",
    "# cleanup\n",
    "del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizer</td>\n",
       "      <td>AlbertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizer</td>\n",
       "      <td>BartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizer</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizer</td>\n",
       "      <td>CamembertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizer</td>\n",
       "      <td>DistilBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizer</td>\n",
       "      <td>ElectraForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizer</td>\n",
       "      <td>LongformerForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizer</td>\n",
       "      <td>MobileBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizer</td>\n",
       "      <td>RobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizer</td>\n",
       "      <td>XLMRobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizer</td>\n",
       "      <td>XLNetForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Multi-label classification\n",
    "\n",
    "Below demonstrates how to setup your `blurr` pipeline for a multi-label classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f154ea4e2544a759310ad6d6ff06463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=6079.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset civil_comments/default (download: 395.73 MiB, generated: 630.60 MiB, post-processed: Unknown sizetotal: 1.00 GiB) to /home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/0ff455d7d5922889535d7da8c0414554daecf6c6e285dacbd7da4ae2516e6cbc...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset civil_comments downloaded and prepared to /home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/0ff455d7d5922889535d7da8c0414554daecf6c6e285dacbd7da4ae2516e6cbc. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18049"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a dataset with the first 10% of training set\n",
    "raw_data = nlp.load_dataset('civil_comments', split='train[:1%]') \n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is such an urgent design problem; kudos to you for taking it on. Very impressive!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this something I'll be able to install on my site? When will you be releasing it?</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 text  \\\n",
       "0               This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!   \n",
       "1  Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!   \n",
       "2                              This is such an urgent design problem; kudos to you for taking it on. Very impressive!   \n",
       "3                                Is this something I'll be able to install on my site? When will you be releasing it?   \n",
       "4                                                                                haha you guys are a bunch of losers.   \n",
       "\n",
       "   toxicity  severe_toxicity  obscene  threat   insult  identity_attack  \\\n",
       "0  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "1  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "2  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "3  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "4  0.893617         0.021277      0.0     0.0  0.87234         0.021277   \n",
       "\n",
       "   sexual_explicit  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df = pd.DataFrame(raw_data, columns=list(raw_data.features.keys()))\n",
    "toxic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['severe_toxicity',\n",
       " 'obscene',\n",
       " 'threat',\n",
       " 'insult',\n",
       " 'identity_attack',\n",
       " 'sexual_explicit']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_cols = list(toxic_df.columns[2:]); lbl_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is such an urgent design problem; kudos to you for taking it on. Very impressive!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this something I'll be able to install on my site? When will you be releasing it?</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 text  \\\n",
       "0               This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!   \n",
       "1  Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!   \n",
       "2                              This is such an urgent design problem; kudos to you for taking it on. Very impressive!   \n",
       "3                                Is this something I'll be able to install on my site? When will you be releasing it?   \n",
       "4                                                                                haha you guys are a bunch of losers.   \n",
       "\n",
       "   toxicity  severe_toxicity  obscene  threat  insult  identity_attack  \\\n",
       "0  0.000000                0        0       0       0                0   \n",
       "1  0.000000                0        0       0       0                0   \n",
       "2  0.000000                0        0       0       0                0   \n",
       "3  0.000000                0        0       0       0                0   \n",
       "4  0.893617                0        0       0       1                0   \n",
       "\n",
       "   sexual_explicit  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df = toxic_df.round({col: 0 for col in lbl_cols})\n",
    "toxic_df = toxic_df.convert_dtypes()\n",
    "\n",
    "toxic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "\n",
    "pretrained_model_name = \"roberta-base\" # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = len(lbl_cols)\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we have to configure the `num_labels` to the number of labels we are predicting. Given that our labels are already encoded, we use a `MultiCategoryBlock` with `encoded=True` and `vocab` equal to the columns with our 1's and 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "blocks = (\n",
    "    HF_TextBlock(hf_arch=hf_arch, hf_tokenizer=hf_tokenizer), \n",
    "    MultiCategoryBlock(encoded=True, vocab=lbl_cols)\n",
    ")\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('text'), get_y=ColReader(lbl_cols), \n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(toxic_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([4, 236]), torch.Size([4, 6]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I think it's reasonable and valid for each councilor to have their own private workspace.  looking ahead a bit, as the area grows...I would think an 8'x7' office is proportionate and appropriate.  if they can do a window in each - bonus.   there will be meeting rooms built into the plans already, so that handles too crowded office meetings. no additional support staff - they resource whoever they use now.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You do know that both Russia and China will do more business in Iran without the sanctions, don't you?  I do not agree that this 'is obviously valuable' anymore than the North Korean appeasements were 'obviously valuable' by Clinton or Bush.  We have seen'moderate Iran' before; the theocracy stomped on them then and have the power to do it again.  The'recent elections' were still limited by the mullahs as to how many and which candidates were even permitted to run for election.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                loss_func=BCEWithLogitsLossFlat(),\n",
    "                metrics=[partial(accuracy_multi, thresh=0.2)],\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "learn.loss_func.thresh = 0.2\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're doing multi-label classification, we adjust our loss function to use binary cross-entropy and our metrics to use the multi-label friendly version of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(b[0])\n",
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.00831763744354248, lr_steep=1.3182567358016968)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.030598</td>\n",
       "      <td>0.031859</td>\n",
       "      <td>0.993857</td>\n",
       "      <td>03:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.048436</td>\n",
       "      <td>0.033644</td>\n",
       "      <td>0.993857</td>\n",
       "      <td>03:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.029388</td>\n",
       "      <td>0.032032</td>\n",
       "      <td>0.993857</td>\n",
       "      <td>03:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>None</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've been collecting Stickley for years...and each piece looks as good as the day I acquired it...the craftsmanship and finish is amazing...\\nStickley is truly heirloom quality...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why are you supporting a New yorker who is stealing barbecue culture and who has the gall to run it on MLK right in the art of gentrification!</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func.thresh = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((#1) ['severe_toxicity'],\n",
       " tensor([False, False, False,  True, False, False]),\n",
       " tensor([1.9676e-06, 4.8389e-03, 4.5106e-05, 2.8335e-02, 1.3351e-03, 1.6474e-03]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"\"\"\n",
    "Those damned affluent white people should only eat their own food, like cod cakes and boiled potatoes. \n",
    "No enchiladas for them!\n",
    "\"\"\"\n",
    "learn.blurr_predict(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-language-modeling.ipynb.\n",
      "Converted 01c_data-question-answering.ipynb.\n",
      "Converted 01d_data-token-classification.ipynb.\n",
      "Converted 01e_data-summarization.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-language-modeling.ipynb.\n",
      "Converted 02c_modeling-question-answering.ipynb.\n",
      "Converted 02d_modeling-token-classification.ipynb.\n",
      "Converted 02e_modeling-summarization.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
