{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.core\n",
    "\n",
    "> This module contains core custom models, loss functions, and a default layer group splitter for use in applying discriminiative learning rates to your huggingface models trained via fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, nlp\n",
    "from transformers import *\n",
    "\n",
    "from fastai.text.all import *\n",
    "from fastai.callback.hook import _print_shapes\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base splitter, model wrapper, and model callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hf_splitter(m):\n",
    "    \"\"\"Splits the huggingface model based on various model architecture conventions\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, 'hf_model')) else m\n",
    "    root_modules = list(model.named_children())\n",
    "    top_module_name, top_module = root_modules[0]\n",
    "    \n",
    "    groups = L([ m for m_name, m in list(top_module.named_children()) ])\n",
    "    groups += L([ m for m_name, m in root_modules[1:] ])\n",
    "\n",
    "    return groups.map(params).filter(lambda el: len(el) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"hf_splitter\" class=\"doc_header\"><code>hf_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>hf_splitter</code>(**`m`**)\n",
       "\n",
       "Splits the huggingface model based on various model architecture conventions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(hf_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_BaseModelWrapper(Module):\n",
    "    def __init__(self, hf_model):\n",
    "        super().__init__()\n",
    "        self.hf_model = hf_model.cuda() if torch.cuda.is_available() else hf_model\n",
    "        \n",
    "        n_fwd_args = self.hf_model.forward.__code__.co_argcount\n",
    "        self.hf_model_fwd_args = self.hf_model.forward.__code__.co_varnames[:n_fwd_args][1:]\n",
    "        \n",
    "    def forward(self, x): \n",
    "        for k in list(x): \n",
    "            if k not in self.hf_model_fwd_args: del x[k]         \n",
    "                \n",
    "        return self.hf_model(**x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `HF_baseModelWrapper` includes some nifty code for just passing in the things your model needs, as not all transformer architectures require/use the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_BaseModelCallback(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a `Callback` for handling what is returned from the huggingface model ... \"the huggingface model will return a tuple in outputs, with the actual predictions and some additional activations (should we want to use them is some regularization scheme)\" - from the fastai [Transformer's Tutorial](http://dev.fast.ai/tutorial.transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence classification\n",
    "\n",
    "Below demonstrates how to setup your `blurr` pipeline for a sequence classification task (e.g., a model that requires a single text input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "imdb_df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.&lt;br /&gt;&lt;br /&gt;But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.&lt;br /&gt;&lt;br /&gt;Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.&lt;br /&gt;&lt;br /&gt;Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  \\\n",
       "0  negative   \n",
       "1  positive   \n",
       "2  negative   \n",
       "3  positive   \n",
       "4  negative   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                    Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!   \n",
       "1  This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...   \n",
       "2  Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.<br /><br />Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...   \n",
       "3  Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.<br /><br />Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...   \n",
       "4  This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "\n",
    "pretrained_model_name = \"roberta-base\" # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "blocks = (HF_TextBlock(hf_arch=hf_arch, hf_tokenizer=hf_tokenizer, padding='max_length'), CategoryBlock)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('text'), get_y=ColReader('label'), \n",
    "                   splitter=ColSplitter(col='is_valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(imdb_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mike Brady (Michael Garfield who had a minuscule part in the classic \"The Warriors\") is the first person in the community to realize that there's murderous slugs in his small town. Not just any slugs, mind you, but carnivorous killer bigger then normal, mutated by toxic waste slugs (who still only go as fast as a normal slug, which isn't that frightening, but I digress). No one will believe him at first, but they will. Oh yes, they will.&lt;br /&gt;&lt;br /&gt;OK, killer slugs are right above psychotic sloths and right below Johnathon Winters as Mork's baby in the creepiness factor. So the absurdness of it all is quite apparent from the get go. The flick is fun somewhat through and is of the'so bad that it's good' variety. I appreciate that they spelled out that this was Slugs: the Movie as opposed to Slugs: the Children's Game or Slugs: the Other White Meat. Probably not worthy of watching it more than once and promptly forgetting it except for playing a rather obscure trivia game. Director Juan Piquer Simón is more widely known for his previous films \"Pod People\" (which MST3K deservedly mocked) and \"Peices\" (which is quite possibly the funnest bad movie ever made) &lt;br /&gt;&lt;br /&gt;Eye Candy: Kari Rose shows T&amp;A &lt;br /&gt;&lt;br /&gt;My Grade: D+ &lt;br /&gt;&lt;br /&gt;DVD Extras: Merely a theatrical trailer for this movie</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We'll also add in custom summary methods for blurr learners/models that work with dictionary inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                loss_func=CrossEntropyLossFlat(),\n",
    "                metrics=[accuracy],\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.to_fp16()` requires a GPU so had to remove for tests to run on github.  Let's check that we can get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2005,  0.1214],\n",
       "         [-0.1990,  0.1120],\n",
       "         [-0.1926,  0.1114],\n",
       "         [-0.1985,  0.1003]], device='cuda:1', grad_fn=<AddmmBackward>),)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_summary(self:nn.Module, *xb):\n",
    "    \"Print a summary of `self` using `xb`\"\n",
    "    sample_inputs,infos = layer_info(self, *xb)\n",
    "    n,bs = 64,find_bs(xb)\n",
    "    inp_sz = _print_shapes(apply(lambda x:x.shape, xb[0]['input_ids']), bs)\n",
    "    res = f\"{self.__class__.__name__} (Input shape: {inp_sz})\\n\"\n",
    "    res += \"=\" * n + \"\\n\"\n",
    "    res += f\"{'Layer (type)':<20} {'Output Shape':<20} {'Param #':<10} {'Trainable':<10}\\n\"\n",
    "    res += \"=\" * n + \"\\n\"\n",
    "    ps,trn_ps = 0,0\n",
    "    infos = [o for o in infos if o is not None] #see comment in previous cell\n",
    "    for typ,np,trn,sz in infos:\n",
    "        if sz is None: continue\n",
    "        ps += np\n",
    "        if trn: trn_ps += np\n",
    "        res += f\"{typ:<20} {_print_shapes(sz, bs)[:19]:<20} {np:<10,} {str(trn):<10}\\n\"\n",
    "        res += \"_\" * n + \"\\n\"\n",
    "    res += f\"\\nTotal params: {ps:,}\\n\"\n",
    "    res += f\"Total trainable params: {trn_ps:,}\\n\"\n",
    "    res += f\"Total non-trainable params: {ps - trn_ps:,}\\n\\n\"\n",
    "    return PrettyString(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_summary(self:Learner):\n",
    "    \"Print a summary of the model, optimizer and loss function.\"\n",
    "    xb = self.dls.train.one_batch()[:self.dls.train.n_inp]\n",
    "    res = self.model.blurr_summary(*xb)\n",
    "    res += f\"Optimizer used: {self.opt_func}\\nLoss function: {self.loss_func}\\n\\n\"\n",
    "    if self.opt is not None:\n",
    "        res += f\"Model \" + (\"unfrozen\\n\\n\" if self.opt.frozen_idx==0 else f\"frozen up to parameter group number {self.opt.frozen_idx}\\n\\n\")\n",
    "    res += \"Callbacks:\\n\" + '\\n'.join(f\"  - {cb}\" for cb in sort_by_run(self.cbs))\n",
    "    return PrettyString(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to create our own `summary` methods above because fastai only works where things are represented by a *single tensor*.  But in the case of huggingface transformers, a *single* sequence is represented by *multiple tensors* (in a dictionary).  \n",
    "\n",
    "The change to make this work is so minor I think that the fastai library can/will hopefully be updated to support this use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.00020892962347716094, lr_steep=0.019054606556892395)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.350093</td>\n",
       "      <td>0.240795</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.266670</td>\n",
       "      <td>0.230021</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.172277</td>\n",
       "      <td>0.229257</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "And here we creat a @typedispatched impelmentation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_BaseInput, y, samples, outs, learner=None, ctxs=None, max_n=6, **kwargs):        \n",
    "    \n",
    "    if ctxs is None: ctxs = get_empty_df(min(len(samples), max_n))\n",
    "    ctxs = show_batch[object](x, y, samples, max_n=max_n, ctxs=ctxs, **kwargs)\n",
    "    \n",
    "    n_preds_per_input = len(outs[0])\n",
    "    if (n_preds_per_input == 1): \n",
    "        for i,ctx in enumerate(ctxs): ctx['target'] = outs[i][0]\n",
    "    else:\n",
    "        for pred_idx in range(n_preds_per_input):\n",
    "            for i,ctx in enumerate(ctxs):  ctx[f'target{pred_idx+1}'] = outs[i][pred_idx]\n",
    "\n",
    "    display_df(pd.DataFrame(ctxs))\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&lt;br /&gt;&lt;br /&gt;Stanley Holloway is excellent as the minor city politician who suddenly finds himself leading one of the world's tiniest nations. Dame Margaret Rutherford is a delight as the history professor who sides with Pimlico. Others in the stand-out cast include Hermione Baddeley, Paul Duplis, Naughton Wayne, Basil Radford &amp; Sir Michael Hordern.&lt;br /&gt;&lt;br /&gt;Welcome to Burgundy!</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sure this was a remake of a 70's film, but it had the suspense and action of a current film, say Breakdown. He's running, desperate to be with his hospitalized wife, the police are the least concern. The chases were very good, the part with him being&lt;br /&gt;&lt;br /&gt;cornered at a rest stop was well done, the end of the movie was a great cliffhanger. This is better than Bullitt, a boring movie with what, a muscle car chase that was filmed badly? Vigo's character knew what he had to do to escape Johnny Law, few movies had the effects-night vision, CB radio-okay I forgot the name of the movie, guy has 76'Caddy souped up, toys with guy he upset. The ending is great, you can't tell if he fakes his suicide or not, a very good did-he-make-it-or-not.</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict(self:Learner, item, rm_type_tfms=None, with_input=False):\n",
    "    dl = self.dls.test_dl([item], rm_type_tfms=rm_type_tfms, num_workers=0)\n",
    "    \n",
    "    # this is where we have to change things up since a blurr \"input\" is represented by a dictionary of\n",
    "    # tensors (input_ids, attention_mask, token_type_ids, etc...) and not a single tensor (which fastai assumes\n",
    "    # in a number of places)\n",
    "    b = dl.one_batch()\n",
    "    inp = b[0]\n",
    "    preds, _, dec_preds = self.get_preds(dl=dl, with_input=False, with_decoded=True)\n",
    "    \n",
    "    i = getattr(self.dls, 'n_inp', -1)\n",
    "    inp = (inp,) if i==1 else tuplify(inp)\n",
    "    dec = self.dls.decode_batch(inp + tuplify(dec_preds))[0]\n",
    "    dec_inp,dec_targ = map(detuplify, [dec[:i],dec[i:]])\n",
    "    res = dec_targ,dec_preds[0],preds[0]\n",
    "    if with_input: res = (dec_inp,) + res\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as with `summary`, we need to replace fastai's `Learner.predict` method with the one above which is able to work with inputs that are represented by multiple tensors included in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('positive', tensor(1), tensor([0.0895, 0.9105]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict('I really liked the movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.243066</td>\n",
       "      <td>0.224596</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.104990</td>\n",
       "      <td>0.331770</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.093418</td>\n",
       "      <td>0.325131</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=slice(1e-6, 1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&lt;br /&gt;&lt;br /&gt;Stanley Holloway is excellent as the minor city politician who suddenly finds himself leading one of the world's tiniest nations. Dame Margaret Rutherford is a delight as the history professor who sides with Pimlico. Others in the stand-out cast include Hermione Baddeley, Paul Duplis, Naughton Wayne, Basil Radford &amp; Sir Michael Hordern.&lt;br /&gt;&lt;br /&gt;Welcome to Burgundy!</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I won't waste a whole lot of time of this one because as far as I'm concerned it isn't really a movie to start with, just a careless mish-mash of borrowed footage and embarrassingly amateurish new footage made solely for the purpose of pasting the whole mess together and call it a \"Boogeyman\" sequel. Literally 80% of this film is stolen from its far superior predecessor \"The Boogeyman\", a film that the writers of this garbage apparently didn't even bother to watch because they couldn't even get actress Suzanna Love's original character's name (Lacy) right. And to add insult to injury the killer is invisible in the original footage and visible in the new footage, apparently they think their audience is as stupid as they are. 0 out of 10 and I wish IMDb's rating system went that low, the most callous and blatant attempt to rip off people's money I've even seen, YOU HAVE BEEN WARNED!</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('positive', tensor(1), tensor([0.0037, 0.9963]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('negative', tensor(0), tensor([0.9971, 0.0029]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"Acting was so bad it was almost funny.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname='seq_class_learn_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('negative', tensor(0), tensor([0.9838, 0.0162]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname='seq_class_learn_export.pkl')\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the core training code above works for **all** pretrained sequence classification models available in huggingface.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained classification models you are working with ... and if any of your pretrained sequence classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.modeling_albert.AlbertForSequenceClassification,\n",
       " transformers.modeling_auto.AutoModelForSequenceClassification,\n",
       " transformers.modeling_bart.BartForSequenceClassification,\n",
       " transformers.modeling_bert.BertForSequenceClassification,\n",
       " transformers.modeling_camembert.CamembertForSequenceClassification,\n",
       " transformers.modeling_distilbert.DistilBertForSequenceClassification,\n",
       " transformers.modeling_electra.ElectraForSequenceClassification,\n",
       " transformers.modeling_flaubert.FlaubertForSequenceClassification,\n",
       " transformers.modeling_longformer.LongformerForSequenceClassification,\n",
       " transformers.modeling_mobilebert.MobileBertForSequenceClassification,\n",
       " transformers.modeling_roberta.RobertaForSequenceClassification,\n",
       " transformers.modeling_xlm.XLMForSequenceClassification,\n",
       " transformers.modeling_xlm_roberta.XLMRobertaForSequenceClassification,\n",
       " transformers.modeling_xlnet.XLNetForSequenceClassification]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLURR_MODEL_HELPER.get_models(task='SequenceClassification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'albert-base-v1',\n",
    "    'facebook/bart-base',\n",
    "    'bert-base-uncased',\n",
    "    'camembert-base',\n",
    "    'distilbert-base-uncased',\n",
    "    'monologg/electra-small-finetuned-imdb',\n",
    "    'flaubert/flaubert_small_cased', \n",
    "    'allenai/longformer-base-4096',\n",
    "    'google/mobilebert-uncased',\n",
    "    'roberta-base',\n",
    "    'xlm-mlm-en-2048',\n",
    "    'xlm-roberta-base',\n",
    "    'xlnet-base-cased'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "\n",
    "model_path = Path('models')\n",
    "imdb_df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== albert-base-v1 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v1 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizer\n",
      "model:\t\tAlbertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.634753</td>\n",
       "      <td>0.632435</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post-war restrictions. merry mayhem is what would happen.br /br /the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall.br</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>three part \"horror\" film with some guy in a boarded up house imploring the viewer not to go \"out there\" and (unfortunately) gives us three tales to prove why.br /br /the first story involves a young couple in a car accident who meet up with two psychos. it leads up to two totally predictable twists. still, it's quick (about 15 minutes), violent, well-acted and well-done. predictable but enjoyable.br /br /the second involves</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/bart-base were not used when initializing BartForSequenceClassification: ['final_logits_bias']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.weight', 'classification_head.dense.bias', 'classification_head.out_proj.weight', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizer\n",
      "model:\t\tBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.419732</td>\n",
       "      <td>0.391576</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For anyone who may not know what a one-actor movie was like, this is the best example. This plot is ridiculous, and really makes no sense. It's full of cliched situations, hackneyed lines, melodrama, comedy... you name it!&lt;br /&gt;&lt;br /&gt;But Amitabh Bachchan can make anything convincing, and this movie is by no means an exception. Everyone turns in a decent performance - Shashi Kapoor, Waheeda Rehman, Ranjit, Om Prakash, Smita Patil... But it is the Megastar who overshadows</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bert-base-uncased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizer\n",
      "model:\t\tBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.558721</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\" in april 1946, the university of chicago agreed to operate argonne national laboratory, with an association of midwestern universities offering to sponsor the research. argonne thereby became the first \" national \" laboratory. it did not, however, remain at its original location in the argonne forest. in 1947, it moved farther west from the \" windy city \" to a new site on illinois farmland. when alvin weinberg visited argonne's director, walter zinn, in 1947, he asked him what kind of reactor was to be built at the new site. when zinn described a heavy - water reactor</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizer\n",
      "model:\t\tCamembertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.684204</td>\n",
       "      <td>0.680298</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Superb cast, more please!&lt;br /&gt;&lt;br /&gt;If you can catch just about anything else written by Plater (or starring these wonderful actors). For anyone who doesn't know Plater has a real feeling for jazz, my recommendation is to see the 'Beiderbecke' trilogy whenever you can.&lt;br /&gt;&lt;br /&gt;\"There's three kinds of jazz - Hot, Cool and 'What time does</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== distilbert-base-uncased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizer\n",
      "model:\t\tDistilBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.498043</td>\n",
       "      <td>0.530333</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>by 1976 the western was an exhausted genre and the makers of this film clearly knew it. still, instead of shelving the project and saving us from having to watch it, they went ahead and made it anyway. apparently in need of an interesting thread to get the audiences to come and see the film, they decided to make it as blatantly violent and unpleasant as possible. hell, it worked for the wild bunch so why shouldn't it work here? of course, the wild bunch had the benefit of a superb script but the script of the last hard men is plain old - fashioned rubbish. &lt; br / &gt; &lt;</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== monologg/electra-small-finetuned-imdb ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/electra-small-finetuned-imdb were not used when initializing ElectraForSequenceClassification: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/electra-small-finetuned-imdb and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizer\n",
      "model:\t\tElectraForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.306104</td>\n",
       "      <td>0.276735</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this kiyoshi kurosawa ghost movie is pretty wild, and it did have at least one jump scare that caught me off guard. but all in all, the movie is incredibly stupid, with a detective trying to track down a suspected serial killer, only to find out he may have committed one of the crimes. then he finds himself haunted by a gorgeous asian lady ghost, and has no idea why ( and neither does the viewer ). as other murders are committed, he becomes even more confused as the killers are easily found, and this ghost still haunts him for some reason. not only is the plot completely stupid, the</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== flaubert/flaubert_small_cased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at flaubert/flaubert_small_cased were not used when initializing FlaubertForSequenceClassification: ['pred_layer.proj.bias', 'pred_layer.proj.weight']\n",
      "- This IS expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaubertForSequenceClassification were not initialized from the model checkpoint at flaubert/flaubert_small_cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "model:\t\tFlaubertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.728136</td>\n",
       "      <td>0.687940</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since for</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I' ve read a lot of comments about the film and how it' s so hard for people to believe that it is a sequel to Henry Fool, and even though it technically is, I think that Fay Grim needs to be looked at as an entirely different film. Just because it is the sequel doesn' t mean that it has to be a direct continuation of the first, and I enjoyed that so much about it. The whole point of the film was to change direction from the first, which makes sense because</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/longformer-base-4096 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizer\n",
      "model:\t\tLongformerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.382392</td>\n",
       "      <td>0.411702</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>02:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This document truly opened my eyes to what people outside of the United States thought about the September 11th attacks. This film was expertly put together and presents this disaster as more than an attack on U.S. soil. The aftermath of this disaster is previewed from many different countries and perspectives. I believe that this film should be more widely distributed for this point. It also helps in the the healing process to finally see something other than news reports on the terrorist attacks. And some of the pieces are actually funny, but not abusively so. This film came highly recommended to me, and I pass on the same feeling</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mobilebert-uncased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizer\n",
      "model:\t\tMobileBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>299270.812500</td>\n",
       "      <td>3040.162598</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post - war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt;</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the first one was different and funny. this attempt should have never left the studio. this movie does not make you laugh. it is a weak attempt at gross out humor. the movie picks out current and old movies to rip - off. this time the jokes seem used and overdone. the audience that i saw it with only re - acted to hannibal dinner scene and was otherwise asleep.</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizer\n",
      "model:\t\tRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.329403</td>\n",
       "      <td>0.390423</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I had the TV on for a white noise companion and heard\" $400 for a fully furnished apartment\" So I ran into the TV room expecting another 70's flick and got much more. Luckily, I could rewind to the beginning (DVR buffer) and hit the record button to watch it entirely.(Cinemax uncut and in HD no less!) Aside from some holes in the story and intermittent improbable dialog/events, this is an effective thriller worthy of your time to watch. Pretty creepy and progressive at times: Beverly D'Angelo's character masturbates in front of Alison Parker, played adroitly by Crist</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-en-2048 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-mlm-en-2048 were not used when initializing XLMForSequenceClassification: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
      "- This IS expected if you are initializing XLMForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLMForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMForSequenceClassification were not initialized from the model checkpoint at xlm-mlm-en-2048 and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "model:\t\tXLMForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.744143</td>\n",
       "      <td>0.713868</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this very funny british comedy shows what might happen if a section of london, in this case pimlico, were to declare itself independent from the rest of the uk and its laws, taxes &amp; post-war restrictions. merry mayhem is what would happen. &lt; br / &gt; &lt; br / &gt; the explosion of a wartime bomb leads to the discovery of ancient documents which show that pimlico was ceded to the duchy of burgundy centuries ago, a small historical footnote long since forgotten. to the new burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from whitehall. &lt; br /</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>although a film with bruce willis is always worth watching, you better skip this one. i watched this one on television, so i didn 't have to plunk down cash for it. lucky me. &lt; br / &gt; &lt; br / &gt; the plot develops slowly, very slowly. although the first 30 minutes or so are quite believable, it gets more and more unbelievable towards the end. it is highly questionable, if a seasoned soldier like lt. waters would disobey direct orders. and even if he would, if the rest of his platoon would. they know he puts them in direct danger, and they know they will certainly</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizer\n",
      "model:\t\tXLMRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.703945</td>\n",
       "      <td>0.689597</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In 17th Century Japan, there lived a samurai who would set the standard for the ages. His name was Mayeda. He is sent on an epic journey across the world to acquire 5,000 muscats from the King of Spain. Whilst at sea a violent storm swallows their precious gold intended to buy the weapons and almost takes their lives. Mayeda must battle all odds to survive and the secure the fate of his beloved Japan. Shogun Mayeda is a multi million dollar action adventure epic set across three continents.&lt;br /&gt;&lt;br /&gt;Starring cinema legends</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizer\n",
      "model:\t\tXLNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/transformers/modeling_xlnet.py:283: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
      "  attn_score = (ac + bd + ef) * self.scale\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.620942</td>\n",
       "      <td>0.622453</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp; post-war restrictions. Merry mayhem is what would happen.&lt;br /&gt;&lt;br /&gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This really doesn't match up to Castle of Cagliostro. Lupin isn't as funny or wacky or as hyperactive. The scenery and music are uninspired and plot just isn't interesting. &lt;br /&gt;&lt;br /&gt;The only good thing about this 'un is the nudity (only in the uncut version) provided by Fujiko. It helped spice up some of the tedious scenes. CoC had a formidable villain and set up the movie for some imaginative set-pieces. The locations in TSoTG are not very vivid or engaging. &lt;br</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "bsz = 2\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    del learn; torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(model_name, \n",
    "                                                                                   task=task, \n",
    "                                                                                   config_kwargs={'num_labels': 2})\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n')\n",
    "\n",
    "    blocks = (HF_TextBlock(hf_arch=hf_arch, hf_tokenizer=hf_tokenizer, max_length=128, padding='max_length'), \n",
    "              CategoryBlock)\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                       get_x=ColReader('text'), \n",
    "                       get_y=ColReader('label'), \n",
    "                       splitter=ColSplitter(col='is_valid'))\n",
    "    \n",
    "    dls = dblock.dataloaders(imdb_df, bs=bsz)\n",
    "    \n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    learn = Learner(dls, \n",
    "                    model,\n",
    "                    opt_func=partial(Adam, decouple_wd=True),\n",
    "                    loss_func=CrossEntropyLossFlat(),\n",
    "                    metrics=[accuracy],\n",
    "                    cbs=[HF_BaseModelCallback],\n",
    "                    splitter=hf_splitter)\n",
    "\n",
    "    learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "    learn.freeze()\n",
    "    \n",
    "    b = dls.one_batch()\n",
    "    \n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***')\n",
    "        test_eq(len(b), bsz)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, 128]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        print('*** TESTING One pass through the model ***')\n",
    "        preds = learn.model(b[0])\n",
    "        test_eq(len(preds[0]), bsz)\n",
    "        test_eq(preds[0].shape, torch.Size([bsz, 2]))\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(max_n=2)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "        \n",
    "# cleanup\n",
    "del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizer</td>\n",
       "      <td>AlbertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizer</td>\n",
       "      <td>BartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizer</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizer</td>\n",
       "      <td>CamembertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizer</td>\n",
       "      <td>DistilBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizer</td>\n",
       "      <td>ElectraForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizer</td>\n",
       "      <td>LongformerForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizer</td>\n",
       "      <td>MobileBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizer</td>\n",
       "      <td>RobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizer</td>\n",
       "      <td>XLMRobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizer</td>\n",
       "      <td>XLNetForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Multi-label classification\n",
    "\n",
    "Below demonstrates how to setup your `blurr` pipeline for a multi-label classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18049"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a dataset with the first 10% of training set\n",
    "raw_data = nlp.load_dataset('civil_comments', split='train[:1%]') \n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is such an urgent design problem; kudos to you for taking it on. Very impressive!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this something I'll be able to install on my site? When will you be releasing it?</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 text  \\\n",
       "0               This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!   \n",
       "1  Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!   \n",
       "2                              This is such an urgent design problem; kudos to you for taking it on. Very impressive!   \n",
       "3                                Is this something I'll be able to install on my site? When will you be releasing it?   \n",
       "4                                                                                haha you guys are a bunch of losers.   \n",
       "\n",
       "   toxicity  severe_toxicity  obscene  threat   insult  identity_attack  \\\n",
       "0  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "1  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "2  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "3  0.000000         0.000000      0.0     0.0  0.00000         0.000000   \n",
       "4  0.893617         0.021277      0.0     0.0  0.87234         0.021277   \n",
       "\n",
       "   sexual_explicit  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df = pd.DataFrame(raw_data, columns=list(raw_data.features.keys()))\n",
    "toxic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['severe_toxicity',\n",
       " 'obscene',\n",
       " 'threat',\n",
       " 'insult',\n",
       " 'identity_attack',\n",
       " 'sexual_explicit']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_cols = list(toxic_df.columns[2:]); lbl_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is such an urgent design problem; kudos to you for taking it on. Very impressive!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this something I'll be able to install on my site? When will you be releasing it?</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 text  \\\n",
       "0               This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!   \n",
       "1  Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!   \n",
       "2                              This is such an urgent design problem; kudos to you for taking it on. Very impressive!   \n",
       "3                                Is this something I'll be able to install on my site? When will you be releasing it?   \n",
       "4                                                                                haha you guys are a bunch of losers.   \n",
       "\n",
       "   toxicity  severe_toxicity  obscene  threat  insult  identity_attack  \\\n",
       "0  0.000000                0        0       0       0                0   \n",
       "1  0.000000                0        0       0       0                0   \n",
       "2  0.000000                0        0       0       0                0   \n",
       "3  0.000000                0        0       0       0                0   \n",
       "4  0.893617                0        0       0       1                0   \n",
       "\n",
       "   sexual_explicit  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df = toxic_df.round({col: 0 for col in lbl_cols})\n",
    "toxic_df = toxic_df.convert_dtypes()\n",
    "\n",
    "toxic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "task = HF_TASKS_AUTO.SequenceClassification\n",
    "\n",
    "pretrained_model_name = \"roberta-base\" # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = len(lbl_cols)\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we have to configure the `num_labels` to the number of labels we are predicting. Given that our labels are already encoded, we use a `MultiCategoryBlock` with `encoded=True` and `vocab` equal to the columns with our 1's and 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "blocks = (\n",
    "    HF_TextBlock(hf_arch=hf_arch, hf_tokenizer=hf_tokenizer), \n",
    "    MultiCategoryBlock(encoded=True, vocab=lbl_cols)\n",
    ")\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('text'), get_y=ColReader(lbl_cols), \n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(toxic_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([4, 77]), torch.Size([4, 6]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>some dude, probably drunk types some nonsense on a computer keyboard and we send him to prison costing us $100,000 in tax money.  We are stupid.</td>\n",
       "      <td>severe_toxicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That's what I ended up doing after I left the page.  Thanks!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                loss_func=BCEWithLogitsLossFlat(),\n",
    "                metrics=[partial(accuracy_multi, thresh=0.2)],\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "learn.loss_func.thresh = 0.2\n",
    "learn.create_opt()             # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're doing multi-label classification, we adjust our loss function to use binary cross-entropy and our metrics to use the multi-label friendly version of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(b[0])\n",
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.012022644281387329, lr_steep=0.0014454397605732083)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.048432</td>\n",
       "      <td>0.032427</td>\n",
       "      <td>0.993857</td>\n",
       "      <td>03:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.039177</td>\n",
       "      <td>0.032663</td>\n",
       "      <td>0.993857</td>\n",
       "      <td>03:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.025707</td>\n",
       "      <td>0.032273</td>\n",
       "      <td>0.993857</td>\n",
       "      <td>03:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>None</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WOW. I am amazed Will did not render the English language incomprehensible for most by using words only used by anal retentive English professors, but I'm even more amazed Will is addressing what republicans created when they were he11 bent on restoring America to a Christian nation (sic) and were going to restore \"morality.\"</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oddly, MCAS has a fund to treat animals.</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func.thresh = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((#1) ['severe_toxicity'],\n",
       " tensor([False, False, False,  True, False, False]),\n",
       " tensor([1.2580e-06, 5.1525e-03, 3.0225e-05, 3.2894e-02, 1.0541e-03, 5.3566e-04]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"\"\"\n",
    "Those damned affluent white people should only eat their own food, like cod cakes and boiled potatoes. \n",
    "No enchiladas for them!\n",
    "\"\"\"\n",
    "learn.blurr_predict(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-language-modeling.ipynb.\n",
      "Converted 01c_data-question-answering.ipynb.\n",
      "Converted 01d_data-token-classification.ipynb.\n",
      "Converted 01e_data-summarization.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-language-modeling.ipynb.\n",
      "Converted 02c_modeling-question-answering.ipynb.\n",
      "Converted 02d_modeling-token-classification.ipynb.\n",
      "Converted 02e_modeling-summarization.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
