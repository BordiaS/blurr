{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.question_answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.question_answering\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for question answering tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "import torch\n",
    "from transformers import *\n",
    "from fastai2.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answer\n",
    "\n",
    "Given a document (context) and a question, the objective of these models is to predict the start and end token of the correct answer as it exists in the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_QstAndAnsModelCallback(HF_BaseModelCallback):  \n",
    "    \n",
    "    def begin_batch(self):\n",
    "        x = self.xb[0]\n",
    "        model_args = [x[0]]\n",
    "        if (self._include_arg('attention_mask', x[1])): model_args.append(x[1])\n",
    "        if (self._include_arg('token_type_ids', x[2])): model_args.append(x[2])\n",
    "        if (self._include_arg('cls_index', x[3])): model_args.append(x[3])\n",
    "        if (self._include_arg('p_mask', x[4])): model_args.append(x[4])\n",
    "\n",
    "        self.learn.xb = tuplify(model_args)\n",
    "        \n",
    "    def after_pred(self): self.learn.pred = self.pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_QstAndAnsModelWrapper(HF_BaseModelWrapper):\n",
    "    \"\"\"A custom model wrapper for question answer models since we need all the outputs (not just the first)\"\"\"\n",
    "    def forward(self, x):\n",
    "        model_kwargs = {}\n",
    "        model_kwargs['input_ids'] = x[0]\n",
    "        if (self._include_arg('attention_mask', x[1])): model_kwargs['attention_mask'] = x[1]\n",
    "        if (self._include_arg('token_type_ids', x[2])): model_kwargs['token_type_ids'] = x[2]\n",
    "        if (self._include_arg('cls_index', x[3])): model_kwargs['cls_index'] = x[3]\n",
    "        if (self._include_arg('p_mask', x[4])): model_kwargs['p_mask'] = x[4]\n",
    "        \n",
    "        outputs = self.hf_model(**model_kwargs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we provide a custom loss function our question answer task, expanding on some techniques learned from here and here.\n",
    "\n",
    "In fact, this new loss function can be used in many other multi-modal architectures, with any mix of loss functions.  For example, this can be ammended to include the `is_impossible` task, as well as the start/end token tasks in the SQUAD v2 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiTargetLoss(Module):\n",
    "    \"\"\"Provides the ability to apply different loss functions to multi-modal targets/predictions\"\"\"\n",
    "    def __init__(self, loss_classes=[CrossEntropyLossFlat, CrossEntropyLossFlat], loss_classes_kwargs=[{}, {}], \n",
    "                 weights=[1, 1], reduction='mean'):\n",
    "        \n",
    "        loss_funcs = [ cls(reduction=reduction, **kwargs) for cls, kwargs in zip(loss_classes, loss_classes_kwargs) ]\n",
    "        store_attr(self, 'loss_funcs, weights')\n",
    "        self._reduction = reduction\n",
    "        \n",
    "    # custom loss function must have either a reduction attribute or a reduction argument (like all fastai and\n",
    "    # PyTorch loss functions) so that the framework can change this as needed (e.g., when doing lear.get_preds \n",
    "    # it will set = 'none'). see this forum topic for more info: https://bit.ly/3br2Syz\n",
    "    @property\n",
    "    def reduction(self): return self._reduction\n",
    "    \n",
    "    @reduction.setter\n",
    "    def reduction(self, v): \n",
    "        self._reduction = v\n",
    "        for lf in self.loss_funcs: lf.reduction = v\n",
    "\n",
    "    def forward(self, outputs, *targets):\n",
    "        loss = 0.\n",
    "        for i, loss_func, weights, output, target in zip(range(len(outputs)), \n",
    "                                                         self.loss_funcs, self.weights,\n",
    "                                                         outputs, targets):\n",
    "            loss += weights * loss_func(output, target) \n",
    "                \n",
    "        return loss\n",
    "    \n",
    "    def activation(self, outs): \n",
    "        acts = [ self.loss_funcs[i].activation(o) for i, o in enumerate(outs) ]\n",
    "        return acts\n",
    "\n",
    "    def decodes(self, outs):   \n",
    "        decodes = [ self.loss_funcs[i].decodes(o) for i, o in enumerate(outs) ]\n",
    "        return decodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we'll use a subset of pre-processed SQUAD v2 for our purposes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('./')\n",
    "squad_df = pd.read_csv(path/'squad_sample.csv'); len(squad_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New_York_City</td>\n",
       "      <td>The New York City Fire Department (FDNY), provides fire protection, technical rescue, primary response to biological, chemical, and radioactive hazards, and emergency medical services for the five boroughs of New York City. The New York City Fire Department is the largest municipal fire department in the United States and the second largest in the world after the Tokyo Fire Department. The FDNY employs approximately 11,080 uniformed firefighters and over 3,300 uniformed EMTs and paramedics. The FDNY's motto is New York's Bravest.</td>\n",
       "      <td>56d1076317492d1400aab78c</td>\n",
       "      <td>What does FDNY stand for?</td>\n",
       "      <td>False</td>\n",
       "      <td>New York City Fire Department</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>Following the death in 1473 of James II, the last Lusignan king, the Republic of Venice assumed control of the island, while the late king's Venetian widow, Queen Catherine Cornaro, reigned as figurehead. Venice formally annexed the Kingdom of Cyprus in 1489, following the abdication of Catherine. The Venetians fortified Nicosia by building the Venetian Walls, and used it as an important commercial hub. Throughout Venetian rule, the Ottoman Empire frequently raided Cyprus. In 1539 the Ottomans destroyed Limassol and so fearing the worst, the Venetians also fortified Famagusta and Kyrenia.</td>\n",
       "      <td>572e7f8003f98919007566df</td>\n",
       "      <td>In what year did the Ottomans destroy Limassol?</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>481</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title  \\\n",
       "0  New_York_City   \n",
       "1         Cyprus   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               context  \\\n",
       "0                                                              The New York City Fire Department (FDNY), provides fire protection, technical rescue, primary response to biological, chemical, and radioactive hazards, and emergency medical services for the five boroughs of New York City. The New York City Fire Department is the largest municipal fire department in the United States and the second largest in the world after the Tokyo Fire Department. The FDNY employs approximately 11,080 uniformed firefighters and over 3,300 uniformed EMTs and paramedics. The FDNY's motto is New York's Bravest.   \n",
       "1  Following the death in 1473 of James II, the last Lusignan king, the Republic of Venice assumed control of the island, while the late king's Venetian widow, Queen Catherine Cornaro, reigned as figurehead. Venice formally annexed the Kingdom of Cyprus in 1489, following the abdication of Catherine. The Venetians fortified Nicosia by building the Venetian Walls, and used it as an important commercial hub. Throughout Venetian rule, the Ottoman Empire frequently raided Cyprus. In 1539 the Ottomans destroyed Limassol and so fearing the worst, the Venetians also fortified Famagusta and Kyrenia.   \n",
       "\n",
       "                question_id                                    question_text  \\\n",
       "0  56d1076317492d1400aab78c                        What does FDNY stand for?   \n",
       "1  572e7f8003f98919007566df  In what year did the Ottomans destroy Limassol?   \n",
       "\n",
       "   is_impossible                    answer_text  answer_start  answer_end  \n",
       "0          False  New York City Fire Department             4          33  \n",
       "1          False                           1539           481         485  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = 'bert-large-uncased-whole-word-masking-finetuned-squad'\n",
    "hf_tokenizer_cls = BertTokenizer\n",
    "hf_model_cls = HF_MODELS.BertForQuestionAnswering\n",
    "\n",
    "hf_arch, hf_tokenizer, hf_config, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name,\n",
    "                                                                               hf_tokenizer_cls,\n",
    "                                                                               hf_model_cls)\n",
    "\n",
    "\n",
    "# # here's a pre-trained roberta model for squad you can try too\n",
    "# pretrained_model_name = \"ahotrod/roberta_large_squad2\"\n",
    "# hf_arch, hf_tokenizer, hf_config, hf_model = \\\n",
    "#     BLURR_MODEL_HELPER.get_auto_hf_objects(pretrained_model_name, task=HF_TASKS_AUTO.ForQuestionAnswering)\n",
    "\n",
    "# # here's a pre-trained xlm model for squad you can try too\n",
    "# pretrained_model_name = 'xlm-mlm-ende-1024'\n",
    "# hf_arch, hf_tokenizer, hf_config, hf_model = \\\n",
    "#     BLURR_MODEL_HELPER.get_auto_hf_objects(pretrained_model_name, task=HF_TASKS_AUTO.ForQuestionAnswering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_squad(row):\n",
    "    context, qst, ans = row['context'], row['question_text'], row['answer_text']\n",
    "    \n",
    "    add_prefix_space = hf_arch in ['gpt2', 'roberta']\n",
    "    \n",
    "    if(hf_tokenizer.padding_side == 'right'):\n",
    "        tok_input = hf_tokenizer.convert_ids_to_tokens(hf_tokenizer.encode(qst, context, \n",
    "                                                                           add_prefix_space=add_prefix_space))\n",
    "    else:\n",
    "        tok_input = hf_tokenizer.convert_ids_to_tokens(hf_tokenizer.encode(context, qst, \n",
    "                                                                           add_prefix_space=add_prefix_space))\n",
    "                                                                       \n",
    "    tok_ans = hf_tokenizer.tokenize(str(row['answer_text']), \n",
    "                                    add_special_tokens=False, \n",
    "                                    add_prefix_space=add_prefix_space)\n",
    "    \n",
    "    start_idx, end_idx = 0,0\n",
    "    for idx, tok in enumerate(tok_input):\n",
    "        try:\n",
    "            if (tok == tok_ans[0] and tok_input[idx:idx + len(tok_ans)] == tok_ans): \n",
    "                start_idx, end_idx = idx, idx + len(tok_ans)\n",
    "                break\n",
    "        except: pass\n",
    "            \n",
    "    row['tokenized_input'] = tok_input\n",
    "    row['tokenized_input_len'] = len(tok_input)\n",
    "    row['tok_answer_start'] = start_idx\n",
    "    row['tok_answer_end'] = end_idx\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (16 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (12 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "squad_df = squad_df.apply(pre_process_squad, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>tokenized_input</th>\n",
       "      <th>tokenized_input_len</th>\n",
       "      <th>tok_answer_start</th>\n",
       "      <th>tok_answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New_York_City</td>\n",
       "      <td>The New York City Fire Department (FDNY), provides fire protection, technical rescue, primary response to biological, chemical, and radioactive hazards, and emergency medical services for the five boroughs of New York City. The New York City Fire Department is the largest municipal fire department in the United States and the second largest in the world after the Tokyo Fire Department. The FDNY employs approximately 11,080 uniformed firefighters and over 3,300 uniformed EMTs and paramedics. The FDNY's motto is New York's Bravest.</td>\n",
       "      <td>56d1076317492d1400aab78c</td>\n",
       "      <td>What does FDNY stand for?</td>\n",
       "      <td>False</td>\n",
       "      <td>New York City Fire Department</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>[[CLS], what, does, f, ##d, ##ny, stand, for, ?, [SEP], the, new, york, city, fire, department, (, f, ##d, ##ny, ), ,, provides, fire, protection, ,, technical, rescue, ,, primary, response, to, biological, ,, chemical, ,, and, radioactive, hazards, ,, and, emergency, medical, services, for, the, five, boroughs, of, new, york, city, ., the, new, york, city, fire, department, is, the, largest, municipal, fire, department, in, the, united, states, and, the, second, largest, in, the, world, after, the, tokyo, fire, department, ., the, f, ##d, ##ny, employs, approximately, 11, ,, 08, ##0, unif...</td>\n",
       "      <td>123</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>Following the death in 1473 of James II, the last Lusignan king, the Republic of Venice assumed control of the island, while the late king's Venetian widow, Queen Catherine Cornaro, reigned as figurehead. Venice formally annexed the Kingdom of Cyprus in 1489, following the abdication of Catherine. The Venetians fortified Nicosia by building the Venetian Walls, and used it as an important commercial hub. Throughout Venetian rule, the Ottoman Empire frequently raided Cyprus. In 1539 the Ottomans destroyed Limassol and so fearing the worst, the Venetians also fortified Famagusta and Kyrenia.</td>\n",
       "      <td>572e7f8003f98919007566df</td>\n",
       "      <td>In what year did the Ottomans destroy Limassol?</td>\n",
       "      <td>False</td>\n",
       "      <td>1539</td>\n",
       "      <td>481</td>\n",
       "      <td>485</td>\n",
       "      <td>[[CLS], in, what, year, did, the, ottomans, destroy, lima, ##sso, ##l, ?, [SEP], following, the, death, in, 147, ##3, of, james, ii, ,, the, last, lu, ##si, ##gnan, king, ,, the, republic, of, venice, assumed, control, of, the, island, ,, while, the, late, king, ', s, venetian, widow, ,, queen, catherine, corn, ##aro, ,, reigned, as, figure, ##head, ., venice, formally, annexed, the, kingdom, of, cyprus, in, 148, ##9, ,, following, the, abd, ##ication, of, catherine, ., the, venetian, ##s, fortified, nico, ##sia, by, building, the, venetian, walls, ,, and, used, it, as, an, important, comm...</td>\n",
       "      <td>139</td>\n",
       "      <td>110</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title  \\\n",
       "0  New_York_City   \n",
       "1         Cyprus   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               context  \\\n",
       "0                                                              The New York City Fire Department (FDNY), provides fire protection, technical rescue, primary response to biological, chemical, and radioactive hazards, and emergency medical services for the five boroughs of New York City. The New York City Fire Department is the largest municipal fire department in the United States and the second largest in the world after the Tokyo Fire Department. The FDNY employs approximately 11,080 uniformed firefighters and over 3,300 uniformed EMTs and paramedics. The FDNY's motto is New York's Bravest.   \n",
       "1  Following the death in 1473 of James II, the last Lusignan king, the Republic of Venice assumed control of the island, while the late king's Venetian widow, Queen Catherine Cornaro, reigned as figurehead. Venice formally annexed the Kingdom of Cyprus in 1489, following the abdication of Catherine. The Venetians fortified Nicosia by building the Venetian Walls, and used it as an important commercial hub. Throughout Venetian rule, the Ottoman Empire frequently raided Cyprus. In 1539 the Ottomans destroyed Limassol and so fearing the worst, the Venetians also fortified Famagusta and Kyrenia.   \n",
       "\n",
       "                question_id                                    question_text  \\\n",
       "0  56d1076317492d1400aab78c                        What does FDNY stand for?   \n",
       "1  572e7f8003f98919007566df  In what year did the Ottomans destroy Limassol?   \n",
       "\n",
       "   is_impossible                    answer_text  answer_start  answer_end  \\\n",
       "0          False  New York City Fire Department             4          33   \n",
       "1          False                           1539           481         485   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           tokenized_input  \\\n",
       "0  [[CLS], what, does, f, ##d, ##ny, stand, for, ?, [SEP], the, new, york, city, fire, department, (, f, ##d, ##ny, ), ,, provides, fire, protection, ,, technical, rescue, ,, primary, response, to, biological, ,, chemical, ,, and, radioactive, hazards, ,, and, emergency, medical, services, for, the, five, boroughs, of, new, york, city, ., the, new, york, city, fire, department, is, the, largest, municipal, fire, department, in, the, united, states, and, the, second, largest, in, the, world, after, the, tokyo, fire, department, ., the, f, ##d, ##ny, employs, approximately, 11, ,, 08, ##0, unif...   \n",
       "1  [[CLS], in, what, year, did, the, ottomans, destroy, lima, ##sso, ##l, ?, [SEP], following, the, death, in, 147, ##3, of, james, ii, ,, the, last, lu, ##si, ##gnan, king, ,, the, republic, of, venice, assumed, control, of, the, island, ,, while, the, late, king, ', s, venetian, widow, ,, queen, catherine, corn, ##aro, ,, reigned, as, figure, ##head, ., venice, formally, annexed, the, kingdom, of, cyprus, in, 148, ##9, ,, following, the, abd, ##ication, of, catherine, ., the, venetian, ##s, fortified, nico, ##sia, by, building, the, venetian, walls, ,, and, used, it, as, an, important, comm...   \n",
       "\n",
       "   tokenized_input_len  tok_answer_start  tok_answer_end  \n",
       "0                  123                11              16  \n",
       "1                  139               110             112  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "squad_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len= 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_df = squad_df[(squad_df.tokenized_input_len < max_seq_len) & (squad_df.is_impossible == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(range(max_seq_len))\n",
    "# vocab = dict(enumerate(range(max_seq_len)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for tokenizers that pad on right or left side\n",
    "trunc_strat = 'only_second' if (hf_tokenizer.padding_side == 'right') else 'only_first'\n",
    "txt_cols = [['question_text'],['context']] if (hf_tokenizer.padding_side == 'right') else [['context'],['question_text']]\n",
    "\n",
    "# override HF_BatchTransform defaults (optional)\n",
    "hf_batch_tfm = HF_BatchTransform(hf_arch, hf_tokenizer, task=ForQuestionAnsweringTask(),\n",
    "                                 max_seq_len=128, truncation_strategy=trunc_strat)\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock.from_df(text_cols_lists=txt_cols, \n",
    "                         hf_arch=hf_arch, hf_tokenizer=hf_tokenizer, hf_batch_tfm=hf_batch_tfm),\n",
    "    CategoryBlock(vocab=vocab),\n",
    "    CategoryBlock(vocab=vocab)\n",
    ")\n",
    "\n",
    "# can't export lambda functions, so made the getter a standard method\n",
    "def get_x(x): return (x.text0, x.text1)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=get_x,\n",
    "                   get_y=[ColReader('tok_answer_start'), ColReader('tok_answer_end')],\n",
    "                   splitter=RandomSplitter(),\n",
    "                   n_inp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = dblock.dataloaders(squad_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, (#128) [0,1,2,3,4,5,6,7,8,9...], (#128) [0,1,2,3,4,5,6,7,8,9...])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.vocab), dls.vocab[1], dls.vocab[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how do birds conserve energy? many, if not most, birds migrate in flocks. for larger birds, flying in flocks reduces the energy cost. geese in a v - formation may conserve 12 – 20 % of the energy they would need to fly alone. red knots calidris canutus and dunlins calidris alpina were found in radar studies to fly 5 km / h ( 3. 1 mph ) faster in flocks than when they were flying alone.</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dovrak has used what type of themes to impart a nationalist flavor? composers of classical music have often made use of folk music ( music created by musicians who are commonly not classically trained, often from a purely oral tradition ). some composers, like dvorak and smetana, have used folk themes to impart a nationalist flavor to their work, while others like bartok have used specific themes lifted whole from their folk - music origins.</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(hf_tokenizer=hf_tokenizer, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_QstAndAnsModelWrapper(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, \n",
    "                hf_model,\n",
    "                opt_func=partial(Adam, decouple_wd=True),\n",
    "                cbs=[HF_QstAndAnsModelCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "learn.loss_func=MultiTargetLoss()\n",
    "learn.create_opt()                # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above how I had to define the loss function *after* creating the `Learner` object.  I'm not sure why, but the `MultiTargetLoss` above prohibits the learner from being exported if I do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y_start, y_end = dls.one_batch()\n",
    "# preds = learn.model(x)\n",
    "# len(preds),preds[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The code above will only work if we are using the model wrapper (not the callback) as the callback does the work of ensuring our input into the huggingface model is correct ... and `learn.model(*x)` doesn't use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.025118863582611083, lr_steep=1.0964782238006592)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.412179</td>\n",
       "      <td>2.753212</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.954786</td>\n",
       "      <td>2.171412</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.420020</td>\n",
       "      <td>2.099426</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the magnetic field is part of what sort of recorder? bell worked extensively in medical research and invented techniques for teaching speech to the deaf. during his volta laboratory period, bell and his associates considered impressing a magnetic field on a record as a means of reproducing sound. although the trio briefly experimented with the concept, they could not develop a workable prototype. they abandoned the idea, never realizing they had glimpsed a basic principle which would one day find its application in the tape recorder, the hard disc and floppy disc drive and other magnetic media.</td>\n",
       "      <td>99</td>\n",
       "      <td>101</td>\n",
       "      <td>99</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>where was the university evacuated? between the german invasion of poland on 1 september 1939 and the anglo - french declaration of war against the german reich on 3 september 1939, the entire city ( a total of 120, 000 people ) was evacuated, like other border towns as well. until the arrival of the wehrmacht troops mid - june 1940, the city was, for ten months, completely empty, with the exception of the garrisoned soldiers. the jews of strasbourg had been evacuated to perigueux and limoges, the university had been evacuated to clermont - ferrand.</td>\n",
       "      <td>111</td>\n",
       "      <td>116</td>\n",
       "      <td>111</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(hf_tokenizer=hf_tokenizer, skip_special_tokens=True, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(('11', '13'),\n",
       " tensor([11]),\n",
       " tensor([[1.9953e-05, 6.6960e-06, 7.5335e-07, 1.7125e-06, 7.1178e-07, 1.2500e-06,\n",
       "          1.0880e-07, 1.9954e-05, 6.6870e-04, 4.3924e-05, 2.1026e-03, 9.9656e-01,\n",
       "          7.1035e-05, 1.8911e-05, 3.0116e-05, 2.0009e-05, 2.4065e-04, 1.0099e-04,\n",
       "          2.6297e-06, 3.6813e-05, 4.9420e-06, 1.9948e-05, 1.9984e-05, 8.5654e-08,\n",
       "          9.5072e-08, 8.9944e-08, 8.9454e-08, 9.1328e-08, 9.4035e-08, 9.3781e-08,\n",
       "          8.7999e-08, 9.0398e-08, 9.3350e-08, 9.2285e-08, 8.5133e-08, 8.3271e-08,\n",
       "          8.7424e-08, 8.7053e-08, 8.3034e-08, 8.3653e-08, 8.4636e-08, 8.8034e-08,\n",
       "          8.9929e-08, 8.7365e-08, 9.0708e-08, 9.0124e-08, 8.9394e-08, 8.8992e-08,\n",
       "          8.9814e-08, 9.0405e-08, 9.4208e-08, 9.3037e-08, 9.1948e-08, 9.3707e-08,\n",
       "          9.7754e-08, 9.7393e-08, 9.5191e-08, 9.2520e-08, 9.3175e-08, 9.8658e-08,\n",
       "          9.7461e-08, 9.2410e-08, 9.0433e-08, 9.3034e-08, 9.8031e-08, 9.2164e-08,\n",
       "          8.9365e-08, 9.1023e-08, 9.2003e-08, 9.6528e-08, 9.1928e-08, 9.2340e-08,\n",
       "          9.3290e-08, 9.5564e-08, 9.3305e-08, 9.4039e-08, 9.3995e-08, 9.5854e-08,\n",
       "          9.8225e-08, 9.4144e-08, 9.6120e-08, 9.7631e-08, 1.0059e-07, 1.0124e-07,\n",
       "          9.5964e-08, 9.4422e-08, 9.9311e-08, 1.0544e-07, 1.0219e-07, 9.2500e-08,\n",
       "          8.8211e-08, 9.3711e-08, 8.9126e-08, 7.9090e-08, 8.6327e-08, 8.1980e-08,\n",
       "          8.8299e-08, 8.2458e-08, 7.6450e-08, 7.9317e-08, 7.8627e-08, 7.2060e-08,\n",
       "          6.8993e-08, 7.3957e-08, 7.7961e-08, 8.6862e-08, 8.3683e-08, 7.8785e-08,\n",
       "          7.8605e-08, 8.1771e-08, 8.9369e-08, 8.4733e-08, 8.4885e-08, 8.6142e-08,\n",
       "          9.3352e-08, 9.4181e-08, 8.6686e-08, 8.0790e-08, 7.9248e-08, 7.9655e-08,\n",
       "          7.3580e-08, 7.0639e-08, 8.0341e-08, 7.6880e-08, 7.9648e-08, 8.0002e-08,\n",
       "          7.3522e-08, 7.5676e-08]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df = pd.DataFrame.from_dict([{\n",
    "    'text0': 'What did George Lucas make?',\n",
    "    'text1': 'George Lucas created Star Wars in 1977. He directed and produced it.'   \n",
    "}], \n",
    "    orient='columns')\n",
    "\n",
    "learn.predict(inf_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['star', 'wars']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_ids = hf_tokenizer.encode('What did George Lucas make?',\n",
    "                              'George Lucas created Star Wars in 1977. He directed and produced it.')\n",
    "\n",
    "hf_tokenizer.convert_ids_to_tokens(inp_ids, skip_special_tokens=False)[11:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is a bug currently in fastai v2 (or with how I'm assembling everything) that currently prevents us from seeing the decoded predictions and probabilities for the \"end\" token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inf_df = pd.DataFrame.from_dict([{\n",
    "    'text0': 'When was Star Wars made?',\n",
    "    'text1': 'George Lucas created Star Wars in 1977. He directed and produced it.'\n",
    "}], \n",
    "    orient='columns')\n",
    "\n",
    "test_dl = dls.test_dl(inf_df)\n",
    "inp, probs, _, preds = learn.get_preds(dl=test_dl, with_input=True, with_decoded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1977']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer.convert_ids_to_tokens(inp[0].tolist()[0], \n",
    "                                   skip_special_tokens=False)[torch.argmax(probs[0]):torch.argmax(probs[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.253970</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 1; 10.91 GiB total capacity; 3.33 GiB already allocated; 9.88 MiB free; 3.34 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-59612d846f50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/development/projects/blurr/_libs/fastcore/fastcore/utils.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/projects/blurr/_libs/fastai2/fastai2/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    111\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    112\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/projects/blurr/_libs/fastcore/fastcore/utils.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/projects/blurr/_libs/fastai2/fastai2/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m;\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/projects/blurr/_libs/fastai2/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m;\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/projects/blurr/_libs/fastai2/fastai2/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/projects/blurr/_libs/fastai2/fastai2/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/projects/blurr/_libs/fastai2/fastai2/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyper\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/projects/blurr/_libs/fastai2/fastai2/optimizer.py\u001b[0m in \u001b[0;36maverage_grad\u001b[0;34m(p, mom, dampening, grad_avg, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maverage_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_avg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;34m\"Keeps track of the avg grads of `p` in `state` with `mom`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mgrad_avg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgrad_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mdamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmom\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mgrad_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 1; 10.91 GiB total capacity; 3.33 GiB already allocated; 9.88 MiB free; 3.34 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=slice(1e-7, 1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(hf_tokenizer=hf_tokenizer, max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(inf_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, pred_classes, probs = learn.predict(inf_df.iloc[0])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ids = hf_tokenizer.encode('When was Star Wars made?',\n",
    "                              'George Lucas created Star Wars in 1977. He directed and produced it.')\n",
    "\n",
    "hf_tokenizer.convert_ids_to_tokens(inp_ids, skip_special_tokens=False)[int(preds[0]):int(preds[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what about inference?\n",
    "\n",
    "Note that I had to replace the loss function because of the above-mentioned issue to exporting the model with the `MultiTargetLoss` loss function.  After getting our inference learner, we put it back and we're good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = nn.CrossEntropyLoss()\n",
    "learn.export(fname='q_and_a_learn_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_learn = load_learner(fname='q_and_a_learn_export.pkl')\n",
    "inf_learn.loss_func = MultiTargetLoss()\n",
    "\n",
    "inf_df = pd.DataFrame.from_dict([\n",
    "    {'text0': 'Who created Star Wars?', \n",
    "     'text1': 'George Lucas created Star Wars in 1977. He directed and produced it.'}],\n",
    "    orient='columns')\n",
    "\n",
    "inf_learn.predict(inf_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ids = hf_tokenizer.encode('Who created Star Wars?',\n",
    "                              'George Lucas created Star Wars in 1977. He directed and produced it.')\n",
    "\n",
    "hf_tokenizer.convert_ids_to_tokens(inp_ids, skip_special_tokens=False)[7:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
