{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.summarization\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from rouge_score import rouge_scorer, scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "\n",
    "The objective of summarization is to generate a concise and accurate representation of a much larger body of text.  For example, we may want to summarize an article in a single sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('./')\n",
    "cnndm_df = pd.read_csv(path/'cnndm_sample.csv'); len(cnndm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...</td>\n",
       "      <td>John Sexton: Traditionally, universities have been defined and limited by location .\\nGlobal campuses form a network of thought, innovation, he writes .\\nFaculty can teach, Sexton says, students can team up in many cities at once .\\nSexton: Research, scholarship can be shared and cultural ties made in \"century of knowledge\"</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will \"hopefully bring some order\" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...</td>\n",
       "      <td>NEW: Protest moves after crackdown at Freedom Square .\\nOrder sought after protests over last month's election turn violent .\\nDemonstrators say the election was fraudulent .\\nState of emergency could last until March 20, official says .</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   article  \\\n",
       "0  (CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...   \n",
       "1  (CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will \"hopefully bring some order\" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                              highlights  \\\n",
       "0  John Sexton: Traditionally, universities have been defined and limited by location .\\nGlobal campuses form a network of thought, innovation, he writes .\\nFaculty can teach, Sexton says, students can team up in many cities at once .\\nSexton: Research, scholarship can be shared and cultural ties made in \"century of knowledge\"   \n",
       "1                                                                                          NEW: Protest moves after crackdown at Freedom Square .\\nOrder sought after protests over last month's election turn violent .\\nDemonstrators say the election was fraudulent .\\nState of emergency could last until March 20, official says .   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnndm_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large-cnn and are newly initialized: ['final_logits_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bart',\n",
       " transformers.configuration_bart.BartConfig,\n",
       " transformers.tokenization_bart.BartTokenizer,\n",
       " transformers.modeling_bart.BartForConditionalGeneration)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               model_cls=BartForConditionalGeneration)\n",
    "\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_batch_tfm = HF_SummarizationBatchTransform(hf_arch, hf_tokenizer)\n",
    "\n",
    "blocks = ( \n",
    "    HF_TextBlock(hf_arch, hf_tokenizer, max_length=512), \n",
    "    HF_TextBlock(hf_arch, hf_tokenizer, hf_batch_tfm=hf_batch_tfm, max_length=150, hf_input_idxs=[0,1])\n",
    ")\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('article'), \n",
    "                   get_y=ColReader('highlights'), \n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(cnndm_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 512]), torch.Size([2, 72]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- Chinese amateur golfer Guan Tianlang was not even born when Tiger Woods won the Masters for the first time in 1997. Guan will become the youngest player in Masters history when he tees off on Thursday, eclipsing the mark set by Italy's Matteo Manassero in 2010. And on Monday, the Chinese teenager -- aged 14 years, five months and 14 days -- was given a helping hand by Woods after the 14-time major winner invited Guan to take in the back nine of the fabled Augusta course. Guan qualified for the year's first major by winning November's Asia-Pacific Amateur Championship, an event designed specifically to unearth global talent. It was the third time the teenager had played with world No. 1 Woods, with the pair joined on their Monday practice round by big-hitting American Dustin Johnson. \"He gives me advice and I will say every time I play with him I feel a lot better and give myself confidence,\" Guan told the PGA Tour's official website. \"I'm not going to push myself too hard. I'm trying to just enjoy my game, play my best and hopefully play a good score.\" Woods, who goes into this weekend's tournament as favorite to clinch a fifth Masters crown, is pleased his legacy has helped created a new generation of players. Opinion: For Tiger, winning does take care of everything. \"It's frightening to think that he was born after I won my first Masters,\" the 37-year-old said after winning the Arnold Palmer Invitational a few weeks ago. \"It's exciting that I've inspired kids to play and not just here in the States, but obviously in China and around the world.\" At the other end of the age scale, Northern Irishman Darren Clarke, aged 44, was hoping to take part in his 12th Masters. But the 2011 British Open champion has been forced to withdraw with the same hamstring injury which kept him out of last week's Valero Texas Open. Clarke was one of Jose Maria Olazabal's vice captains when he led Europe to a stunning Ryder Cup victory against the United States at Medinah in September. Meanwhile Spain's Olazabal, a two-time champion at Augusta, hit a wayward drive during the first day of practice which left a male spectator with blood pouring from his head. Olazabal, the last European to wear the green jacket, immediately apologized and offered the stricken fan a signed glove. Woods back on top of the world.</td>\n",
       "      <td>Chinese amateur Guan Tianlang plays back nine of Augusta with Tiger Woods.\\nGuan to become the youngest player in Masters history when play begins on Thursday.\\n2011 British Open champion Darren Clarke forced to withdraw due to a hamstring injury.\\nJose Maria Olazabal apologizes to fan after hitting him in the head with a wayward shot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Sebastian Vettel made Formula One history as he won the season-ending Abu Dhabi Grand Prix to clinch the title. The 23-year-old German becomes the youngest champion in the sport's history and his triumph completes the double for Red Bull who won the constructors' category. Fernando Alonso went into the final round with an eight-point lead in the standings ahead of Vettel's teammate Mark Webber of Australia, but they finished seventh and eighth respectively to see their title hopes ended. Vettel was winning his fifth race of the season and he dominated from pole position to hold off 2008 champion Lewis Hamilton whose McLaren teammate Jenson Button took third. Drivers' Championship (after 19 rounds):. 1. Sebastian Vettel (Ger) Red Bull 256 points. 2. Fernando Alonso (Spa) Ferrari 252. 3. Mark Webber (Aus) Red Bull 242. 4. Lewis Hamilton (GB) McLaren 240. 5. Jenson Button (GB) McLaren 214. 6. Felipe Massa (Bra) Ferrari 144. 7. Nico Rosberg (Ger) Mercedes 142. 8. Robert Kubica (Pol) Renault 136. 9. Michael Schumacher (Ger) Mercedes 72. 10. Rubens Barrichello (Bra) Williams 47. Constructors' Championship:. 1. Red Bull 498 points. 2. McLaren 454. 3. Ferrari 396. 4. Mercedes 214. 5. Renault 163. 6. Williams 69. 7. Force India 68. 8. Sauber 44. 9. Toro Rosso 13.</td>\n",
       "      <td>Red Bull's Sebastian Vettel becomes youngest F1 world champion.\\n23-year-old German wins Abu Dhabi GP to overtake Fernando Alonso in the standings.\\nVettel's Red Bull teammate finishes third in the title race with Lewis Hamilton fourth.\\nRed Bull win constructors' title from McLaren with Ferrari third.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(hf_tokenizer=hf_tokenizer, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for summarization tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_rouge(predicted_txts, reference_txts, rouge_keys=[\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True):\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_keys, use_stemmer=use_stemmer)\n",
    "    aggregator = scoring.BootstrapAggregator()\n",
    "\n",
    "    for ref_text, pred_txt in zip(reference_txts, predicted_txts):\n",
    "        scores = scorer.score(ref_text, pred_txt)\n",
    "        aggregator.add_scores(scores)\n",
    "\n",
    "    result = aggregator.aggregate()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Here we create a summarization specific subclass of `HF_BaseModelCallback` in order to include custom, summarization specific, metrics, and also handle the pre-calculated loss during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_SummarizationModelCallback(HF_BaseModelCallback):  \n",
    "    def __init__(self, rouge_metrics=[\"rouge1\", \"rouge2\", \"rougeL\"], text_gen_kwargs={}, **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self=self, names='rouge_metrics, text_gen_kwargs, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in rouge_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the target's HF_TokenizerTransform (used for rouge metrics)\n",
    "        hf_textblock_tfm = self.learn.dls.tfms[-1]\n",
    "        self.hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "        self.tok_kwargs = hf_textblock_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "        \n",
    "        \n",
    "    # --- batch begin/after phases ---\n",
    "    def before_batch(self): self.hf_loss = None\n",
    "        \n",
    "    def after_pred(self): \n",
    "        # the \"labels\" key will only be included in the input dictionary *IF* we are training with target labels, \n",
    "        # in which case the first output of the model will be the loss\n",
    "        if ('labels' in self.xb[0]):\n",
    "            self.hf_loss, self.learn.pred = self.pred[0], self.pred[1]\n",
    "        else:\n",
    "            self.learn.pred = self.pred[0]\n",
    "            \n",
    "    def after_loss(self): \n",
    "        # if we already have the loss from the model, update the Learner's loss to be it\n",
    "        if (self.hf_loss is not None): self.learn.loss = self.hf_loss\n",
    "        \n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # grab predicted and reference ids for any metrics that need them\n",
    "        input_ids, attention_mask = self.xb[0]['input_ids'], self.xb[0]['attention_mask']\n",
    "        gen_ids = self.learn.model.hf_model.generate(input_ids=input_ids, \n",
    "                                                     attention_mask=attention_mask, \n",
    "                                                     use_cache=True,\n",
    "                                                     **self.text_gen_kwargs)\n",
    "        \n",
    "        self.generated_ids += gen_ids.tolist()\n",
    "        self.refernce_ids += self.yb[0].tolist()\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.generated_ids, self.refernce_ids = [], []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        # are there rouge metrics to calculate?\n",
    "        if (self.rouge_metrics is not None and len(self.rouge_metrics) > 0):\n",
    "            gen_texts = self.hf_tokenizer.batch_decode(self.generated_ids, \n",
    "                                                       skip_special_tokens=True, \n",
    "                                                       clean_up_tokenization_spaces=True)\n",
    "\n",
    "            ref_texts = self.hf_tokenizer.batch_decode(self.refernce_ids, \n",
    "                                                       skip_special_tokens=True, \n",
    "                                                       clean_up_tokenization_spaces=True)\n",
    "\n",
    "            rouge_results = calculate_rouge(gen_texts, ref_texts, rouge_keys=self.rouge_metrics)\n",
    "            \n",
    "            for rouge_key, scores in rouge_results.items(): \n",
    "                self.custom_metrics_dict[rouge_key] = scores.mid.fmeasure\n",
    "                \n",
    "\n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a custom param splitter to give us a bit more depth in applying discriminative learning rates for summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def summarization_splitter(m, arch):\n",
    "    \"\"\"Custom param splitter for summarization models\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, 'hf_model')) else m\n",
    "    \n",
    "    if arch in ['bart', 'pegasus']:     \n",
    "        embeds = nn.Sequential(\n",
    "            model.model.shared, \n",
    "            model.model.encoder.embed_positions, \n",
    "            model.model.encoder.embed_tokens,\n",
    "            model.model.decoder.embed_positions, \n",
    "            model.model.decoder.embed_tokens\n",
    "        )\n",
    "        \n",
    "        groups = L(embeds, model.model.encoder, model.model.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "    \n",
    "    raise ValueError('Invalid architecture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"summarization_splitter\" class=\"doc_header\"><code>summarization_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>summarization_splitter</code>(**`m`**, **`arch`**)\n",
       "\n",
       "Custom param splitter for summarization models"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(summarization_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we don't really need a loss function, we have to provide a custom loss class/function for fastai to function properly (e.g. one with a `decodes` and `activation` methods).  Why?  Because these methods will get called in methods like `show_results` to get the actual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_MaskedLMLoss():\n",
    "    def __call__(self, inp, targ, **kwargs): return\n",
    "    def decodes(self, x): return x.argmax(dim=-1)\n",
    "    def activation(self, x): return F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': True,\n",
       " 'length_penalty': 2.0,\n",
       " 'max_length': 130,\n",
       " 'min_length': 30,\n",
       " 'no_repeat_ngram_size': 3,\n",
       " 'num_beams': 4}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_gen_kwargs = { **hf_config.task_specific_params['summarization'], **{'max_length': 130, 'min_length': 30} }\n",
    "text_gen_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "model_cb = HF_SummarizationModelCallback(text_gen_kwargs=text_gen_kwargs)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=ranger,\n",
    "                loss_func=HF_MaskedLMLoss(),\n",
    "                cbs=[model_cb],\n",
    "                splitter=partial(summarization_splitter, arch=hf_arch))#.to_fp16()\n",
    "\n",
    "learn.create_opt() \n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " tensor(3.2352, device='cuda:1', grad_fn=<NllLossBackward>),\n",
       " torch.Size([2, 70, 50264]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0], preds[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, torch.Size([2, 512]), 2, torch.Size([2, 71]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.00020892962347716094, lr_steep=0.0002754228771664202)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.466346</td>\n",
       "      <td>1.439261</td>\n",
       "      <td>0.393531</td>\n",
       "      <td>0.175944</td>\n",
       "      <td>0.269177</td>\n",
       "      <td>04:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.139633</td>\n",
       "      <td>1.448134</td>\n",
       "      <td>0.392608</td>\n",
       "      <td>0.179572</td>\n",
       "      <td>0.268698</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.986405</td>\n",
       "      <td>1.456029</td>\n",
       "      <td>0.393337</td>\n",
       "      <td>0.182789</td>\n",
       "      <td>0.267836</td>\n",
       "      <td>04:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=3e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to take advantage of huggingface's `PreTrainedModel.generate` model, which can be used to easily implement beam search, top-k/nucleous sampling, etc... so that we get more human sounding results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \n",
    "into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \n",
    "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \n",
    "Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \n",
    "but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \n",
    "of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \n",
    "cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \n",
    "occurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \n",
    "her, and took off for the French border. The other gunmen followed into France, which is only about 100 \n",
    "meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \n",
    "There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \n",
    "robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \n",
    "Gill said. The robbers spoke French and drove vehicles with French license plates. CNN's Andreena Narayan \n",
    "contributed to this report.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10 10About 10 men a\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict(test_article)\n",
    "print(res[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't look much like a human-generated summary.  Let's use huggingface's `PreTrainedModel.generate` method to create something more human-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Target ===\n",
      " Chinese amateur Guan Tianlang plays back nine of Augusta with Tiger Woods .\n",
      "Guan to become the youngest player in Masters history when play begins on Thursday .\n",
      "2011 British Open champion Darren Clarke forced to withdraw due to a hamstring injury .\n",
      "Jose Maria Olazabal apologizes to fan after hitting him in the head with a wayward shot .\n",
      "\n",
      "=== Prediction ===\n",
      " Chinese amateur golfer Guan Tianlang will become the youngest player in Masters history when he tees off on Thursday .\n",
      "Guan Tianlang was not even born when Tiger Woods won the Masters for the first time in 1997 .\n",
      "The 14-time major winner invited Guan to take in the back nine of the Augusta course on Monday .\n",
      "Woods is pleased his legacy has helped created a new generation of players .\n",
      "Darren Clarke forced to withdraw from the Masters with a hamstring injury .\n"
     ]
    }
   ],
   "source": [
    "test_input_ids = dls.train_ds[0][0]['input_ids'].unsqueeze(0).to(learn.model.hf_model.device)\n",
    "gen_text = learn.model.hf_model.generate(test_input_ids, num_beams=4, max_length=130, min_length=30)\n",
    "\n",
    "print('=== Target ===')\n",
    "print(f'{hf_tokenizer.decode(dls.train_ds[0][1][\"input_ids\"], skip_special_tokens=True, clean_up_tokenization_spaces=False)}\\n')\n",
    "\n",
    "print('=== Prediction ===')\n",
    "print(hf_tokenizer.decode(gen_text[0], skip_special_tokens=True, clean_up_tokenization_spaces=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add a `blurr_summarize` method to `Learner` that uses huggingface's `PreTrainedModel.generate` to create our predictions.  For the full list of arguments you can pass in see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate). You can also check out their [\"How To Generate\"](https://github.com/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb) notebook for more information about how it all works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_summarize(self:Learner, inp, **kwargs):\n",
    "    \"\"\"Uses the built-in `generate` method to generate the text \n",
    "    (see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
    "    for a list of arguments you can pass in)\n",
    "    \"\"\"\n",
    "    # grab the text generation kwargs\n",
    "    text_gen_kwargs = self.cbs.filter(lambda el: isinstance(el, HF_SummarizationModelCallback) )[0].text_gen_kwargs\n",
    "    text_gen_kwargs = { **text_gen_kwargs, **kwargs}\n",
    "    \n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_textblock_tfm.kwargs\n",
    "\n",
    "    if (isinstance(inp, str)):\n",
    "        input_ids = hf_tokenizer.encode(inp, padding=True, truncation=True, return_tensors='pt', **tok_kwargs)\n",
    "    else:\n",
    "        input_ids = inp\n",
    "        \n",
    "    input_ids = input_ids.to(self.model.hf_model.device)\n",
    "    \n",
    "    gen_texts = self.model.hf_model.generate(input_ids, **text_gen_kwargs)\n",
    "    outputs = [ hf_tokenizer.decode(txt, skip_special_tokens=True, clean_up_tokenization_spaces=False) \n",
    "               for txt in gen_texts ]\n",
    "    \n",
    "    if hf_textblock_tfm.hf_arch == 'pegasus':\n",
    "        outputs = [o.replace('<n>', ' ') for o in outputs]\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_summarize\" class=\"doc_header\"><code>Learner.blurr_summarize</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_summarize</code>(**`inp`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Uses the built-in `generate` method to generate the text \n",
       "(see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
       "for a list of arguments you can pass in)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino .\n",
      "One group tried to break into the casino's vault on the lower level but could not get in .\n",
      "A woman driving by unknowingly blocked the robbers' vehicles and was beaten by one of them .\n",
      "There were about 600 people in the casino at the time of the robbery .\n",
      "\n",
      "=== Prediction 2 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino .\n",
      "One group tried to break into the casino's vault on the lower level but could not get in .\n",
      "A woman driving by unknowingly blocked the robbers' vehicles with her car and was beaten by one of them .\n",
      "\n",
      "=== Prediction 3 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino .\n",
      "One group tried to break into the casino's vault on the lower level but could not get in .\n",
      "A woman driving by unknowingly blocked the robbers' vehicles and was beaten by one of them .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = learn.blurr_summarize(test_article, num_return_sequences=3)\n",
    "\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much nicer!!! Now, we can update our @typedispatched `show_results` to use this new method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_SummarizationInput, y, samples, outs, learner, ctxs=None, max_n=6, **kwargs):  \n",
    "    gen_text_txts = learner.blurr_summarize(x[0])\n",
    "    res = L([ (sample[0], sample[1], gen_txt) for sample, gen_txt in zip(samples, gen_text_txts) ])          \n",
    "    \n",
    "    display_df(pd.DataFrame(res, columns=['text', 'target', 'prediction'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- Rory McIlroy has been reflecting on his meltdown at the Masters, after the 21-year-old squandered a four-stroke lead going into the final round at Augusta, eventually carding an eight-over-par 80 to finish 10 strokes behind winner Charl Schwartzel. Speaking to the official Masters website, the Northern Irishman said: \"I'm very disappointed. \"I was leading this golf tournament with nine holes to go, and I just unraveled. Hit a bad tee shot on 10, and then never really recovered. It's going to be hard to take for a few days, but I'll get over it.\" McIlroy is not alone in crumbling on the back nine whilst leading the Masters and joins a famous list that includes great names such as Ben Hogan, Arnold Palmer, Scott Hoch and Greg Norman. Can McIlroy conquer mental minefield? And McIlory admitted that when he missed the fairway on the 13th hole, he knew his Masters dream had died. \"I'd knew that unless I birdied my way in, I realized I didn't have a chance,\" McIlroy said. \"I realized that was it then. \"But this is my first experience at it and hopefully the next time I'm in this position I'll be able to handle it better. \"I didn't handle it particularly well obviously, but it was a character-building day, put it that way. I'll come out stronger for it.\" And, speaking on his Twitter feed, McIlroy quoted Muhammad Ali, saying: \"It's repetition of affirmations that leads to belief -- and once that belief becomes a deep conviction, things begin to happen.\" McIlory also received some words of encouragement from Schwartzel who said: \"Golf is a really funny game -- one moment you're on top of it, the next moment it bites you. \"Rory is going to feel hurt. It's not easy what he went through. He is such a phenomenal player and he will win one. \"The first just happens to be the toughest, and that may be the biggest lesson of all,\" added the South African.</td>\n",
       "      <td>Rory McIlory has spoken about his final round heartbreak at the Masters.\\nThe 21-year-old wasted a four-stroke lead to finish 10 shots behind Charl Schwartzel.\\nThe Northern Irishman also quoted boxer Muhammad Ali on his Twitter page.</td>\n",
       "      <td>Rory McIlroy has been reflecting on his meltdown at the Masters .\\nThe Northern Irishman squandered a four-stroke lead going into the final round at Augusta .\\nMcIlroy carded an eight-over-par 80 to finish 10 strokes behind winner Charl Schwartzel .\\nSchwartzel has given McIlory words of encouragement and says he will win the tournament .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN)  -- The girlfriend of former NFL star Steve McNair first shot him in his right temple, then fired three more shots at close range, most likely as he slept, police said Wednesday. Steve McNair, 36, spent 13 seasons in the NFL, the majority with the Tennessee Titans. She then sat on the couch next to his body, and killed herself so that she would fall into his lap, they said. \"The totality of the evidence clearly points to a murder-suicide,\" Nashville, Tennessee, Police Chief Ronal Serpas told reporters at an afternoon news conference. McNair, 36, and Sahel Kazemi, 20, were found fatally shot in a condominium in downtown Nashville on Saturday afternoon, authorities said. \"McNair was seated on the sofa and likely was asleep, and we believe that Kazemi shot him in the right temple, then shot him twice in the chest, and then shot him a final time in the left temple,\" Serpas said.  Watch police chief describe murder-suicide ». \"Kazemi then positioned herself next to McNair on the sofa and shot herself once in the right temple and expired.... We do believe she tried to stage that when she killed herself, she would fall in his lap.\" A trace of gunshot residue was found on her left hand, he said. Kazemi used a 9 mm handgun, Serpas said. McNair was married and had four children. Serpas said he had spoken with McNair's wife Wednesday to update her on the investigation. The police chief said Kazemi had become rattled over the last week, believing that McNair was involved with another woman. \"She had become very distraught and on two occasions told friends and associates that her life was all messed up and that she was going to end it all,\" Serpas said. He said Kazemi had seen another person leave the condo a few days before and was concerned \"whether or not her relationship was unraveling with Mr. McNair.\" \"There was evidence that she was spinning out of control,\" Serpas said. He added that there was no evidence found at the condo indicating anyone else was there at the time of the deaths, which is believed to be after 1 a.m. Saturday. Dr. Feng Li, the assistant medical examiner who has been handling the case, told CNN earlier Wednesday that all evidence was \"indicating that she killed Mr. McNair and killed herself.\" \"It's almost an assured thing. We have to be convinced otherwise</td>\n",
       "      <td>\"The totality of the evidence clearly points to a murder-suicide,\" chief says.\\nCoroner: \"It's almost an assured thing. We have to be convinced otherwise\"\\nMcNair and his girlfriend, Sahel Kazemi, were found shot to death Saturday.</td>\n",
       "      <td>Police: Girlfriend shot ex-NFL star Steve McNair in right temple, then fired three more shots at close range .\\nSahel Kazemi then sat on couch next to his body and shot herself, police say .\\nPolice: Evidence \"clearly points to a murder-suicide\"\\nMcNair, Kazemi found fatally shot in downtown Nashville condo on Saturday afternoon .\\nKazemi had become \"distraught\" over McNair's possible involvement with another woman, police chief says .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname='summarize_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\\nA woman driving by unknowingly blocked the robbers' vehicles and was beaten by one of them .\\nThere were about 600 people in the casino at the time of the robbery .\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname='summarize_export.pkl')\n",
    "inf_learn.blurr_summarize(test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-token-classification.ipynb.\n",
      "Converted 01b_data-question-answering.ipynb.\n",
      "Converted 01e_data-summarization.ipynb.\n",
      "Converted 01z_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-token-classification.ipynb.\n",
      "Converted 02b_modeling-question-answering.ipynb.\n",
      "Converted 02e_modeling-summarization.ipynb.\n",
      "Converted 02z_modeling-language-modeling.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
