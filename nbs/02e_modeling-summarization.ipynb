{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.summarization\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai2.text.all import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from rouge_score import rouge_scorer, scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "\n",
    "The objective of summarization is to generate a concise and accurate representation of a much larger body of text.  For example, we may want to summarize an article in a single sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('./')\n",
    "cnndm_df = pd.read_csv(path/'cnndm_sample.csv'); len(cnndm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...</td>\n",
       "      <td>John Sexton: Traditionally, universities have been defined and limited by location .\\nGlobal campuses form a network of thought, innovation, he writes .\\nFaculty can teach, Sexton says, students can team up in many cities at once .\\nSexton: Research, scholarship can be shared and cultural ties made in \"century of knowledge\"</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will \"hopefully bring some order\" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...</td>\n",
       "      <td>NEW: Protest moves after crackdown at Freedom Square .\\nOrder sought after protests over last month's election turn violent .\\nDemonstrators say the election was fraudulent .\\nState of emergency could last until March 20, official says .</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   article  \\\n",
       "0  (CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...   \n",
       "1  (CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will \"hopefully bring some order\" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                              highlights  \\\n",
       "0  John Sexton: Traditionally, universities have been defined and limited by location .\\nGlobal campuses form a network of thought, innovation, he writes .\\nFaculty can teach, Sexton says, students can team up in many cities at once .\\nSexton: Research, scholarship can be shared and cultural ties made in \"century of knowledge\"   \n",
       "1                                                                                          NEW: Protest moves after crackdown at Freedom Square .\\nOrder sought after protests over last month's election turn violent .\\nDemonstrators say the election was fraudulent .\\nState of emergency could last until March 20, official says .   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnndm_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large-cnn and are newly initialized: ['final_logits_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bart',\n",
       " transformers.configuration_bart.BartConfig,\n",
       " transformers.tokenization_bart.BartTokenizer,\n",
       " transformers.modeling_bart.BartForConditionalGeneration)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               model_cls=BartForConditionalGeneration)\n",
    "\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_batch_tfm = HF_SummarizationBatchTransform(hf_arch, hf_tokenizer)\n",
    "\n",
    "blocks = ( \n",
    "    HF_TextBlock(hf_arch, hf_tokenizer), \n",
    "    HF_TextBlock(hf_arch, hf_tokenizer, hf_batch_tfm=hf_batch_tfm, max_length=150)\n",
    ")\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('article'), \n",
    "                   get_y=ColReader('highlights'), \n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(cnndm_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([4, 512]), torch.Size([4, 150]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHICAGO, Illinois (CNN) -- Police are investigating the death of the former chief fundraiser for ex-Illinois Gov. Rod Blagojevich as a \"death-suicide,\" an Illinois mayor said Sunday. Christopher Kelly, 51, was former Illinois Gov. Rod Blagojevich's chief fundraiser. Financier Christopher Kelly told police shortly before he died Saturday that he took an \"overdose of drugs,\" said Dwight Welch, mayor of Country Club Hills, Illinois. Country Club Hills police found several drugs in Kelly's black 2007 Cadillac Escalade, but they were not sure yet whether they were prescribed, Welch said. Country Club Hills is about 27 miles south of Chicago. Kelly had recently undergone surgery and was taking drugs following the operation, Welch said. Welch said he did not know which drugs Kelly was taking. Kelly, 51, of Burr Ridge, Illinois, was pronounced dead at Stroger hospital in Cook County at 10:46 a.m. Saturday, hospital spokesman Marcel Bright told CNN. Autopsy results were expected Sunday afternoon, Welch said. The Cook County Medical Examiner's Office did not comment on the results, but said that a ruling on Kelly's death was \"pending further studies.\" Toxicology results won't be available for \"some time,\" Welch said. Blagojevich blamed the government for Kelly's death. \"I don't know any more than you know, except that a friend of mine took his life because he refused to submit to the pressure by the government to lie about me,\" Blagojevich told CNN. \"And to think that it comes to something like that begs a lot of questions.\" Blagojevich said his statement that Kelly \"took his life\" was based on what he had read in news reports. Earlier this year, Blagojevich, who was impeached and removed from office, pleaded not guilty to federal corruption charges. A federal grand jury in April indicted him on 16 felony counts, including racketeering, conspiracy, wire fraud and making false statements to investigators. The indictment also named Kelly. On Tuesday in a separate case, Kelly pleaded guilty to two counts of mail fraud \"in a kickback scheme to bring in $8.5 million in business at O'Hare International Airport to his roofing company,\" the Chicago Tribune reported on its Web site Sunday. Kelly was to begin a prison sentence this week, the Tribune reported. Kelly was transferred to Stroger hospital after first receiving care at Oak Forest Hospital</td>\n",
       "      <td>NEW: Police want to talk to Kelly's girlfriend, who took him to hospital, mayor says.\\nChristopher Kelly, before dying, told police he overdosed, an Illinois mayor says.\\nKelly was named in indictment in Blagojevich case.\\nIn separate case, Kelly pleaded guilty to mail fraud on Tuesday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- The iconic image of the neighborhood drugstore and wise and friendly pharmacist were once part of the American social fabric. The local pharmacy was where we went to pursue romance over an ice cream soda, share gossip with members of our community or acquire our most basic supplies. Pharmacists were our friends, our neighbors and those we looked to for help and aid. But increasingly, as the local pharmacy transformed into the large chain drug store, the analgesics and advice were joined by something quite different and deadly: tobacco products. Along with medicines, greeting cards and cosmetics, large retailers and pharmacies like Walmart, Rite Aid and Walgreens sell cigarettes and other tobacco products, despite the fact that we know they are harmful. But on Wednesday, CVS/Caremark stepped up and declared loud and clear: Cigarettes and health care cannot and should not coexist under the same roof. We applaud CVS for taking the bold and socially conscious step to stop selling cigarettes and other tobacco products effective October 1. More than 7,600 CVS stores across the nation will no longer sell these products -- impacting thousands of customers across the country and helping to promote longer, healthier lives. Despite intense competition in the industry, CVS had the vision and the conviction to do what is right for its customers. Each year in our country, more than 480,000 Americans lose their lives to tobacco-related diseases, including heart disease, cancers, emphysema and stroke. Tobacco use also takes a huge toll on our economy, from lost productivity to the medical care costs of treating sick smokers. But tobacco-related disease is wholly preventable. Proven tactics such as raising the price of tobacco products, clean indoor air laws, and effective public education campaigns can help drive smoking rates down. For years, these have been the tools of government and nonprofit organizations like Legacy Foundation. CVS brought a critical additional tool to bear -- limiting access to tobacco -- and issued a clarion call for retailers to join the fight to change the culture around tobacco use to make it less socially acceptable. Removing tobacco products from pharmacy shelves -- where they are often both an eye-level temptation for youth who are open to smoking and a trigger for smokers struggling to quit -- will help foster positive changes in our attitudes toward smoking. We challenge other large retailers to take the same step and put their customers' health and well-being ahead of their profit margins. CVS's decision shows that the for-profit sector can truly do good. Increasingly, America's pharmacies are</td>\n",
       "      <td>CVS/Caremark announced that it will stop selling cigarettes and tobacco products.\\nRobin Koval: This is a bold and socially conscious move that helps customers.\\nShe say more pharmacies want to serve as trusted health care providers.\\nKoval: It makes no sense to be health provider while selling harmful tobacco products.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(hf_tokenizer=hf_tokenizer, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for summarization tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_rouge(predicted_txts, reference_txts, rouge_keys=[\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True):\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_keys, use_stemmer=use_stemmer)\n",
    "    aggregator = scoring.BootstrapAggregator()\n",
    "\n",
    "    for ref_text, pred_txt in zip(reference_txts, predicted_txts):\n",
    "        scores = scorer.score(ref_text, pred_txt)\n",
    "        aggregator.add_scores(scores)\n",
    "\n",
    "    result = aggregator.aggregate()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Here we create a summarization specific subclass of `HF_BaseModelCallback` in order to include custom, summarization specific, metrics, and also handle the pre-calculated loss during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_SummarizationModelCallback(HF_BaseModelCallback):  \n",
    "    def __init__(self, rouge_metrics=[\"rouge1\", \"rouge2\", \"rougeL\"], text_gen_kwargs={}, **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self, 'rouge_metrics, text_gen_kwargs, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in rouge_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the target's HF_TokenizerTransform (used for rouge metrics)\n",
    "        hf_textblock_tfm = self.learn.dls.tfms[-1]\n",
    "        self.hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "        self.tok_kwargs = hf_textblock_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def begin_fit(self): self.setup()\n",
    "        \n",
    "        \n",
    "    # --- batch begin/after phases ---\n",
    "    def begin_batch(self): self.hf_loss = None\n",
    "        \n",
    "    def after_pred(self): \n",
    "        # the \"labels\" key will only be included in the input dictionary *IF* we are training with target labels, \n",
    "        # in which case the first output of the model will be the loss\n",
    "        if ('labels' in self.xb[0]):\n",
    "            self.hf_loss, self.learn.pred = self.pred[0], self.pred[1]\n",
    "        else:\n",
    "            self.learn.pred = self.pred[0]\n",
    "            \n",
    "    def after_loss(self): \n",
    "        # if we already have the loss from the model, update the Learner's loss to be it\n",
    "        if (self.hf_loss is not None): self.learn.loss = self.hf_loss\n",
    "        \n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # grab predicted and reference ids for any metrics that need them\n",
    "        input_ids, attention_mask = self.xb[0]['input_ids'], self.xb[0]['attention_mask']\n",
    "        gen_ids = self.learn.model.hf_model.generate(input_ids=input_ids, \n",
    "                                                     attention_mask=attention_mask, \n",
    "                                                     use_cache=True,\n",
    "                                                     **self.text_gen_kwargs)\n",
    "        \n",
    "        self.generated_ids += gen_ids.tolist()\n",
    "        self.refernce_ids += self.yb[0].tolist()\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def begin_validate(self): self.generated_ids, self.refernce_ids = [], []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        # are there rouge metrics to calculate?\n",
    "        if (self.rouge_metrics is not None and len(self.rouge_metrics) > 0):\n",
    "            gen_texts = self.hf_tokenizer.batch_decode(self.generated_ids, \n",
    "                                                       skip_special_tokens=True, \n",
    "                                                       clean_up_tokenization_spaces=True)\n",
    "\n",
    "            ref_texts = self.hf_tokenizer.batch_decode(self.refernce_ids, \n",
    "                                                       skip_special_tokens=True, \n",
    "                                                       clean_up_tokenization_spaces=True)\n",
    "\n",
    "            rouge_results = calculate_rouge(gen_texts, ref_texts, rouge_keys=self.rouge_metrics)\n",
    "            \n",
    "            for rouge_key, scores in rouge_results.items(): \n",
    "                self.custom_metrics_dict[rouge_key] = scores.mid.fmeasure\n",
    "                \n",
    "\n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a custom param splitter to give us a bit more depth in applying discriminative learning rates for summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def summarization_splitter(m, arch):\n",
    "    \"\"\"Custom param splitter for summarization models\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, 'hf_model')) else m\n",
    "    \n",
    "    if (arch == 'bart'):     \n",
    "        embeds = nn.Sequential(\n",
    "            model.model.shared, \n",
    "            model.model.encoder.embed_positions, \n",
    "            model.model.encoder.embed_tokens,\n",
    "            model.model.decoder.embed_positions, \n",
    "            model.model.decoder.embed_tokens\n",
    "        )\n",
    "        \n",
    "        groups = L(embeds, model.model.encoder, model.model.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "    \n",
    "    raise ValueError('Invalid architecture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"summarization_splitter\" class=\"doc_header\"><code>summarization_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>summarization_splitter</code>(**`m`**, **`arch`**)\n",
       "\n",
       "Custom param splitter for summarization models"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(summarization_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we don't really need a loss function, we have to provide a custom loss class/function for fastai to function properly (e.g. one with a `decodes` and `activation` methods).  Why?  Because these methods will get called in methods like `show_results` to get the actual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_MaskedLMLoss():\n",
    "    def __call__(self, inp, targ, **kwargs): return\n",
    "    def decodes(self, x): return x.argmax(dim=-1)\n",
    "    def activation(self, x): return F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': True,\n",
       " 'length_penalty': 2.0,\n",
       " 'max_length': 130,\n",
       " 'min_length': 30,\n",
       " 'no_repeat_ngram_size': 3,\n",
       " 'num_beams': 4}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_gen_kwargs = { **hf_config.task_specific_params['summarization'], **{'max_length': 130, 'min_length': 30} }\n",
    "text_gen_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "model_cb = HF_SummarizationModelCallback(text_gen_kwargs=text_gen_kwargs)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=ranger,\n",
    "                loss_func=HF_MaskedLMLoss(),\n",
    "                cbs=[model_cb],\n",
    "                splitter=partial(summarization_splitter, arch=hf_arch))#.to_fp16()\n",
    "\n",
    "learn.create_opt() \n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " tensor(3.5072, device='cuda:1', grad_fn=<NllLossBackward>),\n",
       " torch.Size([4, 149, 50264]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0], preds[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, torch.Size([4, 512]), 4, torch.Size([4, 150]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.0002511886414140463, lr_steep=0.0005754399462603033)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.708176</td>\n",
       "      <td>1.457652</td>\n",
       "      <td>0.399363</td>\n",
       "      <td>0.182079</td>\n",
       "      <td>0.284496</td>\n",
       "      <td>03:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.323971</td>\n",
       "      <td>1.430543</td>\n",
       "      <td>0.405772</td>\n",
       "      <td>0.184912</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>03:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.196899</td>\n",
       "      <td>1.429245</td>\n",
       "      <td>0.407611</td>\n",
       "      <td>0.187018</td>\n",
       "      <td>0.283407</td>\n",
       "      <td>03:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=3e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to take advantage of huggingface's `PreTrainedModel.generate` model, which can be used to easily implement beam search, top-k/nucleous sampling, etc... so that we get more human sounding results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \n",
    "into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \n",
    "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \n",
    "Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \n",
    "but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \n",
    "of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \n",
    "cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \n",
    "occurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \n",
    "her, and took off for the French border. The other gunmen followed into France, which is only about 100 \n",
    "meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \n",
    "There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \n",
    "robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \n",
    "Gill said. The robbers spoke French and drove vehicles with French license plates. CNN's Andreena Narayan \n",
    "contributed to this report.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The TheAbout 10 men\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict(test_article)\n",
    "print(res[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't look much like a human-generated summary.  Let's use huggingface's `PreTrainedModel.generate` method to create something more human-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Target ===\n",
      " NEW: Police want to talk to Kelly's girlfriend, who took him to hospital, mayor says .\n",
      "Christopher Kelly, before dying, told police he overdosed, an Illinois mayor says .\n",
      "Kelly was named in indictment in Blagojevich case .\n",
      "In separate case, Kelly pleaded guilty to mail fraud on Tuesday .\n",
      "\n",
      "=== Prediction ===\n",
      " Financier Christopher Kelly told police he took an \"overdose of drugs,\" mayor of Country Club Hills, Illinois, says .\n",
      "Kelly, 51, pronounced dead at Stroger hospital in Cook County at 10:46 a.m. Saturday .\n",
      "Police found several drugs in Kelly's black 2007 Cadillac Escalade, but not sure if prescribed, mayor says .\n"
     ]
    }
   ],
   "source": [
    "test_input_ids = dls.train_ds[0][0]['input_ids'].unsqueeze(0).to(learn.model.hf_model.device)\n",
    "gen_text = learn.model.hf_model.generate(test_input_ids, num_beams=4, max_length=130, min_length=30)\n",
    "\n",
    "print('=== Target ===')\n",
    "print(f'{hf_tokenizer.decode(dls.train_ds[0][1][\"input_ids\"], skip_special_tokens=True, clean_up_tokenization_spaces=False)}\\n')\n",
    "\n",
    "print('=== Prediction ===')\n",
    "print(hf_tokenizer.decode(gen_text[0], skip_special_tokens=True, clean_up_tokenization_spaces=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add a `blurr_summarize` method to `Learner` that uses huggingface's `PreTrainedModel.generate` to create our predictions.  For the full list of arguments you can pass in see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate). You can also check out their [\"How To Generate\"](https://github.com/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb) notebook for more information about how it all works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_summarize(self:Learner, inp, **kwargs):\n",
    "    \"\"\"Uses the built-in `generate` method to generate the text \n",
    "    (see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
    "    for a list of arguments you can pass in)\n",
    "    \"\"\"\n",
    "    # grab the text generation kwargs\n",
    "    text_gen_kwargs = self.cbs.filter(lambda el: isinstance(el, HF_SummarizationModelCallback) )[0].text_gen_kwargs\n",
    "    text_gen_kwargs = { **text_gen_kwargs, **kwargs}\n",
    "    \n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_textblock_tfm.kwargs\n",
    "\n",
    "    if (isinstance(inp, str)):\n",
    "        input_ids = hf_tokenizer.encode(inp, padding=True, truncation=True, return_tensors='pt', **tok_kwargs)\n",
    "    else:\n",
    "        input_ids = inp\n",
    "        \n",
    "    input_ids = input_ids.to(self.model.hf_model.device)\n",
    "    \n",
    "    gen_texts = self.model.hf_model.generate(input_ids, **text_gen_kwargs)\n",
    "    outputs = [ hf_tokenizer.decode(txt, skip_special_tokens=True, clean_up_tokenization_spaces=False) \n",
    "               for txt in gen_texts ]\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_summarize\" class=\"doc_header\"><code>Learner.blurr_summarize</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_summarize</code>(**`inp`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Uses the built-in `generate` method to generate the text \n",
       "(see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
       "for a list of arguments you can pass in)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      " About 10 men with pistols and machine guns raid a casino in Switzerland and make off with several hundred thousand Swiss francs .\n",
      "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\n",
      "One group tried to break into the casino's vault on the lower level but could not get in .\n",
      "They then robbed the cashier of the money that was not secured, police say .\n",
      "There were no serious injuries, although one guest was kicked in the head by one of the robbers when he moved .\n",
      "\n",
      "=== Prediction 2 ===\n",
      " About 10 men with pistols and machine guns raid a casino in Switzerland and make off with several hundred thousand Swiss francs .\n",
      "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\n",
      "One group tried to break into the casino's vault on the lower level but could not get in .\n",
      "They then robbed the cashier of the money that was not secured, police say .\n",
      "There were no serious injuries, although one guest was kicked in the head by one of the robbers .\n",
      "\n",
      "=== Prediction 3 ===\n",
      " About 10 men with pistols and machine guns raid a casino in Switzerland and make off with several hundred thousand Swiss francs .\n",
      "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\n",
      "One group tried to break into the casino's vault on the lower level but could not get in .\n",
      "They then robbed the cashier of the money that was not secured, police say .\n",
      "A woman driving by unknowingly blocked the gunmen's vehicles and was beaten to death .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = learn.blurr_summarize(test_article, num_return_sequences=3)\n",
    "\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much nicer!!! Now, we can update our @typedispatched `show_results` to use this new method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_SummarizationInput, y, samples, outs, learner, ctxs=None, max_n=6, **kwargs):  \n",
    "    gen_text_txts = learner.blurr_summarize(x[0])\n",
    "    res = L([ (sample[0], sample[1], gen_txt) for sample, gen_txt in zip(samples, gen_text_txts) ])          \n",
    "    \n",
    "    display_df(pd.DataFrame(res, columns=['text', 'target', 'prediction'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- The U.S. Olympic Committee said Friday that the uniforms for the opening and closing ceremonies at the 2014 Olympic Winter Games will be made in the United States. The news came after it was revealed that American athletes at this year's games are going to be wearing clothing manufactured in China -- a fact that sparked outrage from some lawmakers and human rights activists. Ralph Lauren and the USOC were bombarded on Facebook and Twitter by critics who demanded the fashion design company manufacture new uniforms in the United States. From our readers: Forget uniforms, U.S. Olmypians should 'go naked' \"With athletes having already arrived in London, and the apparel distribution process beginning this weekend, we are unfortunately not able to make a change for London,\" USOC CEO Scott Blackmun said in a statement. \"We are absolutely committed, however, to working with our sponsors to ensure that the concerns voiced are addressed. To that end, Ralph Lauren has agreed to domestically manufacture Team USA's apparel for Opening and Closing Ceremonies for the 2014 Olympic Winter Games,\" he said. \"In the meantime, we ask for the American people's support. The members of Team USA have dedicated their entire lives to training for this one moment. They are some of the finest men and women this country has to offer and they are prepared to succeed both on and off the field of play in London. Our country should be proud of the individual athletes that will represent them in London and I'm hopeful that everyone will rally around Team USA,\" Blackmun said. Ralph Lauren similarly released a statement Friday, confirming it would manufacture uniforms domestically for the 2014 games. \"For more than 45 years Ralph Lauren has built a brand that embodies the best of American quality and design rooted in the rich heritage of our country,\" it said, promising to \"lead the conversation within our industry and our government addressing the issue of increasing manufacturing in the United States.\" Previously, the USOC had defended the uniforms. In a statement Thursday, USOC spokesman Patrick Sandusky said that \"unlike most Olympic teams around the world, the U.S. Olympic Team is privately funded and we're grateful for the support of our sponsors.\" He described the criticism as nonsense in a tweet. In testimony before Congress last year, the American Apparel and Footwear Association said that 98% of all apparel and 99% of all footwear sold in the United States are manufactured abroad. According to the Labor Department, 10 years ago, there were more than 350,000 Americans employed by apparel manufacturers.</td>\n",
       "      <td>NEW: Ralph Lauren promises to address the issue of increasing U.S. manufacturing.\\nThe USOC says it is unable to make a change in time for London.\\nControversy erupted after it was revealed U.S. athletes will be wearing clothing made in China.\\nSen. Harry Reid says Team USA uniforms manufactured in China should be destroyed.</td>\n",
       "      <td>NEW: Ralph Lauren confirms it will manufacture uniforms domestically for the 2014 games .\\nThe uniforms for the opening and closing ceremonies will be made in the United States, the USOC says .\\nAthletes at this year's games are going to be wearing clothing manufactured in China .\\nThat fact sparked outrage from some lawmakers and human rights activists .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- The future of around 2,000 Dutch soldiers serving in Afghanistan has been thrown into doubt by the collapse Saturday of the Netherlands' coalition government. Dutch Prime Minister Jan Peter Balkenende's office said in a statement that the Labor Party had withdrawn from the government following days of talks over whether the troops should be brought home. Balkenende's center-right Christian Democratic Alliance had hoped to keep the country's troops in Afghanistan as part of NATO's International Security and Assistance Force beyond an August deadline for their return. NATO Secretary-General Anders Fogh Rasmussen asked the Netherlands to extend its mission in Afghanistan earlier this month. The Netherlands currently has 1,950 troops serving in Afghanistan's Uruzgan province as part of NATO's International Security and Assistance Force, according to the ISAF Web site. The Dutch government extended the military mission by two years back in 2007. But the Labor Party, led by Deputy Prime Minister Wouter Bos, opposed fulfilling NATO's request to extend the mission again. Bos said that the current Afghanistan policy was not sustainable, according to the official ANP news agency. In a statement to reporters, Balkenende said there was no longer a \"fruitful path\" for the near-three-year-old coalition between the CDA, Labor and the Christian Union to go forward. He said he would meet Queen Beatrix, the country's head of state, later Saturday to offer the resignations of the 12 Labor members of his cabinet and \"make available\" the 12 cabinet positions held by his own party and three held by the Christian Union. The move is expected to trigger early general elections in the country. Balkenende has led a succession of coalitions since becoming prime minister in 2002. The CDA, Labor and Christian Union entered into a coalition agreement in February 2007 following elections in November 2006. But the three parties have disagreed on several issues including Afghanistan.</td>\n",
       "      <td>Labor Party members quit the coalition government after talks fail.\\nSpeculation that the political squabble over Afghanistan could not be settled.\\nThe Netherlands has roughly 2,000 troops serving in Afghanistan's Uruzgan province.</td>\n",
       "      <td>Netherlands currently has 1,950 troops serving in Afghanistan's Uruzgan province as part of NATO's ISAF .\\nThe Labor Party, led by Deputy Prime Minister Wouter Bos, opposed fulfilling NATO's request to extend mission .\\nBos: Current Afghanistan policy was not sustainable, according to official ANP news agency .\\nPrime Minister Jan Peter Balkenende has led a succession of coalitions since becoming prime minister in 2002 .\\nHe said there was no longer a \"fruitful path\" for the coalition to go forward .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(CNN) -- They were the liars. The \"trolls.\" The bitter, vindictive and jealous. They were Lance Armstrong's first and fiercest critics, frequently castigated by the once-dominant athlete and celebrity cancer survivor, shunned by sponsors, race organizers and many of the cyclist's loyal followers. Now, on the cusp of the broadcast of an interview in which Armstrong is said to finally acknowledge what he had fiercely denied for years -- that he used performance-enhancing substances -- they are finally feeling vindicated. \"He was Tony Soprano,\" author Dan Coyle, who wrote a book about Armstrong, told CNN's Anderson Cooper. \"When you crossed him, he cut you dead. You were gone. The question is, is he going to apologize to the people he hurt along the way? \" Former Armstrong teammate Frankie Andreu also talked about Armstrong's wrath. \"Anybody that crossed his path or didn't go along with his plan, he set out to take them down. And he was very powerful and influential and did take them down,\" Andreu told ESPN radio host Colin Cowherd on Tuesday. Interview won't reduce sanctions. \"So it's kind of a big turnaround, it's a big surprise now with him going on 'Oprah' and supposedly admitting to doping during his career, which of course he's always denied,\" Andreu said. Winfrey, appearing on \"CBS This Morning,\" appeared to confirm media reports Tuesday that Armstrong acknowledged using performance enhancing substances in his interview with her. She didn't reveal details of his statements, which will run on her OWN cable network and on the Internet on two nights beginning Thursday. Armstrong has long denied using performance enhancers during what had been a record-setting cycling career. But in a scathing report last year, the U.S. Anti Doping Agency accused him of being at the heart of a sophisticated doping program. Andreu and his wife, Betsy, say they fell into disfavor with Armstrong after testifying in an arbitration case filed against Armstrong by a company seeking to avoid paying out bonuses to him for race victories during which he was accused of doping. In their testimony, they told of a 1996 incident in an Indianapolis hospital room in which, they said, Armstrong told doctors treating him for cancer that he had taken a variety of performance enhancing drugs. Public takes shots at Armstrong in advance of interview. \"After that, it was all-out attack, war on my wife and I,\" Andreu told Cowherd</td>\n",
       "      <td>A confession \"won't be enough\" for Armstrong, author says.\\nCritics have accused Lance Armstrong of bullying them for years.\\nNow, Armstrong is said to acknowledge doping in a television interview.\\n\"It's kind of a big turnaround,\" a former teammate tells ESPN.</td>\n",
       "      <td>Armstrong has long denied using performance enhancers during what had been a record-setting cycling career .\\nBut in a scathing report last year, the U.S. Anti Doping Agency accused him of being at the heart of a sophisticated doping program .\\n\"It's kind of a big turnaround, it's a big surprise now with him going on 'Oprah' and supposedly admitting to doping,\" former teammate Frankie Andreu says .\\nAndreu and his wife say they fell into disfavor with Armstrong after testifying in an arbitration case .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(CNN) -- Saudi Arabia is re-establishing its diplomatic presence in Egypt after tensions briefly spurred the kingdom to pull its envoys and shutter its missions, Egyptian and Saudi state news agencies said Friday. Ambassador Ahmad Kattan is returning to his post in Cairo, and Saudi Arabia's embassy and consulate will reopen by Sunday, the agencies said. Saudi Arabia called back Kattan and closed its embassy and consulates last Sunday after raucous protests in Cairo over the imprisonment of Ahmed Mohammed el-Gezawi, an Egyptian human rights lawyer. Throngs of Egyptians had gathered in front of the Saudi Embassy last week, calling for the release of el-Gezawi. The decision to pull out Saudi diplomats came after protesters' \"attempts to storm and threaten the security and safety of its (embassy) employees,\" the Saudi Press Agency said. Saudi officials say el-Gezawi is accused of trying to smuggle thousands of pills into the country. The Egyptian Organization for Human Rights say el-Gezawi had been traveling during Umrah, a minor pilgrimage to Mecca, when he was detained. \"What has happened in the recent days of repercussions in the relationship between the two countries is painful to every honorable Saudi and Egyptian citizen, and our decision to recall the ambassador and the closure of the embassy were only to protect its employees from other situations that could have developed with dire consequences,\" the Saudi Press Agency said, quoting King Abdullah bin Abdul Aziz. \"We will not allow this incidental crisis to prolong.\" The protests and the Saudi reaction appear to have again ratcheted up long-standing tensions between the two Middle Eastern nations. The strains can be traced back to 1979, when the kingdom broke off diplomatic relations after Egypt inked a peace deal with Israel based on the Camp David Accords. The ties were restored in November 1987. Egypt, the most populous Arab country, has often engaged in \"a subtle competition\" with its Saudi counterparts \"over this question of regional leadership,\" Cook said. Egypt erupted in protest last year during 18 days of demonstrations in Cairo's Tahrir Square after similar uprisings in neighboring Tunisia, ultimately ousting Egypt's longtime president Hosni Mubarak after nearly three decades in power. CNN's Saad Abedine contributed to this report.</td>\n",
       "      <td>Saudi Ambassador Ahmad Kattan is returning to Egypt.\\n\"We will not allow this incident crisis to prolong,\" King Abdullah says.\\nThe ambassador was pulled after protests in front of the Saudi Embassy.</td>\n",
       "      <td>Saudi Arabia is re-establishing its diplomatic presence in Egypt after tensions briefly spurred the kingdom to pull its envoys .\\nEgyptian and Saudi state news agencies say ambassador Ahmad Kattan is returning to his post in Cairo .\\nSaudi Arabia's embassy and consulate will reopen by Sunday, the agencies say .\\nThe strains can be traced back to 1979, when the kingdom broke off diplomatic relations with Egypt .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname='summarize_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" About 10 men with pistols and machine guns raid a casino in Switzerland and make off with several hundred thousand Swiss francs .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\\nThey then robbed the cashier of the money that was not secured, police say .\\nThere were no serious injuries, although one guest was kicked in the head by one of the robbers when he moved .\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname='summarize_export.pkl')\n",
    "inf_learn.blurr_summarize(test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-language-modeling.ipynb.\n",
      "Converted 01c_data-question-answering.ipynb.\n",
      "Converted 01d_data-token-classification.ipynb.\n",
      "Converted 01e_data-summarization.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-language-modeling.ipynb.\n",
      "Converted 02c_modeling-question-answering.ipynb.\n",
      "Converted 02d_modeling-token-classification.ipynb.\n",
      "Converted 02e_modeling-summarization.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
