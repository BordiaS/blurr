{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.summarization\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from rouge_score import rouge_scorer, scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "\n",
    "The objective of summarization is to generate a concise and accurate representation of a much larger body of text.  For example, we may want to summarize an article in a single sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('./')\n",
    "cnndm_df = pd.read_csv(path/'cnndm_sample.csv'); len(cnndm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...</td>\n",
       "      <td>John Sexton: Traditionally, universities have been defined and limited by location .\\nGlobal campuses form a network of thought, innovation, he writes .\\nFaculty can teach, Sexton says, students can team up in many cities at once .\\nSexton: Research, scholarship can be shared and cultural ties made in \"century of knowledge\"</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will \"hopefully bring some order\" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...</td>\n",
       "      <td>NEW: Protest moves after crackdown at Freedom Square .\\nOrder sought after protests over last month's election turn violent .\\nDemonstrators say the election was fraudulent .\\nState of emergency could last until March 20, official says .</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   article  \\\n",
       "0  (CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...   \n",
       "1  (CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will \"hopefully bring some order\" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                              highlights  \\\n",
       "0  John Sexton: Traditionally, universities have been defined and limited by location .\\nGlobal campuses form a network of thought, innovation, he writes .\\nFaculty can teach, Sexton says, students can team up in many cities at once .\\nSexton: Research, scholarship can be shared and cultural ties made in \"century of knowledge\"   \n",
       "1                                                                                          NEW: Protest moves after crackdown at Freedom Square .\\nOrder sought after protests over last month's election turn violent .\\nDemonstrators say the election was fraudulent .\\nState of emergency could last until March 20, official says .   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnndm_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "# pretrained_model_name = \"t5-small\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "#                                                                                model_cls=T5ForConditionalGeneration)\n",
    "\n",
    "# pretrained_model_name = \"google/pegasus-cnn_dailymail\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "#                                                                                model_cls=PegasusForConditionalGeneration)\n",
    "\n",
    "# pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "#                                                                                model_cls=BartForConditionalGeneration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bart',\n",
       " transformers.configuration_bart.BartConfig,\n",
       " transformers.tokenization_bart.BartTokenizer,\n",
       " transformers.modeling_bart.BartForConditionalGeneration)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               model_cls=BartForConditionalGeneration)\n",
    "\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_batch_tfm = HF_SummarizationBatchTransform(hf_arch, hf_tokenizer)\n",
    "\n",
    "blocks = ( \n",
    "    HF_TextBlock(hf_arch, hf_tokenizer, max_length=256), \n",
    "    HF_TextBlock(hf_arch, hf_tokenizer, hf_batch_tfm=hf_batch_tfm, max_length=100, hf_input_idxs=[0,1])\n",
    ")\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('article'), \n",
    "                   get_y=ColReader('highlights'), \n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(cnndm_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 256]), torch.Size([2, 51]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington (CNN) -- Having trouble pronouncing an Italian word? If you sit on the Supreme Court, consult an expert. On Monday, Justice Sonia Sotomayor was announcing the court's opinion in Krupski v. Costa Crociere SpA (09-337), a lesser-known appeal dealing with the scope of the right to file an amended lawsuit to correct a mistake in a party's identity. The newest justice was having trouble pronouncing the name of the cruise ship company at the center of the case. Costa Cruises is a British and American-owned firm based in Genoa, Italy, where it is registered as Costa Crociere SpA. The appeal involved passenger Wanda Krupksi, who tripped over a cable and fractured her leg in 2007 aboard the Costa Magica. At issue was whether Krupski should have sued Costa Cruises or Costa Crociere SpA in federal court. The justice writing the majority ruling typically announces the decision from the bench in a public session, with a brief oral summary that supplements the official written opinion. That's where the fun began. Sotomayor needed help and knew exactly where to turn. \"Costa Cruises responded that she should have sued a related company called</td>\n",
       "      <td>Newest high court justice gives oral summary of cruise ship case.\\nShe turned to fellow justice for pronunciation of Italian company.\\nSotomayor was also honored over the weekend in New York.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- An earthquake in central Oklahoma prompted a few calls to the police but no apparent damage Saturday. The U.S. Geological Survey said the quake had a preliminary 4.5 magnitude to the quake and said it was centered near Jones, Oklahoma, 14 miles northeast of Oklahoma City. The shaking lasted 3 to 5 seconds at 12:15 p.m. Central Time, said Oklahoma City police Lt. Jason Samuel. He said a few people called the department to ask what happened. No damage had been reported. Samuel said the quake was strong enough to wake him from a nap at his home. He said it seemed stronger and longer-lasting that other earthquakes in the area in recent years. Oklahoma had a stronger earthquake -- 5.6 magnitude -- on November 5, 2011. Although damage was not widespread, it did buckle U.S. Highway 62 in Lincoln County. CNN's David Simpson and Janet DiGiacomo contributed to this report.</td>\n",
       "      <td>Only a few calls to Oklahoma City police after 4.5 quake.\\nStronger quake in 2011 buckled highway in Oklahoma.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(hf_tokenizer=hf_tokenizer, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for summarization tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_rouge(predicted_txts, reference_txts, rouge_keys=[\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True):\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_keys, use_stemmer=use_stemmer)\n",
    "    aggregator = scoring.BootstrapAggregator()\n",
    "\n",
    "    for ref_text, pred_txt in zip(reference_txts, predicted_txts):\n",
    "        scores = scorer.score(ref_text, pred_txt)\n",
    "        aggregator.add_scores(scores)\n",
    "\n",
    "    result = aggregator.aggregate()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Here we create a summarization specific subclass of `HF_BaseModelCallback` in order to include custom, summarization specific, metrics, and also handle the pre-calculated loss during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_SummarizationModelCallback(HF_BaseModelCallback):  \n",
    "    def __init__(self, rouge_metrics=[\"rouge1\", \"rouge2\", \"rougeL\"], text_gen_kwargs={}, **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self=self, names='rouge_metrics, text_gen_kwargs, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in rouge_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the target's HF_TokenizerTransform (used for rouge metrics)\n",
    "        hf_textblock_tfm = self.learn.dls.tfms[-1]\n",
    "        self.hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "        self.tok_kwargs = hf_textblock_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "        \n",
    "        \n",
    "    # --- batch begin/after phases ---\n",
    "    def before_batch(self): self.hf_loss = None\n",
    "        \n",
    "    def after_pred(self): \n",
    "        # the \"labels\" key will only be included in the input dictionary *IF* we are training with target labels, \n",
    "        # in which case the first output of the model will be the loss\n",
    "        if ('labels' in self.xb[0]):\n",
    "            self.hf_loss, self.learn.pred = self.pred[0], self.pred[1]\n",
    "        else:\n",
    "            self.learn.pred = self.pred[0]\n",
    "            \n",
    "    def after_loss(self): \n",
    "        # if we already have the loss from the model, update the Learner's loss to be it\n",
    "        if (self.hf_loss is not None): self.learn.loss = self.hf_loss\n",
    "        \n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # grab predicted and reference ids for any metrics that need them\n",
    "        input_ids, attention_mask = self.xb[0]['input_ids'], self.xb[0]['attention_mask']\n",
    "        gen_ids = self.learn.model.hf_model.generate(input_ids=input_ids, \n",
    "                                                     attention_mask=attention_mask, \n",
    "                                                     use_cache=True,\n",
    "                                                     **self.text_gen_kwargs)\n",
    "        \n",
    "        self.generated_ids += gen_ids.tolist()\n",
    "        self.refernce_ids += self.yb[0].tolist()\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.generated_ids, self.refernce_ids = [], []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        # are there rouge metrics to calculate?\n",
    "        if (self.rouge_metrics is not None and len(self.rouge_metrics) > 0):\n",
    "            gen_texts = self.hf_tokenizer.batch_decode(self.generated_ids, \n",
    "                                                       skip_special_tokens=True, \n",
    "                                                       clean_up_tokenization_spaces=True)\n",
    "\n",
    "            ref_texts = self.hf_tokenizer.batch_decode(self.refernce_ids, \n",
    "                                                       skip_special_tokens=True, \n",
    "                                                       clean_up_tokenization_spaces=True)\n",
    "\n",
    "            rouge_results = calculate_rouge(gen_texts, ref_texts, rouge_keys=self.rouge_metrics)\n",
    "            \n",
    "            for rouge_key, scores in rouge_results.items(): \n",
    "                self.custom_metrics_dict[rouge_key] = scores.mid.fmeasure\n",
    "                \n",
    "\n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a custom param splitter to give us a bit more depth in applying discriminative learning rates for summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def summarization_splitter(m, arch):\n",
    "    \"\"\"Custom param splitter for summarization models\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, 'hf_model')) else m\n",
    "    \n",
    "    if arch in ['bart', 'pegasus']:     \n",
    "        embeds = nn.Sequential(\n",
    "            model.model.shared, \n",
    "            model.model.encoder.embed_positions, \n",
    "            model.model.encoder.embed_tokens,\n",
    "            model.model.decoder.embed_positions, \n",
    "            model.model.decoder.embed_tokens\n",
    "        )\n",
    "        \n",
    "        groups = L(embeds, model.model.encoder, model.model.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "    \n",
    "    if arch in['t5']:\n",
    "        embeds = nn.Sequential(\n",
    "            model.shared, \n",
    "            model.encoder.embed_tokens,\n",
    "            model.decoder.embed_tokens\n",
    "        )\n",
    "        \n",
    "        groups = L(embeds, model.encoder, model.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "    \n",
    "    raise ValueError('Invalid architecture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"summarization_splitter\" class=\"doc_header\"><code>summarization_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>summarization_splitter</code>(**`m`**, **`arch`**)\n",
       "\n",
       "Custom param splitter for summarization models"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(summarization_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we don't really need a loss function, we have to provide a custom loss class/function for fastai to function properly (e.g. one with a `decodes` and `activation` methods).  Why?  Because these methods will get called in methods like `show_results` to get the actual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_MaskedLMLoss():\n",
    "    def __call__(self, inp, targ, **kwargs): return\n",
    "    def decodes(self, x): return x.argmax(dim=-1)\n",
    "    def activation(self, x): return F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': True,\n",
       " 'length_penalty': 2.0,\n",
       " 'max_length': 130,\n",
       " 'min_length': 30,\n",
       " 'no_repeat_ngram_size': 3,\n",
       " 'num_beams': 4}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_gen_kwargs = { **hf_config.task_specific_params['summarization'], **{'max_length': 130, 'min_length': 30} }\n",
    "text_gen_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "model_cb = HF_SummarizationModelCallback(text_gen_kwargs=text_gen_kwargs)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=ranger,\n",
    "                loss_func=HF_MaskedLMLoss(),\n",
    "                cbs=[model_cb],\n",
    "                splitter=partial(summarization_splitter, arch=hf_arch))#.to_fp16()\n",
    "\n",
    "learn.create_opt() \n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " tensor(4.2707, device='cuda:1', grad_fn=<NllLossBackward>),\n",
       " torch.Size([2, 53, 50264]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0], preds[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, torch.Size([2, 256]), 2, torch.Size([2, 54]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.0001737800776027143, lr_steep=6.309573450380412e-07)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.684707</td>\n",
       "      <td>1.903918</td>\n",
       "      <td>0.366860</td>\n",
       "      <td>0.151517</td>\n",
       "      <td>0.237965</td>\n",
       "      <td>04:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.418471</td>\n",
       "      <td>1.897334</td>\n",
       "      <td>0.378602</td>\n",
       "      <td>0.162281</td>\n",
       "      <td>0.251070</td>\n",
       "      <td>04:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.189154</td>\n",
       "      <td>1.904099</td>\n",
       "      <td>0.379188</td>\n",
       "      <td>0.161845</td>\n",
       "      <td>0.255042</td>\n",
       "      <td>03:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=3e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to take advantage of huggingface's `PreTrainedModel.generate` model, which can be used to easily implement beam search, top-k/nucleous sampling, etc... so that we get more human sounding results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \n",
    "into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \n",
    "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \n",
    "Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \n",
    "but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \n",
    "of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \n",
    "cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \n",
    "occurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \n",
    "her, and took off for the French border. The other gunmen followed into France, which is only about 100 \n",
    "meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \n",
    "There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \n",
    "robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \n",
    "Gill said. The robbers spoke French and drove vehicles with French license plates. CNN's Andreena Narayan \n",
    "contributed to this report.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gun GunAbout 10 men\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict(test_article)\n",
    "print(res[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't look much like a human-generated summary.  Let's use huggingface's `PreTrainedModel.generate` method to create something more human-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Target ===\n",
      " Newest high court justice gives oral summary of cruise ship case .\n",
      "She turned to fellow justice for pronunciation of Italian company .\n",
      "Sotomayor was also honored over the weekend in New York .\n",
      "\n",
      "=== Prediction ===\n",
      " Sotomayor was announcing the court's opinion in Krupski v. Costa Crociere SpA .\n",
      "The appeal involved a woman who tripped over a cable and fractured her leg aboard a Costa Cruises ship .\n",
      "At issue was whether she should have sued the cruise line or a related company in federal court .\n",
      "Costa Cruises is a British and American-owned firm based in Genoa, Italy .\n"
     ]
    }
   ],
   "source": [
    "test_input_ids = dls.train_ds[0][0]['input_ids'].unsqueeze(0).to(learn.model.hf_model.device)\n",
    "gen_text = learn.model.hf_model.generate(test_input_ids, num_beams=4, max_length=130, min_length=30)\n",
    "\n",
    "print('=== Target ===')\n",
    "print(f'{hf_tokenizer.decode(dls.train_ds[0][1][\"input_ids\"], skip_special_tokens=True, clean_up_tokenization_spaces=False)}\\n')\n",
    "\n",
    "print('=== Prediction ===')\n",
    "print(hf_tokenizer.decode(gen_text[0], skip_special_tokens=True, clean_up_tokenization_spaces=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add a `blurr_summarize` method to `Learner` that uses huggingface's `PreTrainedModel.generate` to create our predictions.  For the full list of arguments you can pass in see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate). You can also check out their [\"How To Generate\"](https://github.com/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb) notebook for more information about how it all works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_summarize(self:Learner, inp, **kwargs):\n",
    "    \"\"\"Uses the built-in `generate` method to generate the text \n",
    "    (see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
    "    for a list of arguments you can pass in)\n",
    "    \"\"\"\n",
    "    # grab the text generation kwargs\n",
    "    text_gen_kwargs = self.cbs.filter(lambda el: isinstance(el, HF_SummarizationModelCallback) )[0].text_gen_kwargs\n",
    "    text_gen_kwargs = { **text_gen_kwargs, **kwargs}\n",
    "    \n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_textblock_tfm.kwargs\n",
    "\n",
    "    if (isinstance(inp, str)):\n",
    "        input_ids = hf_tokenizer.encode(inp, padding=True, truncation=True, return_tensors='pt', **tok_kwargs)\n",
    "    else:\n",
    "        input_ids = inp\n",
    "        \n",
    "    input_ids = input_ids.to(self.model.hf_model.device)\n",
    "    \n",
    "    gen_texts = self.model.hf_model.generate(input_ids, **text_gen_kwargs)\n",
    "    outputs = [ hf_tokenizer.decode(txt, skip_special_tokens=True, clean_up_tokenization_spaces=False) \n",
    "               for txt in gen_texts ]\n",
    "    \n",
    "    if hf_textblock_tfm.hf_arch == 'pegasus':\n",
    "        outputs = [o.replace('<n>', ' ') for o in outputs]\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_summarize\" class=\"doc_header\"><code>Learner.blurr_summarize</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_summarize</code>(**`inp`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Uses the built-in `generate` method to generate the text \n",
       "(see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
       "for a list of arguments you can pass in)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\n",
      "One group tried to break into the casino's vault on the lower level but could not get in .\n",
      "A woman driving by unknowingly blocked the armed robbers' vehicles and was beaten to death .\n",
      "\n",
      "=== Prediction 2 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "About 600 people were in the casino at the time of the robbery .\n",
      "There were no serious injuries, although one guest was kicked in the head by one of the robbers .\n",
      "The robbers spoke French and drove vehicles with French license plates, a police officer says .\n",
      "\n",
      "=== Prediction 3 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "About 600 people were in the casino at the time of the robbery .\n",
      "There were no serious injuries, although one guest was kicked in the head by one of the robbers .\n",
      "The robbers spoke French and drove vehicles with French license plates, police said .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = learn.blurr_summarize(test_article, num_return_sequences=3)\n",
    "\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much nicer!!! Now, we can update our @typedispatched `show_results` to use this new method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_SummarizationInput, y, samples, outs, learner, ctxs=None, max_n=6, **kwargs):  \n",
    "    gen_text_txts = learner.blurr_summarize(x[0])\n",
    "    res = L([ (sample[0], sample[1], gen_txt) for sample, gen_txt in zip(samples, gen_text_txts) ])          \n",
    "    \n",
    "    display_df(pd.DataFrame(res, columns=['text', 'target', 'prediction'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- It's one win for Darrell Wallace Jr., but what will it mean for other African-American race car drivers -- present and future? The answer to that question might not come for years. Nonetheless, NASCAR wasted no time Saturday in hailing Wallace's on-track success at Martinsville Speedway in southern Virginia. \"We congratulate Darrell Wallace Jr. on his first national series victory, one that will be remembered as a remarkable moment in our sport's history,\" said NASCAR chairman and CEO Brian France. Wallace took the Kroger 200 on the racing circuit's Camping World Truck Series, which is on NASCAR's third tier. Still, it is notable given that no African-American has won any NASCAR national series race since December 1, 1963, when Wendell Scott became the first ever to win a race at NASCAR's top level, in a victory at Speedway Park in Jacksonville, Florida. Scott, a Virginia native who served in the Army during World War II, raced in more than 500 races during his career -- finishing in the top five 20 times, though that would be his only victory. Plus, the 20-year-old Wallace isn't just any driver. He's a highly touted graduate of the NASCAR Drive for Diversity, having been featured</td>\n",
       "      <td>NEW: \"We Came. We Saw. We Conquered,\" Wallace tweets.\\nDarrell Wallace Jr. wins a third-tier NASCAR race in Martinsville.\\nIt's the first NASCAR national series win for an African-African since 1963.\\nNASCAR's CEO says the win \"will be remembered... in our sport's history\"</td>\n",
       "      <td>NASCAR hails Darrell Wallace Jr.'s win as a \"remarkable moment\" in the sport's history .\\nNo African-American has won a NASCAR national series race since Wendell Scott in 1963 .\\nWallace is a graduate of the NASCAR Drive for Diversity program .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Israeli President Shimon Peres said he had an amicable phone conversation with Turkish Prime Minister Recep Tayyip Erdogan, a day after Erdogan stormed offstage during an angry exchange with Peres at the World Economic Forum in Davos, Switzerland. Turkish PM Recep Tayyip Erdogan leaves the stage Thursday, as Israeli President Shimon Peres sits, left. Peres said he and Erdogan did not take the spat personally. \"I called him up and said, yes, it's nothing against you, nothing against Turkey. We consider you as a friend,\" Peres said. He said Erdogan reciprocated. Although there was no mention of an apology, Peres said there was a polite exchange between the two leaders. \"I didn't take it personally. I didn't go for a personal fight. I answered unfounded accusations. It was my duty. And they didn't change my mind,\" he said.  Watch Shimon Peres on the Gaza conflict ». Turkey, a predominantly Muslim nation, has long been the Jewish state's closest military and economic partner in the region, and Turkey recently mediated indirect peace talks between Israel and Syria. But many Turks have been incensed with Israel over its three-week military operation that ended there earlier this month. And in</td>\n",
       "      <td>Turkish Prime Minister angered during debate on Gaza at World Economic Forum.\\nRecep Tayyip Erdogan called Israel's Gaza campaign \"barbaric,\" stormed off stage.\\nIsraeli president Shimon Peres said he and Erdogan did not take spat personally.\\nErdogan returned home to a hero's welcome in Istanbul.</td>\n",
       "      <td>Turkish PM Erdogan stormed off stage during angry exchange with Israeli President Peres at Davos summit .\\nPeres says he and Erdogan did not take spat personally, had amicable phone conversation .\\nTurkey has long been Israel's closest military and economic partner in region .\\nBut many Turks have been incensed with Israel over its three-week military operation in Gaza .\\nErdogan recently mediated indirect peace talks between Israel and Syria .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname='summarize_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\\nA woman driving by unknowingly blocked the armed robbers' vehicles and was beaten to death .\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname='summarize_export.pkl')\n",
    "inf_learn.blurr_summarize(test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the core training code above works for **all** pretrained summarization models available in huggingface.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained summarization models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.modeling_bart.BartForConditionalGeneration,\n",
       " transformers.modeling_mbart.MBartForConditionalGeneration,\n",
       " transformers.modeling_pegasus.PegasusForConditionalGeneration,\n",
       " transformers.modeling_t5.T5ForConditionalGeneration]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLURR_MODEL_HELPER.get_models(task='ConditionalGeneration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    ('facebook/bart-large-cnn',BartForConditionalGeneration),\n",
    "    ('t5-small', T5ForConditionalGeneration),\n",
    "    #('google/pegasus-cnn_dailymail', PegasusForConditionalGeneration), ... don't fit on my 1080TI :(\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./')\n",
    "cnndm_df = pd.read_csv(path/'cnndm_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-large-cnn ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizer\n",
      "model:\t\tBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.294048</td>\n",
       "      <td>2.836430</td>\n",
       "      <td>0.319604</td>\n",
       "      <td>0.140422</td>\n",
       "      <td>0.254950</td>\n",
       "      <td>02:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- Your kids deserve better. Because Congress failed to pass the Child Nutrition Bill last week, bad school lunches will remain bad. While the bill wasn't perfect, it would have created stronger nutritional standards and provided more money for the school lunch program -- adding six cents per lunch for the first time in 30 years. This was the first step on the long ladder to fresh food, and now it's a missed opportunity. Among other things, this bill would have banned the junk food that is served in schools and competes with the fresh food your kids need. Eating this junk every day will take 10 years off their</td>\n",
       "      <td>Jamie Oliver: Child Nutrition Bill failed, which means same old unhealthy school lunches.\\nSchools serve junk food like chocolate milk, soda</td>\n",
       "      <td>Congress failed to pass the Child Nutrition Bill .\\nJulian Zelizer: The bill would have banned junk food in schools .\\nHe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- How can educating girls change the world? \"Girl Rising\" tells the stories of girls from around the world and their determination to overcome extraordinary odds. Filmmakers enlisted celebrities and renowned authors to participate in the project, which took six years to complete. Filmmakers traveled to some of the most remote regions in the world, interviewing hundreds of girls and selecting a few to give voice to the challenges and hopes of millions. Watch a preview of 'Girl Rising' Academy Award nominee Richard Robbins, who directed \"Girl Rising,\" talks about why he made the film, how crowd-sourcing was key and why the</td>\n",
       "      <td>\"Girl Rising\" tells the stories of girls around the world and their quest for education.\\nDirector Richard Robbins says the project took six years</td>\n",
       "      <td>\"Girl Rising\" tells the stories of girls from around the world .\\nFilmmakers enlisted celebrities and renowned authors in the film .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== t5-small ===\n",
      "\n",
      "architecture:\tt5\n",
      "tokenizer:\tT5Tokenizer\n",
      "model:\t\tT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING One pass through the model ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.881922</td>\n",
       "      <td>2.690632</td>\n",
       "      <td>0.325988</td>\n",
       "      <td>0.149257</td>\n",
       "      <td>0.265832</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summarize: Washington (CNN) -- The U.S. Supreme Court will take another look at an 11-year-old boy's request to have Israel listed as his place of birth on his U.S. passport. The justices announced Monday they would review a federal law giving that special right to those like young Menachem Zivotofsky, who were born in Jerusalem. But that is a disputed region in the eyes of the Obama administration, which said the larger issue should be resolved by bilateral negotiations, not by a 2002 congressional action favoring the family and the more than 50,000</td>\n",
       "      <td>2002 law lets U.S. citizens born in Jerusalem ask that Israel be listed as birthplace on passports. The U.S.</td>\n",
       "      <td>the justices will review a federal law giving that special right to 11-year-old menachem Zivotofsky .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summarize: BEIRUT, Lebanon (CNN) -- A car bomb struck a U.S. Embassy vehicle Tuesday as it traveled along a coastal highway north of Beirut, killing at least three Lebanese civilian bystanders, according to American and Lebanese officials. Lebanese soldiers and Red Cross workers stand near charred cars at the site of the explosion in Beirut. The driver of the embassy vehicle suffered minor injuries, and the sole passenger walked away unscathed, U.S. State Department spokesman Sean McCormack said.</td>\n",
       "      <td>NEW: The United States is outraged by the attack, Secretary of State Rice says. Car bomb strikes U.S. Embassy vehicle</td>\n",
       "      <td>a car bomb strikes a U.S. Embassy vehicle in Beirut, killing at least three Lebanese civilian bystand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "bsz = 2\n",
    "inp_seq_sz = 128\n",
    "\n",
    "test_results = []\n",
    "for model_name, model_cls in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(model_name, \n",
    "                                                                                   model_cls=model_cls)\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n')\n",
    "    \n",
    "    # 1. build your DataBlock\n",
    "    hf_batch_tfm = HF_SummarizationBatchTransform(hf_arch, hf_tokenizer)\n",
    "\n",
    "    blocks = ( \n",
    "        HF_TextBlock(hf_arch, hf_tokenizer, padding='max_length', max_length=inp_seq_sz), \n",
    "        HF_TextBlock(hf_arch, hf_tokenizer, hf_batch_tfm=hf_batch_tfm, padding='max_length', max_length=30, \n",
    "                     hf_input_idxs=[0,1])\n",
    "    )\n",
    "    \n",
    "    def add_t5_prefix(inp): return f'summarize: {inp}' if (hf_arch == 't5') else inp\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=Pipeline([ColReader('article'), add_t5_prefix]), \n",
    "                   get_y=ColReader('highlights'), \n",
    "                   splitter=RandomSplitter())\n",
    "    \n",
    "    dls = dblock.dataloaders(cnndm_df, bs=bsz)\n",
    "\n",
    "    # 2. build your Learner\n",
    "    text_gen_kwargs = {}\n",
    "    if (hf_arch in ['bart', 't5']):\n",
    "        text_gen_kwargs = { \n",
    "            **hf_config.task_specific_params['summarization'], \n",
    "            **{'max_length': 30, 'min_length': 10} \n",
    "        }\n",
    "    \n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    model_cb = HF_SummarizationModelCallback(text_gen_kwargs=text_gen_kwargs)\n",
    "\n",
    "    learn = Learner(dls, \n",
    "                    model,\n",
    "                    opt_func=ranger,\n",
    "                    loss_func=HF_MaskedLMLoss(),\n",
    "                    cbs=[model_cb],\n",
    "                    splitter=partial(summarization_splitter, arch=hf_arch))#.to_fp16()\n",
    "\n",
    "    learn.create_opt() \n",
    "    learn.freeze()\n",
    "    \n",
    "    # 3. Run your tests\n",
    "    b = dls.one_batch()\n",
    "\n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***\\n')\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, inp_seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        print('*** TESTING One pass through the model ***')\n",
    "        preds = learn.model(b[0])\n",
    "        test_eq(preds[1].shape[0], bsz)\n",
    "        test_eq(preds[1].shape[2], hf_config.vocab_size)\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizer</td>\n",
       "      <td>BartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t5</td>\n",
       "      <td>T5Tokenizer</td>\n",
       "      <td>T5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model_name', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01a_data-token-classification.ipynb.\n",
      "Converted 01b_data-question-answering.ipynb.\n",
      "Converted 01e_data-summarization.ipynb.\n",
      "Converted 01z_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-core.ipynb.\n",
      "Converted 02a_modeling-token-classification.ipynb.\n",
      "Converted 02b_modeling-question-answering.ipynb.\n",
      "Converted 02e_modeling-summarization.ipynb.\n",
      "Converted 02z_modeling-language-modeling.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
