{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.summarization\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ast, torch\n",
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.core import *\n",
    "\n",
    "from rouge_score import rouge_scorer, scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "\n",
    "The objective of summarization is to generate a concise and accurate representation of a much larger body of text.  For example, we may want to summarize an article in a single sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('./')\n",
    "cnndm_df = pd.read_csv(path/'cnndm_sample.csv'); len(cnndm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>ds_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...</td>\n",
       "      <td>John Sexton: Traditionally, universities have been defined and limited by location .\\nGlobal campuses form a network of thought, innovation, he writes .\\nFaculty can teach, Sexton says, students can team up in many cities at once .\\nSexton: Research, scholarship can be shared and cultural ties made in \"century of knowledge\"</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will \"hopefully bring some order\" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...</td>\n",
       "      <td>NEW: Protest moves after crackdown at Freedom Square .\\nOrder sought after protests over last month's election turn violent .\\nDemonstrators say the election was fraudulent .\\nState of emergency could last until March 20, official says .</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   article  \\\n",
       "0  (CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...   \n",
       "1  (CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will \"hopefully bring some order\" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                              highlights  \\\n",
       "0  John Sexton: Traditionally, universities have been defined and limited by location .\\nGlobal campuses form a network of thought, innovation, he writes .\\nFaculty can teach, Sexton says, students can team up in many cities at once .\\nSexton: Research, scholarship can be shared and cultural ties made in \"century of knowledge\"   \n",
       "1                                                                                          NEW: Protest moves after crackdown at Freedom Square .\\nOrder sought after protests over last month's election turn violent .\\nDemonstrators say the election was fraudulent .\\nState of emergency could last until March 20, official says .   \n",
       "\n",
       "  ds_type  \n",
       "0   train  \n",
       "1   train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnndm_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large-cnn and are newly initialized: ['final_logits_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bart',\n",
       " transformers.configuration_bart.BartConfig,\n",
       " transformers.tokenization_bart.BartTokenizer,\n",
       " transformers.modeling_bart.BartForConditionalGeneration)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               model_cls=BartForConditionalGeneration)\n",
    "\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_batch_tfm = HF_SummarizationBatchTransform(hf_arch, hf_tokenizer)\n",
    "\n",
    "blocks = ( \n",
    "    HF_TextBlock(hf_arch, hf_tokenizer, max_length=512), \n",
    "    HF_TextBlock(hf_arch, hf_tokenizer, hf_batch_tfm=hf_batch_tfm, max_length=150, hf_input_idxs=[0,1])\n",
    ")\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, \n",
    "                   get_x=ColReader('article'), \n",
    "                   get_y=ColReader('highlights'), \n",
    "                   splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(cnndm_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 512]), torch.Size([2, 86]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0]['input_ids'].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)  -- Arturo Gatti, who was found dead in a Brazilian hotel room in suspicious circumstances, is revered by boxing fans for his trilogy of thrilling and brutal fights with Micky \"Irish\" Ward. Arturo Gatti fought to the limit of his endurance in many epic bouts. The Italian-born Canadian captured world titles at super featherweight and junior welterweight during his 16-year-professional career and also fought and lost to legends Oscar De La Hoya and Floyd Mayweather Jr. in big money matches. But his 2002 and 2003 bouts with Ward will always be remembered, and two of them won the \"Fight of the Year\" award given out by the prestigious Ring Magazine. The first two fights were over 10 rounds, with Gatti losing the first and gaining revenge in a classic second bout. The third and deciding fight took place in June 2003, and Gatti broke his right hand in the fourth round. Almost unbelievably, he fought on and despite being floored in the sixth dominated the rest of the fight to win on a unanimous decision. Despite Gatti's winning the WBC junior welterweight crown the following year by beating Gianluca Branco of Italy to the vacant title, his storied wins over Ward proved to be the high point of Gatti's career. He made two successful defenses of the title against lightly-regarded opponents until running into Mayweather in June 2005. It proved a big fight too many, as he was slowed by body shots and cut a sorry figure as he was stopped in the sixth round. Moving up to welterweight, Gatti won a warm-up fight before losing to Carlos Baldomir in a world title bout. His comeback fight, with old rival Micky Ward by then his trainer, also ended in defeat to Alfonso Gomez in July 2007, and he promptly announced his retirement. It ended a 49-fight career with 31 knockout and nine defeats. His first world title had come with victory over Tracy Harris Patterson, the adopted son of heavyweight great Floyd Patterson, to claim the IBF super featherweight crown. As his fame spread and with countless nominations for Ring's Fight of the Year, Gatti, nicknamed \"Thunder,\" gained a large and devoted following among boxing fans. But his life outside the ring proved contentious and in March this year the Canadian Press reported that Gatti was charged with assaulting his then girlfriend Amanda Rodriguez and spent two nights in jail after failing to turn up for a court appearance. Gatti later married Rodriguez, and they have a</td>\n",
       "      <td>Arturo Gatti was one of the most popular fighters of his generation.\\nItalian-born Canadian fought epic trilogy of bouts with Micky Ward.\\nGatti also won world titles at two different weights in 16-year pro career.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- U.S. Supreme Court justices peppered attorneys with questions Tuesday over whether an Arkansas inmate should be allowed to grow a beard as part of his religious faith. Gregory Holt, also known as Abdul Maalik Muhammad, is a Muslim who filed a handwritten petition with the high court. He cited rights under the federal Religious Land Use and Institutionalized Persons Act, or RLUIPA. He wants to grow the beard as part of his religious faith and his attorneys claim he had offered to keep it to a \"half-inch\" as part of what Holt called a \"compromise.\" In their response, Arkansas corrections officials cited security concerns in their refusal to accommodate. Justices to debate prisoner's religious right to grow a beard. According to the state of Arkansas, current policy allows only a \"neatly trimmed mustache\" and inmate beards could pose a security risk to guards and the public: Prisoners who escape could shave their facial hair, altering their appearance. And weapons and other contraband could be hidden in heavy beards or inside their cheeks, covered by facial hair. Justice Samuel Alito was skeptical: \"As far as searching a beard is concerned: Why can't the prison just give the inmate a comb and say comb your beard? And if there's anything in there -- if there's a SIM card in there or a revolver or anything else you think can be hidden in a half-inch beard, a tiny revolver -- it'll fall out.\" Chief Justice John Roberts addressed the issue of how to define \"neatly trimmed.\" \"One of the difficult issues in a case like this is where to draw the line,\" Roberts said, addressing Holt's lawyer. \"And you just say: 'Well, we want to draw the line at a half-inch because that lets us win.' And the next day someone's going to be here with 1 inch. And then 2 inches. Administrative Directive 98-04.D of the Arkansas Department of Correction permits beards only for those \"with a diagnosed dermatological problem.\" But in his self-initiated plea to the justices, Holt complained that he and fellow Muslims were forced \"to either obey their religious beliefs and face disciplinary action on the one hand, or violate those beliefs in order to acquiesce\" to the facial hair policy. Read Holt's original handwritten petition to the Supreme Court (PDF) He cited the Hadith -- literary traditions and sayings of the Prophet Mohammed -- which says, \"Allah's Messenger said, 'Cut</td>\n",
       "      <td>Gregory Holt wants to grow beard as part of his religious faith.\\nArkansas officials have denied him the right.\\nJustices peppered both sides with questions.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(hf_tokenizer=hf_tokenizer, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In this section, we'll add helpful metrics for summarization tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_rouge(predicted_txts, reference_txts, rouge_keys=[\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True):\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_keys, use_stemmer=use_stemmer)\n",
    "    aggregator = scoring.BootstrapAggregator()\n",
    "\n",
    "    for ref_text, pred_txt in zip(reference_txts, predicted_txts):\n",
    "        scores = scorer.score(ref_text, pred_txt)\n",
    "        aggregator.add_scores(scores)\n",
    "\n",
    "    result = aggregator.aggregate()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Here we create a summarization specific subclass of `HF_BaseModelCallback` in order to include custom, summarization specific, metrics, and also handle the pre-calculated loss during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_SummarizationModelCallback(HF_BaseModelCallback):  \n",
    "    def __init__(self, rouge_metrics=[\"rouge1\", \"rouge2\", \"rougeL\"], text_gen_kwargs={}, **kwargs):\n",
    "        self.run_before = Recorder\n",
    "        \n",
    "        store_attr(self, 'rouge_metrics, text_gen_kwargs, kwargs')\n",
    "        self.custom_metrics_dict = { k:None for k in rouge_metrics }\n",
    "        \n",
    "        self.do_setup = True\n",
    "        \n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if (not self.do_setup): return\n",
    "        \n",
    "        # grab the hf_tokenizer from the target's HF_TokenizerTransform (used for rouge metrics)\n",
    "        hf_textblock_tfm = self.learn.dls.tfms[-1]\n",
    "        self.hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "        self.tok_kwargs = hf_textblock_tfm.kwargs\n",
    "        \n",
    "        # add custom text generation specific metrics\n",
    "        custom_metric_keys = self.custom_metrics_dict.keys()\n",
    "        custom_metrics = L([ ValueMetric(partial(self.metric_value, metric_key=k), k) for k in custom_metric_keys ])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "        \n",
    "        self.do_setup = False\n",
    "        \n",
    "    def before_fit(self): self.setup()\n",
    "        \n",
    "        \n",
    "    # --- batch begin/after phases ---\n",
    "    def before_batch(self): self.hf_loss = None\n",
    "        \n",
    "    def after_pred(self): \n",
    "        # the \"labels\" key will only be included in the input dictionary *IF* we are training with target labels, \n",
    "        # in which case the first output of the model will be the loss\n",
    "        if ('labels' in self.xb[0]):\n",
    "            self.hf_loss, self.learn.pred = self.pred[0], self.pred[1]\n",
    "        else:\n",
    "            self.learn.pred = self.pred[0]\n",
    "            \n",
    "    def after_loss(self): \n",
    "        # if we already have the loss from the model, update the Learner's loss to be it\n",
    "        if (self.hf_loss is not None): self.learn.loss = self.hf_loss\n",
    "        \n",
    "    def after_batch(self):\n",
    "        if (self.training or self.learn.y is None): return\n",
    "        \n",
    "        # grab predicted and reference ids for any metrics that need them\n",
    "        input_ids, attention_mask = self.xb[0]['input_ids'], self.xb[0]['attention_mask']\n",
    "        gen_ids = self.learn.model.hf_model.generate(input_ids=input_ids, \n",
    "                                                     attention_mask=attention_mask, \n",
    "                                                     use_cache=True,\n",
    "                                                     **self.text_gen_kwargs)\n",
    "        \n",
    "        self.generated_ids += gen_ids.tolist()\n",
    "        self.refernce_ids += self.yb[0].tolist()\n",
    "        \n",
    "        \n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self): self.generated_ids, self.refernce_ids = [], []\n",
    "        \n",
    "    def after_validate(self):\n",
    "        # are there rouge metrics to calculate?\n",
    "        if (self.rouge_metrics is not None and len(self.rouge_metrics) > 0):\n",
    "            gen_texts = self.hf_tokenizer.batch_decode(self.generated_ids, \n",
    "                                                       skip_special_tokens=True, \n",
    "                                                       clean_up_tokenization_spaces=True)\n",
    "\n",
    "            ref_texts = self.hf_tokenizer.batch_decode(self.refernce_ids, \n",
    "                                                       skip_special_tokens=True, \n",
    "                                                       clean_up_tokenization_spaces=True)\n",
    "\n",
    "            rouge_results = calculate_rouge(gen_texts, ref_texts, rouge_keys=self.rouge_metrics)\n",
    "            \n",
    "            for rouge_key, scores in rouge_results.items(): \n",
    "                self.custom_metrics_dict[rouge_key] = scores.mid.fmeasure\n",
    "                \n",
    "\n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key): return self.custom_metrics_dict[metric_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a custom param splitter to give us a bit more depth in applying discriminative learning rates for summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def summarization_splitter(m, arch):\n",
    "    \"\"\"Custom param splitter for summarization models\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, 'hf_model')) else m\n",
    "    \n",
    "    if arch in ['bart', 'pegasus']:     \n",
    "        embeds = nn.Sequential(\n",
    "            model.model.shared, \n",
    "            model.model.encoder.embed_positions, \n",
    "            model.model.encoder.embed_tokens,\n",
    "            model.model.decoder.embed_positions, \n",
    "            model.model.decoder.embed_tokens\n",
    "        )\n",
    "        \n",
    "        groups = L(embeds, model.model.encoder, model.model.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "    \n",
    "    raise ValueError('Invalid architecture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"summarization_splitter\" class=\"doc_header\"><code>summarization_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>summarization_splitter</code>(**`m`**, **`arch`**)\n",
       "\n",
       "Custom param splitter for summarization models"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(summarization_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we don't really need a loss function, we have to provide a custom loss class/function for fastai to function properly (e.g. one with a `decodes` and `activation` methods).  Why?  Because these methods will get called in methods like `show_results` to get the actual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_MaskedLMLoss():\n",
    "    def __call__(self, inp, targ, **kwargs): return\n",
    "    def decodes(self, x): return x.argmax(dim=-1)\n",
    "    def activation(self, x): return F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': True,\n",
       " 'length_penalty': 2.0,\n",
       " 'max_length': 130,\n",
       " 'min_length': 30,\n",
       " 'no_repeat_ngram_size': 3,\n",
       " 'num_beams': 4}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_gen_kwargs = { **hf_config.task_specific_params['summarization'], **{'max_length': 130, 'min_length': 30} }\n",
    "text_gen_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "model_cb = HF_SummarizationModelCallback(text_gen_kwargs=text_gen_kwargs)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=ranger,\n",
    "                loss_func=HF_MaskedLMLoss(),\n",
    "                cbs=[model_cb],\n",
    "                splitter=partial(summarization_splitter, arch=hf_arch))#.to_fp16()\n",
    "\n",
    "learn.create_opt() \n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.blurr_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " tensor(3.2785, device='cuda:1', grad_fn=<NllLossBackward>),\n",
       " torch.Size([2, 49, 50264]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "len(preds),preds[0], preds[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, torch.Size([2, 512]), 2, torch.Size([2, 50]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0]['input_ids'].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.00010000000474974513, lr_steep=1.3182567499825382e-06)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.406839</td>\n",
       "      <td>1.497895</td>\n",
       "      <td>0.381799</td>\n",
       "      <td>0.167776</td>\n",
       "      <td>0.257260</td>\n",
       "      <td>04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.109648</td>\n",
       "      <td>1.498273</td>\n",
       "      <td>0.378201</td>\n",
       "      <td>0.163422</td>\n",
       "      <td>0.259255</td>\n",
       "      <td>04:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.015443</td>\n",
       "      <td>1.504310</td>\n",
       "      <td>0.395336</td>\n",
       "      <td>0.176750</td>\n",
       "      <td>0.270462</td>\n",
       "      <td>04:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(3, lr_max=3e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "Below we'll add in additional functionality to take advantage of huggingface's `PreTrainedModel.generate` model, which can be used to easily implement beam search, top-k/nucleous sampling, etc... so that we get more human sounding results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \n",
    "into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \n",
    "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \n",
    "Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \n",
    "but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \n",
    "of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \n",
    "cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \n",
    "occurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \n",
    "her, and took off for the French border. The other gunmen followed into France, which is only about 100 \n",
    "meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \n",
    "There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \n",
    "robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \n",
    "Gill said. The robbers spoke French and drove vehicles with French license plates. CNN's Andreena Narayan \n",
    "contributed to this report.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10 10About 10 men a\n"
     ]
    }
   ],
   "source": [
    "res = learn.blurr_predict(test_article)\n",
    "print(res[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't look much like a human-generated summary.  Let's use huggingface's `PreTrainedModel.generate` method to create something more human-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Target ===\n",
      " Arturo Gatti was one of the most popular fighters of his generation .\n",
      "Italian-born Canadian fought epic trilogy of bouts with Micky Ward .\n",
      "Gatti also won world titles at two different weights in 16-year pro career .\n",
      "\n",
      "=== Prediction ===\n",
      " Arturo Gatti is revered by boxing fans for his trilogy of thrilling and brutal fights with Micky Ward .\n",
      "The Italian-born Canadian captured world titles at super featherweight and junior welterweight during his 16-year professional career .\n",
      "He also fought and lost to legends Oscar De La Hoya and Floyd Mayweather Jr. in big money matches .\n",
      "Gatti, nicknamed \"Thunder,\" gained a large and devoted following among boxing fans .\n"
     ]
    }
   ],
   "source": [
    "test_input_ids = dls.train_ds[0][0]['input_ids'].unsqueeze(0).to(learn.model.hf_model.device)\n",
    "gen_text = learn.model.hf_model.generate(test_input_ids, num_beams=4, max_length=130, min_length=30)\n",
    "\n",
    "print('=== Target ===')\n",
    "print(f'{hf_tokenizer.decode(dls.train_ds[0][1][\"input_ids\"], skip_special_tokens=True, clean_up_tokenization_spaces=False)}\\n')\n",
    "\n",
    "print('=== Prediction ===')\n",
    "print(hf_tokenizer.decode(gen_text[0], skip_special_tokens=True, clean_up_tokenization_spaces=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add a `blurr_summarize` method to `Learner` that uses huggingface's `PreTrainedModel.generate` to create our predictions.  For the full list of arguments you can pass in see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate). You can also check out their [\"How To Generate\"](https://github.com/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb) notebook for more information about how it all works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_summarize(self:Learner, inp, **kwargs):\n",
    "    \"\"\"Uses the built-in `generate` method to generate the text \n",
    "    (see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
    "    for a list of arguments you can pass in)\n",
    "    \"\"\"\n",
    "    # grab the text generation kwargs\n",
    "    text_gen_kwargs = self.cbs.filter(lambda el: isinstance(el, HF_SummarizationModelCallback) )[0].text_gen_kwargs\n",
    "    text_gen_kwargs = { **text_gen_kwargs, **kwargs}\n",
    "    \n",
    "    # grab the huggingface tokenizer from the learner's dls.tfms\n",
    "    hf_textblock_tfm = self.dls.tfms[0]\n",
    "    hf_tokenizer = hf_textblock_tfm.hf_tokenizer\n",
    "    tok_kwargs = hf_textblock_tfm.kwargs\n",
    "\n",
    "    if (isinstance(inp, str)):\n",
    "        input_ids = hf_tokenizer.encode(inp, padding=True, truncation=True, return_tensors='pt', **tok_kwargs)\n",
    "    else:\n",
    "        input_ids = inp\n",
    "        \n",
    "    input_ids = input_ids.to(self.model.hf_model.device)\n",
    "    \n",
    "    gen_texts = self.model.hf_model.generate(input_ids, **text_gen_kwargs)\n",
    "    outputs = [ hf_tokenizer.decode(txt, skip_special_tokens=True, clean_up_tokenization_spaces=False) \n",
    "               for txt in gen_texts ]\n",
    "    \n",
    "    if hf_textblock_tfm.hf_arch == 'pegasus':\n",
    "        outputs = [o.replace('<n>', ' ') for o in outputs]\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_summarize\" class=\"doc_header\"><code>Learner.blurr_summarize</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_summarize</code>(**`inp`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Uses the built-in `generate` method to generate the text \n",
       "(see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
       "for a list of arguments you can pass in)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\n",
      "One group tried to break into the casino's vault on the lower level but could not get in .\n",
      "Another group robbed the upper level where the roulette and blackjack tables are located .\n",
      "There were no serious injuries, although one guest was kicked in the head by one of the robbers .\n",
      "\n",
      "=== Prediction 2 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\n",
      "One group tried to break into the casino's vault on the lower level but could not get in .\n",
      "Another group robbed the upper level where the roulette and blackjack tables are located .\n",
      "There were about 600 people in the casino at the time of the robbery .\n",
      "\n",
      "=== Prediction 3 ===\n",
      " Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\n",
      "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\n",
      "One group tried to break into the casino's vault on the lower level but could not get in .\n",
      "Another group robbed the upper level where the roulette and blackjack tables are located .\n",
      "A woman driving by unknowingly blocked the robbers' vehicles with her car, and one man beat her .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = learn.blurr_summarize(test_article, num_return_sequences=3)\n",
    "\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much nicer!!! Now, we can update our @typedispatched `show_results` to use this new method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_SummarizationInput, y, samples, outs, learner, ctxs=None, max_n=6, **kwargs):  \n",
    "    gen_text_txts = learner.blurr_summarize(x[0])\n",
    "    res = L([ (sample[0], sample[1], gen_txt) for sample, gen_txt in zip(samples, gen_text_txts) ])          \n",
    "    \n",
    "    display_df(pd.DataFrame(res, columns=['text', 'target', 'prediction'])[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- North Korea accused the United States and South Korea of sending spy planes on about 200 missions near the isolated communist nation ahead of a North Korea rocket launch scheduled for early April. Pyongyang claims reconnaissance aircraft, including the high-altitude U-2 spy plane, have flown spy missions. \"The U.S. imperialists and the South Korean puppet military warmongers perpetrated intensive aerial espionage against the DPRK (North Korea) in March by massively mobilizing strategic and tactical reconnaissance planes with various missions,\" a military source said, according to a report from North Korea's state-run news service, KCNA, on Tuesday. Pyongyang said the United States committed 110 cases of \"aerial espionage and the South Korean puppet forces at least 80 cases,\" during March, KCNA reported. The source said the missions utilized six types of reconnaissance aircraft, including the high-altitude U-2 spy plane. \"The U.S. imperialist warmongers had better bear in mind that... spy planes perpetrating espionage against the DPRK are within the range of its strikes.\" The Pentagon was not immediately available to comment on the story. The North Korean government says it will launch a commercial satellite atop a rocket sometime between April 4 and April 8. Satellite imagery taken on Sunday appears to show a rocket at the Musudan-ri launch site in northeastern North Korea. U.S. Defense Secretary Robert Gates said Sunday there is little doubt that the planned rocket launch is designed to bolster North Korea's military capability. He also indicated that the U.S. military could be prepared to shoot down a North Korean missile if the rogue regime develops the capability to reach Hawaii or the western continental United States in a future launch.  Watch analysis of Pyongyang's planned rocket launch ». Both the United States and Japan have mobilized missile defense systems ahead of the launch. North Korea has threatened to start a war if Japan were to shoot down its rocket. Tokyo said the move is aimed at shooting down any debris from the launch that might fall into Japanese territory. U.S. Navy ships capable of shooting down ballistic missiles have been moved to the Sea of Japan, a Navy spokesman said. The United States generally has a number of ships equipped with powerful Aegis radar in the Sea of Japan because of North Korean threats to launch rockets. The ships are designed to track and, if needed, shoot down ballistic missiles. The United States has no plans to shoot down the North Korean rocket, U.S. Secretary of State Hillary Clinton said last week, but will raise</td>\n",
       "      <td>North Korea claims it detected about 200 spy plane missions near it.\\nClaim comes ahead of North Korea's launch of a rocket scheduled for early April.\\nPyongyang warned that spy planes are within the range of its strikes.\\nU.S. has little doubt rocket launch is designed to bolster N. Korea's military capability.</td>\n",
       "      <td>North Korea says U.S., South Korea committed 110 cases of \"aerial espionage\" during March .\\nNorth Korea says it will launch a commercial satellite atop a rocket sometime between April 4 and April 8 .\\nBoth the United States and Japan have mobilized missile defense systems ahead of the launch .\\nSatellite imagery appears to show a rocket at the Musudan-ri launch site in northeastern North Korea .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- The massive earthquake and tsunami that hit Japan on Friday spared the island of Indonesia, a nearby developing country that was devastated in 2004 by one of the deadliest tsunamis in history. Helping after that disaster was CNN Hero Robin Lim. Lim is the founder of Indonesia's Yayasan Bumi Sehat health clinics, which provide free prenatal and birthing care to women in need. Lim recently spoke with CNN's Ebonne Ruffins about how her midwife teams respond in natural disasters, balancing critical medical needs with cultural traditions. Ebonne Ruffins: What's it like to work in Indonesia and, specifically, after the 2004 tsunami? Robin Lim: In Indonesia, there is a great need for us because many mothers want the help of professional birth attendants but can't afford them. So they come to us. It was not easy to start so grass-roots in Bali, completely reliant on donations, but we did it. And when the tsunami happened a few years later in Aceh, we were early responders. So many on the eastern coast lost everything, and it was very difficult to witness. But we had to be there for those who survived or were fighting to survive. Ruffins: How do your teams provide maternal and infant care in the middle of a devastated area? Lim: Because the devastation can ruin entire clinics and resources, we have to be prepared to treat them with limited materials. Instead of cutting the umbilical cord, for instance, we burn it -- especially in disaster zones, because it's something we can teach our midwives and doctors who've lost their instruments. Using scissors to sever the umbilical cord carries a risk of tetanus. If you burn the cord, there's just no risk of infection. And outside of just knowing how to safely respond medically, we try to have respect for everyone's faith. We don't have any particular religion, and we'll honor all requests and faith traditions -- special songs, flowers or chants. No matter what they are or where we are, we honor these faiths. This helps the moms feel safe and supported with us. Video: Watch a cord-burning ceremony at Lim's clinic. Ruffins: You've delivered enough babies to repopulate another island. Have you learned anything from the people you've helped? Lim: I've learned a lot. Quite often I cry tears of joy because I feel humbled. Once in a while, a baby is born that doesn't breathe. Normally CPR works, but sometimes</td>\n",
       "      <td>Robin Lim founded health clinics in Indonesia that offer free prenatal and birthing care.\\nWhen a tsunami hit in 2004, her midwife teams had to work with limited resources.\\nLim: We try to have respect for everyone's faith.\\nDo you know a hero? Nominations are open for 2011 CNN Heroes.</td>\n",
       "      <td>Robin Lim is the founder of Indonesia's Yayasan Bumi Sehat health clinics .\\nThey provide free prenatal and birthing care to women in need .\\nLim: Disasters can ruin entire clinics and resources, so we have to be prepared to treat them with limited materials .\\nInstead of cutting the umbilical cord, for instance, we burn it -- especially in disaster zones .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname='summarize_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\\nAnother group robbed the upper level where the roulette and blackjack tables are located .\\nThere were no serious injuries, although one guest was kicked in the head by one of the robbers .\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname='summarize_export.pkl')\n",
    "inf_learn.blurr_summarize(test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Converted 00_utils.ipynb.\nConverted 01_data-core.ipynb.\nConverted 01a_data-token-classification.ipynb.\nConverted 01b_data-question-answering.ipynb.\nConverted 01e_data-summarization.ipynb.\nConverted 01z_data-language-modeling.ipynb.\nConverted 02_modeling-core.ipynb.\nConverted 02a_modeling-token-classification.ipynb.\nConverted 02b_modeling-question-answering.ipynb.\nConverted 02e_modeling-summarization.ipynb.\nConverted 02z_modeling-language-modeling.ipynb.\nConverted index.ipynb.\n"
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
