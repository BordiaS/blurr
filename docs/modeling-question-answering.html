---

title: modeling.question_answering

keywords: fastai
sidebar: home_sidebar

summary: "This module contains custom models, loss functions, custom splitters, etc... for question answering tasks"
description: "This module contains custom models, loss functions, custom splitters, etc... for question answering tasks"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/02c_modeling-question-answering.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#cuda</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Using GPU #</span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Using GPU #1: GeForce GTX 1080 Ti
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Question-Answer">Question Answer<a class="anchor-link" href="#Question-Answer"> </a></h2><p>Given a document (context) and a question, the objective of these models is to predict the start and end token of the correct answer as it exists in the context.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="HF_QstAndAnsModelCallback" class="doc_header"><code>class</code> <code>HF_QstAndAnsModelCallback</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/modeling/question_answering.py#L16" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>HF_QstAndAnsModelCallback</code>() :: <a href="/blurr/modeling-core#HF_BaseModelCallback"><code>HF_BaseModelCallback</code></a></p>
</blockquote>
<p>Basic class handling tweaks of the training loop by changing a <code>Learner</code> in various events</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="HF_QstAndAnsModelWrapper" class="doc_header"><code>class</code> <code>HF_QstAndAnsModelWrapper</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/modeling/question_answering.py#L31" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>HF_QstAndAnsModelWrapper</code>(<strong><code>hf_model</code></strong>) :: <a href="/blurr/modeling-core#HF_BaseModelWrapper"><code>HF_BaseModelWrapper</code></a></p>
</blockquote>
<p>A custom model wrapper for question answer models since we need all the outputs (not just the first)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And here we provide a custom loss function our question answer task, expanding on some techniques learned from here and here.</p>
<p>In fact, this new loss function can be used in many other multi-modal architectures, with any mix of loss functions.  For example, this can be ammended to include the <code>is_impossible</code> task, as well as the start/end token tasks in the SQUAD v2 dataset.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MultiTargetLoss" class="doc_header"><code>class</code> <code>MultiTargetLoss</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/modeling/question_answering.py#L45" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MultiTargetLoss</code>(<strong><code>loss_classes</code></strong>=<em><code>[&lt;class 'fastai2.layers.CrossEntropyLossFlat'&gt;, &lt;class 'fastai2.layers.CrossEntropyLossFlat'&gt;]</code></em>, <strong><code>loss_classes_kwargs</code></strong>=<em><code>[{}, {}]</code></em>, <strong><code>weights</code></strong>=<em><code>[1, 1]</code></em>, <strong><code>reduction</code></strong>=<em><code>'mean'</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Provides the ability to apply different loss functions to multi-modal targets/predictions</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Again, we'll use a subset of pre-processed SQUAD v2 for our purposes below.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;./&#39;</span><span class="p">)</span>
<span class="n">squad_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;squad_sample.csv&#39;</span><span class="p">);</span> <span class="nb">len</span><span class="p">(</span><span class="n">squad_df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1000</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">squad_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>context</th>
      <th>question_id</th>
      <th>question_text</th>
      <th>is_impossible</th>
      <th>answer_text</th>
      <th>answer_start</th>
      <th>answer_end</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>New_York_City</td>
      <td>The New York City Fire Department (FDNY), provides fire protection, technical rescue, primary response to biological, chemical, and radioactive hazards, and emergency medical services for the five boroughs of New York City. The New York City Fire Department is the largest municipal fire department in the United States and the second largest in the world after the Tokyo Fire Department. The FDNY employs approximately 11,080 uniformed firefighters and over 3,300 uniformed EMTs and paramedics. The FDNY's motto is New York's Bravest.</td>
      <td>56d1076317492d1400aab78c</td>
      <td>What does FDNY stand for?</td>
      <td>False</td>
      <td>New York City Fire Department</td>
      <td>4</td>
      <td>33</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Cyprus</td>
      <td>Following the death in 1473 of James II, the last Lusignan king, the Republic of Venice assumed control of the island, while the late king's Venetian widow, Queen Catherine Cornaro, reigned as figurehead. Venice formally annexed the Kingdom of Cyprus in 1489, following the abdication of Catherine. The Venetians fortified Nicosia by building the Venetian Walls, and used it as an important commercial hub. Throughout Venetian rule, the Ottoman Empire frequently raided Cyprus. In 1539 the Ottomans destroyed Limassol and so fearing the worst, the Venetians also fortified Famagusta and Kyrenia.</td>
      <td>572e7f8003f98919007566df</td>
      <td>In what year did the Ottomans destroy Limassol?</td>
      <td>False</td>
      <td>1539</td>
      <td>481</td>
      <td>485</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s1">&#39;bert-large-uncased-whole-word-masking-finetuned-squad&#39;</span>
<span class="n">hf_tokenizer_cls</span> <span class="o">=</span> <span class="n">BertTokenizer</span>
<span class="n">hf_model_cls</span> <span class="o">=</span> <span class="n">HF_MODELS</span><span class="o">.</span><span class="n">BertForQuestionAnswering</span>

<span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span>
                                                                               <span class="n">hf_tokenizer_cls</span><span class="p">,</span>
                                                                               <span class="n">hf_model_cls</span><span class="p">)</span>


<span class="c1"># # here&#39;s a pre-trained roberta model for squad you can try too</span>
<span class="c1"># pretrained_model_name = &quot;ahotrod/roberta_large_squad2&quot;</span>
<span class="c1"># hf_arch, hf_tokenizer, hf_config, hf_model = \</span>
<span class="c1">#     BLURR_MODEL_HELPER.get_auto_hf_objects(pretrained_model_name, task=HF_TASKS_AUTO.ForQuestionAnswering)</span>

<span class="c1"># # here&#39;s a pre-trained xlm model for squad you can try too</span>
<span class="c1"># pretrained_model_name = &#39;xlm-mlm-ende-1024&#39;</span>
<span class="c1"># hf_arch, hf_tokenizer, hf_config, hf_model = \</span>
<span class="c1">#     BLURR_MODEL_HELPER.get_auto_hf_objects(pretrained_model_name, task=HF_TASKS_AUTO.ForQuestionAnswering)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">pre_process_squad</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="n">context</span><span class="p">,</span> <span class="n">qst</span><span class="p">,</span> <span class="n">ans</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;question_text&#39;</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;answer_text&#39;</span><span class="p">]</span>
    
    <span class="n">add_prefix_space</span> <span class="o">=</span> <span class="n">hf_arch</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;gpt2&#39;</span><span class="p">,</span> <span class="s1">&#39;roberta&#39;</span><span class="p">]</span>
    
    <span class="k">if</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">==</span> <span class="s1">&#39;right&#39;</span><span class="p">):</span>
        <span class="n">tok_input</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">qst</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> 
                                                                           <span class="n">add_prefix_space</span><span class="o">=</span><span class="n">add_prefix_space</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tok_input</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">qst</span><span class="p">,</span> 
                                                                           <span class="n">add_prefix_space</span><span class="o">=</span><span class="n">add_prefix_space</span><span class="p">))</span>
                                                                       
    <span class="n">tok_ans</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;answer_text&#39;</span><span class="p">]),</span> 
                                    <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                    <span class="n">add_prefix_space</span><span class="o">=</span><span class="n">add_prefix_space</span><span class="p">)</span>
    
    <span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">tok</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tok_input</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">tok</span> <span class="o">==</span> <span class="n">tok_ans</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">tok_input</span><span class="p">[</span><span class="n">idx</span><span class="p">:</span><span class="n">idx</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">tok_ans</span><span class="p">)]</span> <span class="o">==</span> <span class="n">tok_ans</span><span class="p">):</span> 
                <span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span> <span class="o">=</span> <span class="n">idx</span><span class="p">,</span> <span class="n">idx</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">tok_ans</span><span class="p">)</span>
                <span class="k">break</span>
        <span class="k">except</span><span class="p">:</span> <span class="k">pass</span>
            
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;tokenized_input&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tok_input</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;tokenized_input_len&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tok_input</span><span class="p">)</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;tok_answer_start&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">start_idx</span>
    <span class="n">row</span><span class="p">[</span><span class="s1">&#39;tok_answer_end&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">end_idx</span>
    
    <span class="k">return</span> <span class="n">row</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">squad_df</span> <span class="o">=</span> <span class="n">squad_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pre_process_squad</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Token indices sequence length is longer than the specified maximum sequence length for this model (16 &gt; 512). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (12 &gt; 512). Running this sequence through the model will result in indexing errors
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_seq_len</span><span class="o">=</span> <span class="mi">128</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">squad_df</span> <span class="o">=</span> <span class="n">squad_df</span><span class="p">[(</span><span class="n">squad_df</span><span class="o">.</span><span class="n">tokenized_input_len</span> <span class="o">&lt;</span> <span class="n">max_seq_len</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">squad_df</span><span class="o">.</span><span class="n">is_impossible</span> <span class="o">==</span> <span class="kc">False</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_seq_len</span><span class="p">))</span>
<span class="c1"># vocab = dict(enumerate(range(max_seq_len)));</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># account for tokenizers that pad on right or left side</span>
<span class="n">trunc_strat</span> <span class="o">=</span> <span class="s1">&#39;only_second&#39;</span> <span class="k">if</span> <span class="p">(</span><span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">==</span> <span class="s1">&#39;right&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;only_first&#39;</span>
<span class="n">txt_cols</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;question_text&#39;</span><span class="p">],[</span><span class="s1">&#39;context&#39;</span><span class="p">]]</span> <span class="k">if</span> <span class="p">(</span><span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">==</span> <span class="s1">&#39;right&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="p">[[</span><span class="s1">&#39;context&#39;</span><span class="p">],[</span><span class="s1">&#39;question_text&#39;</span><span class="p">]]</span>

<span class="c1"># override HF_BatchTransform defaults (optional)</span>
<span class="n">hf_batch_tfm</span> <span class="o">=</span> <span class="n">HF_BatchTransform</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="n">ForQuestionAnsweringTask</span><span class="p">(),</span>
                                 <span class="n">max_seq_len</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">truncation_strategy</span><span class="o">=</span><span class="n">trunc_strat</span><span class="p">)</span>

<span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">HF_TextBlock</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">text_cols_lists</span><span class="o">=</span><span class="n">txt_cols</span><span class="p">,</span> 
                         <span class="n">hf_arch</span><span class="o">=</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="o">=</span><span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_batch_tfm</span><span class="o">=</span><span class="n">hf_batch_tfm</span><span class="p">),</span>
    <span class="n">CategoryBlock</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">vocab</span><span class="p">),</span>
    <span class="n">CategoryBlock</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># can&#39;t export lambda functions, so made the getter a standard method</span>
<span class="k">def</span> <span class="nf">get_x</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">text0</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">text1</span><span class="p">)</span>

<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> 
                   <span class="n">get_x</span><span class="o">=</span><span class="n">get_x</span><span class="p">,</span>
                   <span class="n">get_y</span><span class="o">=</span><span class="p">[</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;tok_answer_start&#39;</span><span class="p">),</span> <span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;tok_answer_end&#39;</span><span class="p">)],</span>
                   <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">(),</span>
                   <span class="n">n_inp</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">squad_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">dls</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">dls</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dls</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(3, (#128) [0,1,2,3,4,5,6,7,8,9...], (#128) [0,1,2,3,4,5,6,7,8,9...])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="o">=</span><span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>category</th>
      <th>category_</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>how do birds conserve energy? many, if not most, birds migrate in flocks. for larger birds, flying in flocks reduces the energy cost. geese in a v - formation may conserve 12 – 20 % of the energy they would need to fly alone. red knots calidris canutus and dunlins calidris alpina were found in radar studies to fly 5 km / h ( 3. 1 mph ) faster in flocks than when they were flying alone.</td>
      <td>35</td>
      <td>39</td>
    </tr>
    <tr>
      <th>1</th>
      <td>dovrak has used what type of themes to impart a nationalist flavor? composers of classical music have often made use of folk music ( music created by musicians who are commonly not classically trained, often from a purely oral tradition ). some composers, like dvorak and smetana, have used folk themes to impart a nationalist flavor to their work, while others like bartok have used specific themes lifted whole from their folk - music origins.</td>
      <td>27</td>
      <td>28</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">HF_QstAndAnsModelWrapper</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> 
                <span class="n">hf_model</span><span class="p">,</span>
                <span class="n">opt_func</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">Adam</span><span class="p">,</span> <span class="n">decouple_wd</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">HF_QstAndAnsModelCallback</span><span class="p">],</span>
                <span class="n">splitter</span><span class="o">=</span><span class="n">hf_splitter</span><span class="p">)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">loss_func</span><span class="o">=</span><span class="n">MultiTargetLoss</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">create_opt</span><span class="p">()</span>                <span class="c1"># -&gt; will create your layer groups based on your &quot;splitter&quot; function</span>
<span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Notice above how I had to define the loss function <em>after</em> creating the <code>Learner</code> object.  I'm not sure why, but the <a href="/blurr/02c_modeling-question-answering#MultiTargetLoss"><code>MultiTargetLoss</code></a> above prohibits the learner from being exported if I do.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># learn.summary()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">param_groups</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>4
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># x, y_start, y_end = dls.one_batch()</span>
<span class="c1"># preds = learn.model(x)</span>
<span class="c1"># len(preds),preds[0].shape</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Note:</strong> The code above will only work if we are using the model wrapper (not the callback) as the callback does the work of ensuring our input into the huggingface model is correct ... and <code>learn.model(*x)</code> doesn't use it.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#slow</span>
<span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">(</span><span class="n">suggestions</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(lr_min=0.025118863582611083, lr_steep=1.0964782238006592)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXzU1b3/8dcnOwkQloSdsASQHcEICIJSN9yX3lpBvdpSUW9rF7t62/vTe29t9Xaxbq1S12rd6tXrjmuVRVSCgiD7ToBsLNknmZmc3x8ZMEICCWTmO5N5Px+PPJj5zsz3+54xfnLmfM/3HHPOISIi8SPB6wAiIhJZKvwiInFGhV9EJM6o8IuIxBkVfhGROKPCLyISZ5K8DtASWVlZbuDAgV7HEBGJKcuWLSt1zmUfuj0mCv/AgQPJz8/3OoaISEwxs21NbVdXj4hInFHhFxGJMyr8IiJxRoVfRCTOqPCLiMQZFX4RkTijwi8iEoXKqv28+UUhJRW1bb5vFX4RkSi0saSS659Yxurd5W2+bxV+EZEoVOsPAtAhObHN963CLyIShWpChT8tue3LdNgKv5k9YmbFZraq0bbfmdlaM/vczF40sy7hOr6ISCyridEW/2PAzEO2vQ2Mds6NBdYDt4Tx+CIiMcvnrwcgLZYKv3NuAbD3kG1vOecCobsfAf3CdXwRkVj2ZVdPDBX+Fvg28EZzD5rZXDPLN7P8kpKSCMYSEfGery7U1ZPSTgq/mf0SCAB/b+45zrl5zrk851xedvZh00mLiLRrvgMt/qS2L9MRn4/fzK4FLgDOcM65SB9fRCQW1PiDJCcaSYkxXvjNbCbwM+A051x1JI8tIhJLavzBsPTvQ3iHcz4NLAFOMLMCM5sD3Ad0At42s+Vm9kC4ji8iEst8/vqwDOWEMLb4nXOzmtj8cLiOJyLSnvhiscUvIiLHrqYuGLYWvwq/iEgUqvEHSQvDUE5Q4RcRiUo+fzAsQzlBhV9EJCr5/MGwXLwFKvwiIlGpxq8+fhGRuOLz12tUj4hIPInJC7hEROTY+TScU0QkvvgCwbCsvgUq/CIiUccfrMcfdGrxi4jEiwNTMms4p4hInDiw7GKqWvwiIvHBF8aF1kGFX0Qk6tSo8IuIxJeDyy5qVI+ISHyoqVOLX0Qkrhzo6om5aZnN7BEzKzazVY22fcPMvjCzejPLC9exRURi2YFRPWlJMVb4gceAmYdsWwVcBiwI43FFRGJauMfxh3PN3QVmNvCQbWsAzCxchxURiXka1SMiEmfidlSPmc01s3wzyy8pKfE6johIxBw8uRtvLX7n3DznXJ5zLi87O9vrOCIiEeOrC2IGqVpzV0QkPvgC9aQlJYbtfGg4h3M+DSwBTjCzAjObY2aXmlkBcArwmpm9Ga7ji4jEqpq68C20DuEd1TOrmYdeDNcxRUTag3AutA7q6hERiTo+f5DUMI3oARV+EZGo41OLX0QkvqirR0Qkzvj89WEbww8q/CIiUaemLqjCLyIST3z+8A7nVOEXEYkyPn+QtDBdtQsq/CIiUadGLX4RkfiiUT0iInHEOYfPX0+qCr+ISHyoDTQsu6gWv4hInKipO7D6lk7uiojEBV8gvIuwgAq/iEhUOdji16geEZH4EO5lF0GFX0Qkqvj8DSd3VfhFROKEz3/g5K4Kv4hIXPhyVE8MFn4ze8TMis1sVaNt3czsbTPbEPq3a7iOLyISi74c1RObwzkfA2Yesu0XwLvOuaHAu6H7IiIScqDFH5N9/M65BcDeQzZfDDweuv04cEm4ji8iEosO9vG3o+GcPZ1zu0O3C4GezT3RzOaaWb6Z5ZeUlEQmnYiIx9r1qB7nnAPcER6f55zLc87lZWdnRzCZiIh3Do7jb0fz8ReZWW+A0L/FET6+iEhUq/EHSUlMICmx/RT+l4FrQrevAV6K8PFFRKJaTV2Q1DCO6IHwDud8GlgCnGBmBWY2B7gDOMvMNgBnhu6LiEhIbSC8i7AAJIVrx865Wc08dEa4jikiEutq6sK77CLoyl0RkahS4w+SlqTCLyISN3z+etLU4hcRiR8NC63H6MldERFpPZ8/GNaLt0CFX0Qkqvj84R/Vo8IvIhJFalT4RUTiS01dPakq/CIi8aNWLX4RkfhS4w/SIUWjekRE4oI/WE+g3ukCLhGReBGJRVhAhV9EJGocnItfffwiIvHBVxf+1bdAhV9EJGr4AqGuHhV+EZH4UFN3oI9fo3pEROLCl+vtqsUvIhIXDozqaZfTMpvZD8xslZl9YWY/9CKDiEi0OTics7318ZvZaOA6YCIwDrjAzIZEOoeISLRpz8M5RwAfO+eqnXMB4APgMg9yiIhEFZ+/YThnu2vxA6uAaWbW3czSgfOA/oc+yczmmlm+meWXlJREPKSISKQdHNXT3gq/c24NcCfwFjAfWA4Em3jePOdcnnMuLzs7O8IpRUQib09VLUkJRkZqOyv8AM65h51zJznnpgP7gPVe5BARiSZbSqvI6ZZOUmJ4S3NSWPfeDDPr4ZwrNrMcGvr3J3uRQ0QkmmwuqWJQVkbYj+NJ4Qf+18y6A37gu865/R7lEBGJCvX1ji2lVUwbmhX2Y3lS+J1z07w4rohItNpVVkNtoJ7B2R3DfqwWdSSZWYaZJYRuDzOzi8wsObzRRETix+aSKoCIdPW09AzCAiDNzPrSMBrnauCxcIUSEYk3W0obCv/g7Ogp/Oacq6bhROyfnXPfAEaFL5aISHzZXFJJp9Qksjumhv1YLS78ZnYKcCXwWmhbeAeaiojEkc2lVQzKzsDMwn6slhb+HwK3AC86574ws8HAP8MXS0QkvmwuqWJwBPr3oYWjepxzH9Awpw6hk7ylzrnvhzOYiEi88PmD7CqrYVDWYbPXhEVLR/U8ZWadzSyDhrl2VpvZT8MbTUQkPmzdU4VzkTmxCy3v6hnpnCsHLgHeAAbRMLJHRESO04GhnNFW+JND4/YvAV52zvkBF75YIiLxY3NJJRCZMfzQ8sL/ILAVyAAWmNkAoDxcoURE4snm0ip6Z6aRnhKZyRRaenL3HuCeRpu2mdmM8EQSEYkvkZqc7YCWntzNNLM/HlgYxcz+QEPrX0REjoNzjs0llRHr34eWd/U8AlQAl4d+yoFHwxVKRCRe7K2qo9wXYHBW+CdnO6ClHUq5zrmvN7r/n2a2PByBRETiyebQHD2DorDFX2Nmpx64Y2ZTgZrwRBIRiR9bQkM5c6OwxX8D8Dczywzd3wdcE55IIiLxY1NpJSmJCfTt2iFix2zpqJ4VwDgz6xy6X25mPwQ+D2c4EZH2bn1hBQOz0klMCP/kbAe0akVf51x56ApegJuP9aBm9iMz+8LMVpnZ02aWdqz7EhGJVTV1QZZs3sOU3PAvt9jY8Szlfkx/nkKLuXwfyHPOjaZheucrjiOHiEhMWrihBJ+/nrNG9ozocY+n8B/PlA1JQAczSwLSgV3HsS8RkZj09uoiOqclMXFQt4ge94h9/GZWQdMF3oBjOhPhnNtpZr8HttMwMugt59xbx7IvEZFYFax3vLe2mBnDe5CceDxt8NY74tGcc52cc52b+OnknDumSSXMrCtwMQ0zfPYBMszsqiaeN/fAlcIlJSXHcigRkaj16fZ97Kmqi3g3DxxfV8+xOhPY4pwrCc3y+QIw5dAnOefmOefynHN52dnZEQ8pIhJOb68uIjnROG1Y5OubF4V/OzDZzNKtYXHJM4A1HuQQEfGEc463VxdxSm4WndKSI378iBd+59zHwPPAp8DKUIZ5kc4hIuKVTSWVbCmt8qSbB1p+5W6bcs7dCtzqxbFFRLz21uoiAM4a4U3h96KrR0Qkrr29uoix/TLplenNtasq/CIiERSsd6zaWcYpud09y6DCLyISQcUVPvxBR/+u6Z5lUOEXEYmgnfsaZrSP5Gych1LhFxGJoJ37Gwp/fxV+EZH4UBBq8ffposIvIhIXCvbV0C0jhfQUT0bTAyr8IiIRtXN/DX09bO2DCr+ISETt3FdNPw/790GFX0QkYpxzavGLiMSTPVV1+Pz1ng7lBBV+EZGIOTiGXy1+EZH4cGAMv1r8IiJx4kCLv5+H0zWACr+ISMQU7KumU2oSmR0iv/hKYyr8IiIRsnN/jefdPKDCLyISMQX7vB/KCSr8IiIREy0t/ohPFmFmJwDPNto0GPh/zrk/RTqLfKmwzEd2p1QSE+zgtvp6x18+2MQnW/YyondnxvbLZEJO11atGuSco6I2QOcmFpSuqQuyv6YOf8BRF6wnu2Mqmene9n2KhEtZjZ8KX8Dzq3bBg8LvnFsHnAhgZonATuDFSOeQL734WQE3P7eCsf26cMdlYxjRuzOVtQFufnY5b60uYmD3dBZvLCVQ70hMMG762hC+N2MISYlH/sLoD9bzk3+s4NXPd3PVpBx+eOYwumakUF0X4K8LtvDggk1U1wUPPj/B4KQBXfna8J4M7dGRz3eW8dn2fezYW831p+Vyxcn9MbMjHFEken05ht/bET3g0WLrjZwBbHLObfM4R1zYVFLJqp1lnDemN8mhoj1/VSE/+cfnjO2bScHeai68dxHfPnUQH6wrYWNJJbdeOJJrpwykLljPusIKHl28lT+9s4EF60v40zfHk9O96V/i2kCQ7z31GW+vLmLa0Cye+GgbL362k2/k9eeVFbsorqjl3NG9mD4sm+TEBJITjY3Flby3tpg7568FGv4QnNCrM5kdkrnlhZW8u6aYO74+hs5pySzZvId3VhfRLSOFOdMGNfmNQiSaRMsYfgBzznl3cLNHgE+dc/c18dhcYC5ATk7OSdu26W/D8aiuC3De3QvZuqeaAd3TufmsYXTukMzcv+Uzum8mT86ZRF2gnttfX8PzywrI7JDM/bMncOrQrMP29dLynfzq/1bhHNw7azwzhvf4yuM1dUHmPpHPwg2l3HbhSK6dOoh1hRX8+rXVLNxQyoScLvzy/BGcNKBbk1kLy3xs31vNyD6d6ZiaRH2949EPt3Ln/LVkpCQSrHeU+wJ0SE6kxh+kW0YK3//aEGZPGkBKkk5bSXR6bPEWbntlNUt/eSbZnVIjckwzW+acyztsu1eF38xSgF3AKOdc0ZGem5eX5/Lz8yMTrJ267eUveOzDrfx85nBeXrGLNbvLARjRuzPPXDf5K33ry3fsJ7tT6hFHHxTsq+aGJ5exdncFd18xnvPH9gZgY3ElP3z2M77YVc6dl43l8pP7H3yNc46SylqyO6YeU5fN+qIK7nhjLd0yUpg5qhenDs1iY3Elv3l9DR9u2kOX9GQGZ2UwoHsGfbt0ID01kQ7JDT/9uqaT2yODXp3T1F0knrj9tdX8bck21v73zIj9DkZj4b8Y+K5z7uyjPVeFv0FNXZANxRXsqayjtLKWrI6ph7W2m/LR5j1cMe8jrp0ykNsuGkV9veO1lbt5f10Jt5w3nKyOx9b6KPf5+fajS/l0+z7uuGwsvkCQ37y+hg7JifzPv4zjrJE9j2m/reWc44P1JbyxspDte6vZvreaXWU1NPWr3TE1ifE5XThvTG/OHtmT7sf43kVa68Ynl7GuqIL3fnx6xI4ZjYX/GeBN59yjR3uuCj/s2FvN7Ic+Ysfemq9s/86pg/j380aQkNB0C6KqNsC5dy/EDN74wbQ2X/Wnui7A9U8sY+GGUgCmD8vm9/8ylh6dWz7yJxycc9QG6vH5g1TWBti+t5pNxZWsL6pkwYYStu2pJsHgtGHZ/GzmcEb07uxpXmn/LrpvEZkdknlizqSIHbO5wu/JyV0zywDOAq734vixZvueamb99SMqawPcfcWJ9O+WTveMFB5ZtIWHFm1hd7mPP3xjHGnJiV95nXOO/351NTv2VfPs3FPCstRbekoSD12Txx1vrGVwdkeumpQTFV0pZkZaciJpyYl0SU+hX9d0puQ2nK9wzrFmdwWvr9zNkx9v4/x7FnJ5Xn9uPnsYPTp9+Qerpi7Iql1lrNpZxsjenZk0uLtXb0fagZ37ahjVJzoaGJ4UfudcFaD/i1pga2kVs/76ETX+IH//ziRG9808+NhtF42ib9cO/Ob1tZSU13LXFSce7JcP1jv+46VVPLN0BzeensvEQU2fSG0LqUmJ3HrhqLDtv62ZGSP7dGZkn85cN20w9763gceXbOW5/B1kpCbRMTWJlKQECvbVEKz/8hvxheP68MvzRrTqOgaJL4FgPXXB+sMaWTV1QfZU1UXFVbvg/XBOoaEb5/llBfgCQepC3ROFZT527fexbW8V6SlJPPWdyYw8pLVgZsydnkuvzA787PkVnPmHD7jpjCFcO2UgP3v+c179fDffnZHLT84+waN3Fv0y05P51QUjuWryAF74bCflNX4qawPU+INcNK4P4/p1YXjvTjy/rIA/v7+J99YU8f0zhnLt1IGkJiUe/QASV/7zldW8u6aIV2469Svnjz7esgeA/t28H8MPHg/nbKn23Me/u6yGr//5Q3aV+UhNSiAlMYHU5AR6dk6jT5cO9O3SgasmD2BIj45H3E/Bvmr++9XVvPlFEekpiVTXBbnl3OFcf1puhN5J+7dtTxX/9cpq3l1bzIDu6dxy7gjOGdUzKrq2JDpcMW8JH23ey7ShWTz2rYkkJhiFZT4uuHchnTsk88r3TiUjNXLt7ag7udsa7bXw76+u4xsPLGF3mY9n5k7+SjfOsfrnumLufmcDsyb255sn57RBSjnUB+tL+PWrq9lQXMnovp3p1TmN5MQEOqQkcuWkAZw0oKvXEcUjM37/PmU1fvZW1fGjM4fxbzNyuWLeR6zZXc5L353K0J6dIpon7gt/cYWPRxdv5QdnDD3sJKgXauqCXPXwx6wsKOOxb5988MSjxIZAsJ6nl+7gxU8LqA3U4w/WU1xRy/5qP7Mm5vCLmcM171Cccc4x6tY3mTUxh31Vdby4fCfTh2bzwfoS7p01ngvH9Yl4pqga1eOFxxZv5S/vb2Jg9/SoaAn/x0ur+HT7Pv48e4KKfgxKSkzg6skDuHrygIPbqmoD3PX2eh79cCtvfVHIheP6kNMtnf7d0hnZp3PUnNiT8KioDVBdF6RX5zR+fPYwVu0q44P1JXxr6kBPiv6RxEXhd87x0vJdADy6eCuX53k72VdpZS0vLd/JNacM5NwxvT3LIW0rIzWJX10wkksn9OX219bwj/wdVDWahG5cv0zOG9Ob88f29nzpPWl7RWU+AHpmpjUMc/7Xk3lt5W7mnDrI42SHi4vC/+n2fezcX8OU3O58uGkPH2/Zy2QPx2S/+OlO/EHHlZO8/+YhbW9Un0yeum4yzjn2VtWxfW81H23ey+srd/PbN9byuzfX8dNzTuC6aYObvfBOYk9ReS0APUPz8OR0T+fG06NzcEVczGj10vJdpCYlcM+s8XRJT+axxVuPeV8lFbXc9fZ6Jv/mXe57b0OrX++c45ml2zlpQNeIn+iRyDIzundMZXxOV248PZdXbjqVBT+dwVkje/LbN9ZyzaOfUFzu8zqmtJHC0H/LWLjOo90X/kCwntc+382ZI3qS1TGVK07O4a3VhRTsq27VfuoC9dzywudMveM97n53A/5gPQ8v2oLPHzz6ixtZtm0fm0qq+GajycskfuR0T+fPV07gt5eNYenWvZx790LeX1fsdSxpA0Whwt/T4+lKWqLdF/7Fm/awp6qOi05sOLly9SkNJ+Oe+Kh10zz/76cFPP3JDr5+Ul/e+/Fp3DNrPPuq/cxfVdiq/TyzdAcdU5M4X337ccvMmDUxh1e+dyrZnVK59tGl/PaNNfiD9V5Hk+NQWOYjs0NyVIwaPJp2X/hfWr6TTmlJnH5CNgB9u3TgnFG9eOaTHdTUtay1Hqx3PPjBJsb2y+Q3l45hcHZHThncnUFZGfz945b/ASn3+Xnt891cOK5PRC/ikOg0tGcn/u+7U5k9KYcHP9jM5Q8uYfue1n0TlehRVO6jVwy09qGdF36fP8hbXxRx7uheX7m8/topAymr8fNkC1v9b35RyNY91dx4Wu7B0UAJCcbsiTks3bqPtYXlLdrPy8t3UeMPcoW6eSQkLTmR31w6hvtmj2djUSVn/+kD7v/nRuoCav3HmqJyHz1joH8f2nnhf29tMZW1AS4+se9Xtk8c1I0ZJ2Tzx7fXs2PvkVtYzjn+8v4mBmdlcPaoXl957Osn9SMlKYGnPt7eojzPLt1xcNFykcYuGNuHN380ndOH9eB3b67jvHsW8smWvV7HklYoLPcdHNET7dp14X9nTRHZnVIPG7ppZvz60jEkGPz7iys50tXLizfuYeXOMuZOH0ziIUPvumWkcP6Y3rzw6U6qagNHzLJs2z5W7ixj9kQtGC5N69OlAw9cfRKPXJuHzx/km/OW8F+vrG5xl6R4J1jvKKmojYkRPdDOC///fH0sz86dfFjBhoa+/p/NHM7CDaW8+NnOZvfxlw820qNTKpdO6Nvk41dOyqGyNsArK3YdMcsji7fQOS2Jyyb0a92bkLjzteE9eetH0/nXyQN4ZPEWzr9nIYs3lqr7J4qVVtZS72JjRA+088KflJjA4OzmZ7W8avIAJuR04b9eXU1pZe1hj6/YsZ/FG/fwnWmDmp2C96QBXTmhZyf+8PZ63li5u8lvDzv31zB/VSGzJubopK60SHpKEv958Wie+s4kagP1XPnQx4y6dT7n3r2QW15YSUnF4b+v4p3CstgZygntvPAfTWKCcefXx1JVG+DXr64+7PHfv7WOLunJzJrY/BW2ZsYfLh9H94wUbvz7p1z98CdsLK74ynMe/3ArAP86ZWBbxpc4MGVIFm/9aDr3zR7Pd6YNpkenVF74tIBvzltysNiI9w5evKXC3zwz62Jmz5vZWjNbY2aneJEDGobUXT89l/9bvouPN+85uP3DjaUs3FDK92YMoVPakWdZHN03k1dvOpXbLhzJioL9nHf3ooNdP1W1AZ7+ZDszR/fSJF1yTDJSk7hgbB9+PnM4j397Ik/MmURxeS2XP7jkqIMTJDIOXIHdM1Mnd4/kbmC+c244MA5Y41EOAL47Ywh9u3Tg1pe/IBCsxznHnfPX0iczjasazb54JEmJCVw7dRD//MnpjOufyU1Pf8Zf3t/E88sKqPAF+PbU6JuoSWLTxEHdePI7k9hfXcc3H1zChqKKo79Iwqqw3EdigtE9Q4W/SWaWCUwHHgZwztU55/ZHOkdjHVIS+Y8LRrC2sIInPtrGG6sKWVFQxo/OGtbqq/CyOqbyxJxJXDC2N3fOX8vtr6/hxP5dtDiHtKkT+3fh6bmTqQvWc8G9i3hs8Rbq66N/bY32qrCslh6dUpscSBKNvGjxDwJKgEfN7DMze8jMMg59kpnNNbN8M8svKSkJe6hzRvVi2tAs/vjWeu6cv5ZhPTse8wictORE7rliPDeclktdoJ7rpw9u47QiDbOAvv6DaUwdksVtr6zmmkc/YXdZjdex4lJxhS9mTuyCN4U/CZgA/MU5Nx6oAn5x6JOcc/Occ3nOubzs7OywhzIzbrtoFL5AkG17qvnpOcOP6693QoLxi3OHk/+rMzXnvoRNj05pPHxNHrdfOpr8rfv42u8/4I9vrz/qdSXStgrLfPTsHBvdPODNfPwFQIFz7uPQ/edpovB7ITe7I786fyRf7CrjzBE92mSfWR1j55dBYpOZceWkAUwbks2db67lnnc38NTH2/nW1IHkZmfQO7MDWZ1S8Qfq8QWC+AOOIT060iEl+icTixWF5T6m5Hq3xkdrRbzwO+cKzWyHmZ3gnFsHnAEcPpbSI9doyKXEqJzu6dw/ewJzTt3Hb19fw+/eXNfsc1OTEpg6JIuvDe/B2SN70iOGuimiTXVdgApfIGbm6QHvVuC6Cfi7maUAm4FveZRDpN2ZkNOVf9wwhT2Vtewu87G7zEdpZS0piQl0SEkkweDjLXt5d00x760t5v+9tIqpQ7K4dHxfzhnVSxcZttKXK2+p8B+Rc245cNjK7yLSdrp3TKV7x1RG9z18UsCZo3vz/y4YyYbiSl5ZsYsXP9vJzc+tILPDan545lCumjyA5MS4vr6zxQ5cSBcr8/RAnF+5KxLPzIxhPTvx47NPYOHPZvCPG05hTN9M/vOV1Zx790LeXVOkxWFaIJZW3jpA3+lEBDPj5IHdeGLORN5ZU8ztr61mzuP5pKckkjewG6cM7s7siTlkph/5KvZ49GXhj52BHCr8InKQmXHWyJ5MH5bFe2uK+WjzHj7avJc756/l2aXbeeiakxnSo/mJD+NRYbmPjJTEo07tEk1U+EXkMKlJiZw7pvfBa1Dyt+7lhieXcen9i7ln9nhmnNA2w53bg1haeesA9fGLyFHlDezGS987lf7d0pnz2FLufmeD+v9DisprY2pED6jwi0gL9e3SgedvPIULx/XhrnfWc+G9i1hZUOZ1LE8VlvnYUFRBnxibeVeFX0RaLD0libuvGM+DV5/E3qo6Lr5/Eb99fQ3VdfE3RURVbYA5jy8lWO+4bnpszb6rwi8irXbOqF68ffNpXJ7XnwcXbObsuxbwz3XFXseKmGC94wfPLGfN7nLumz2B4b06ex2pVVT4ReSYZHZI5o7QutapSQl869Gl3PjkMj7cVNrup4j+zetreGdNEbddNIoZw2PvRLdG9YjIcZk0uDuv/2AaD7y/mXkLNvHGqkJ6Z6Zx8Yl9uXbKwJi6orUlHlm0hYcXbeHaKQP511MGeh3nmFhTi4NHm7y8PJefn+91DBE5ipq6IG+vKeLFTwtYsKGUpATjmikDueG0XLplpHgdr1V8/iCVtYGvzLD78opdfP/pz5g5qhf3Xzkh6hdeMbNlzrnDpsdR4ReRsNixt5q73lnPi5/tJCMliZ/NPIGrJw/ALLqL5QG3vLCSZ5du59wxvbl++mDKawJ867FPGJ/Tlb99e2KrV+fzggq/iHhifVEFv35tDQvWl3DZhL785tIxUV80awNB8n79Dj06pVJcXktFbYCkBCM3uyPP3XAKmR1i4yrd5gq/+vhFJKyG9ezEY9eezD3vbeBP72xgfVEFD1x1Ev26pnsdrVmLN5ZS4QtwzxXjyRvYlac/2c4nW/by60vGxEzRPxKN6hGRsEtIMH545jAeviaPbaXVnHPXAv7y/iZqA0GvozXp1c930zktialDsuiUlqMc4UsAAAqjSURBVMzc6bk8dM3J7eZEtQq/iETMGSN68tr3p3FKbhZ3zl/L2Xct4K0vCr2O9RW1gSBvry7i7FG9SElqnyWyfb4rEYlaOd3TeeiaPP727YmkJCYw94ll3PDEMoorfF5HA2DRhoZunvPH9vY6Sth40sdvZluBCiAIBJo6+SAi7dv0Ydm8/oNp/HXhZv70zgaW/HEPP585vOGEakUtJRW1VNUF8PmD+PxBTuzflVkT+4d9VNBrn+8ms0MyU3OzwnocL3l5cneGc67Uw+OLiMeSExP4t9OHcM6oXvz8+c/59xdXfuXxtOQE0pITSTTjufwCFm0s4X/+ZRwdw7Qu8IFunpmj2283D2hUj4hEgdzsjjx3/Snkb9tHalICPTqn0j0j9WDxdc4xb8Fm7py/lnWFFTx49UkM6dGpzXMsXF9KRW377uYB7wq/A94yMwc86Jyb51EOEYkSCQnGxEHdmnzMzLj+tFzG9Mvk+09/xkX3Lea3l43h4hP7Htcx91bVceG9iwAYmJVOSUVtQzfPkPbbzQPendw91Tk3ATgX+K6ZTT/0CWY218zyzSy/pKQk8glFJOpMyc3i1ZumMapPZ37wzHJ++eJKfP5jHxL6yKIt7CqrYXxOFyprg5RU1DJ7Ug7Jie23mwei4MpdM7sNqHTO/b655+jKXRFpzB+s5/dvrePBDzYzqk9nHj6GMfZlNX5OveM9Th2axV+uOilMSb3V3JW7Ef+zZmYZZtbpwG3gbGBVpHOISOxKTkzglnNHNFwQtqeayx9cQsG+6lbt44klW6moDfDdGUPCEzKKefF9piewyMxWAJ8Arznn5nuQQ0Ri3BkjevLkdyaxv7qOyx9YwtbSqha9rrouwMOLtjDjhGxG980Mc8roE/HC75zb7JwbF/oZ5Zy7PdIZRKT9OLF/F56eOxlfoJ7LH1zC8h37j/qapz7ezr5qP9/72tAIJIw+7fsMhojEhVF9Mnlm7mTM4JL7F/Pj51ZQVH74lcDOOXaX1TBvwWam5HbnpAFdPUjrPY3jF5F2YVjPTrxz82nc98+NPLpoK2+s2s1pw7JJSkwgwRpO5q7aWU5pZS1mcPcV472O7BkVfhFpNzqlJXPLuSOYPTGH/3lzHWt3l1PvoN450lOSOP2EbEb36czJg7oxqk/89e0foMIvIu3OgO4Z3D97gtcxopb6+EVE4owKv4hInFHhFxGJMyr8IiJxRoVfRCTOqPCLiMQZFX4RkTijwi8iEmc8n4+/JcysBNgWupsJlB3h9qH/ZgGtWdu38T5b+lhzmZrK1dS2cGdsLlNzt6MpX1O5mtqmz1CfYTjzNZXr0G3JrczX1hmbuj3AOZd92J6dczH1A8w70u0m/s0/1v239LHmMjWVx4uMzWWKls/wSPn0GeozjIZ8LfkMW5svEp9hcz+x2NXzylFuH/rv8ey/pY81l6m5PJHO2Fym5m5HU77m8kRTRn2GLXtMn2HLchzpsdZ+hk2Kia6e42Fm+a6JpceiSbRnjPZ8EP0Zoz0fRH9G5Ws7sdjib615XgdogWjPGO35IPozRns+iP6MytdG2n2LX0REvioeWvwiItKICr+ISJxR4RcRiTNxXfjNbJqZPWBmD5nZh17nOZSZJZjZ7WZ2r5ld43WeppjZ6Wa2MPQ5nu51nqaYWYaZ5ZvZBV5naYqZjQh9fs+b2Y1e5zmUmV1iZn81s2fN7Gyv8zTFzAab2cNm9rzXWQ4I/d49HvrsrvQ6T2MxW/jN7BEzKzazVYdsn2lm68xso5n94kj7cM4tdM7dALwKPB5t+YCLgX6AHyhoy3xtmNEBlUBaW2dso3wAPweea8tsbZnRObcm9Ht4OTA1CvP9n3PuOuAG4Jttma8NM252zs1p62yHamXWy4DnQ5/dReHO1iqtvdIsWn6A6cAEYFWjbYnAJmAwkAKsAEYCY2go7o1/ejR63XNAp2jLB/wCuD702uej8TMEEkKv6wn8PQrznQVcAVwLXBCNn2HoNRcBbwCzozFf6HV/ACZE62cYrv9PjiPrLcCJoec8Fc5crf2J2cXWnXMLzGzgIZsnAhudc5sBzOwZ4GLn3G+BJr/mm1kOUOacq4i2fGZWANSF7gbbMl9bZWxkH5AabflC3U8ZNPyPWGNmrzvn6qMpY2g/LwMvm9lrwFPRlM/MDLgDeMM592lbZWvLjJHSmqw0fAPuBywnynpXYrbwN6MvsKPR/QJg0lFeMwd4NGyJvqq1+V4A7jWzacCCcAZrpFUZzewy4BygC3BfeKMBrcznnPslgJldC5S2ZdE/gtZ+hqfT0C2QCrwe1mQNWvt7eBNwJpBpZkOccw+EM1xIaz/D7sDtwHgzuyX0ByJSmst6D3CfmZ3PsU/pEBbtrfC3mnPuVq8zNMc5V03DH6ao5Zx7gYY/UFHNOfeY1xma45x7H3jf4xjNcs7dQ0MRi1rOuT00nIOIGs65KuBbXudoSlR9/WgDO4H+je73C22LFtGeD6I/Y7Tng+jPGO35IDYyHhBLWYH2V/iXAkPNbJCZpdBwUu9ljzM1Fu35IPozRns+iP6M0Z4PYiPjAbGUtYHXZ5eP4+z608BuvhzqOCe0/TxgPQ1n2X+pfLGbMdrzxULGaM8XKxljMeuRfjRJm4hInGlvXT0iInIUKvwiInFGhV9EJM6o8IuIxBkVfhGROKPCLyISZ1T4JWaZWWWEj9cmazZYwxoGZWa23MzWmtnvW/CaS8xsZFscX0SFXyTEzI44d5VzbkobHm6hc+5EYDxwgZkdbR7+S2iYYVTkuKnwS7tiZrlmNt/MllnDymDDQ9svNLOPzewzM3vHzHqGtt9mZk+Y2WLgidD9R8zsfTPbbGbfb7TvytC/p4cefz7UYv97aOpizOy80LZlZnaPmb16pLzOuRoapu3tG3r9dWa21MxWmNn/mlm6mU2hYb7+34W+JeQ29z5FWkKFX9qbecBNzrmTgJ8Afw5tXwRMds6NB54BftboNSOBM51zs0L3h9Mw1fRE4FYzS27iOOOBH4ZeOxiYamZpwIPAuaHjZx8trJl1BYby5bTbLzjnTnbOjQPW0DAlwIc0zP3yU+fcic65TUd4nyJHFffTMkv7YWYdgSnAP0INcPhycZh+wLNm1puGVZK2NHrpy6GW9wGvOedqgVozK6ZhdbFDl5X8xDlXEDrucmAgDUtQbnbOHdj308DcZuJOM7MVNBT9PznnCkPbR5vZr2lY36Aj8GYr36fIUanwS3uSAOwP9Z0f6l7gj865l0MLn9zW6LGqQ55b2+h2kKb/P2nJc45koXPuAjMbBHxkZs8555YDjwGXOOdWhBaPOb2J1x7pfYoclbp6pN1wzpUDW8zsG9CwZKCZjQs9nMmXc6RfE6YI64DBjZbmO+rC5KFvB3fQsCA8QCdgd6h76cpGT60IPXa09ylyVCr8EsvSzayg0c/NNBTLOaFulC9oWPsUGlr4/zCzZUBpOMKEuov+DZgfOk4FUNaClz4ATA/9wfgP4GNgMbC20XOeAX4aOjmdS/PvU+SoNC2zSBsys47OucrQKJ/7gQ3Oubu8ziXSmFr8Im3rutDJ3i9o6F560OM8IodRi19EJM6oxS8iEmdU+EVE4owKv4hInFHhFxGJMyr8IiJxRoVfRCTO/H9WGu66CMhC6QAAAABJRU5ErkJggg==
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#slow</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>4.412179</td>
      <td>2.753212</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2.954786</td>
      <td>2.171412</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2.420020</td>
      <td>2.099426</td>
      <td>00:15</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="o">=</span><span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>category</th>
      <th>category_</th>
      <th>target1</th>
      <th>target2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>the magnetic field is part of what sort of recorder? bell worked extensively in medical research and invented techniques for teaching speech to the deaf. during his volta laboratory period, bell and his associates considered impressing a magnetic field on a record as a means of reproducing sound. although the trio briefly experimented with the concept, they could not develop a workable prototype. they abandoned the idea, never realizing they had glimpsed a basic principle which would one day find its application in the tape recorder, the hard disc and floppy disc drive and other magnetic media.</td>
      <td>99</td>
      <td>101</td>
      <td>99</td>
      <td>101</td>
    </tr>
    <tr>
      <th>1</th>
      <td>where was the university evacuated? between the german invasion of poland on 1 september 1939 and the anglo - french declaration of war against the german reich on 3 september 1939, the entire city ( a total of 120, 000 people ) was evacuated, like other border towns as well. until the arrival of the wehrmacht troops mid - june 1940, the city was, for ten months, completely empty, with the exception of the garrisoned soldiers. the jews of strasbourg had been evacuated to perigueux and limoges, the university had been evacuated to clermont - ferrand.</td>
      <td>111</td>
      <td>116</td>
      <td>111</td>
      <td>116</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inf_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">([{</span>
    <span class="s1">&#39;text0&#39;</span><span class="p">:</span> <span class="s1">&#39;What did George Lucas make?&#39;</span><span class="p">,</span>
    <span class="s1">&#39;text1&#39;</span><span class="p">:</span> <span class="s1">&#39;George Lucas created Star Wars in 1977. He directed and produced it.&#39;</span>   
<span class="p">}],</span> 
    <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;columns&#39;</span><span class="p">)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inf_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((&#39;11&#39;, &#39;13&#39;),
 tensor([11]),
 tensor([[1.9953e-05, 6.6960e-06, 7.5335e-07, 1.7125e-06, 7.1178e-07, 1.2500e-06,
          1.0880e-07, 1.9954e-05, 6.6870e-04, 4.3924e-05, 2.1026e-03, 9.9656e-01,
          7.1035e-05, 1.8911e-05, 3.0116e-05, 2.0009e-05, 2.4065e-04, 1.0099e-04,
          2.6297e-06, 3.6813e-05, 4.9420e-06, 1.9948e-05, 1.9984e-05, 8.5654e-08,
          9.5072e-08, 8.9944e-08, 8.9454e-08, 9.1328e-08, 9.4035e-08, 9.3781e-08,
          8.7999e-08, 9.0398e-08, 9.3350e-08, 9.2285e-08, 8.5133e-08, 8.3271e-08,
          8.7424e-08, 8.7053e-08, 8.3034e-08, 8.3653e-08, 8.4636e-08, 8.8034e-08,
          8.9929e-08, 8.7365e-08, 9.0708e-08, 9.0124e-08, 8.9394e-08, 8.8992e-08,
          8.9814e-08, 9.0405e-08, 9.4208e-08, 9.3037e-08, 9.1948e-08, 9.3707e-08,
          9.7754e-08, 9.7393e-08, 9.5191e-08, 9.2520e-08, 9.3175e-08, 9.8658e-08,
          9.7461e-08, 9.2410e-08, 9.0433e-08, 9.3034e-08, 9.8031e-08, 9.2164e-08,
          8.9365e-08, 9.1023e-08, 9.2003e-08, 9.6528e-08, 9.1928e-08, 9.2340e-08,
          9.3290e-08, 9.5564e-08, 9.3305e-08, 9.4039e-08, 9.3995e-08, 9.5854e-08,
          9.8225e-08, 9.4144e-08, 9.6120e-08, 9.7631e-08, 1.0059e-07, 1.0124e-07,
          9.5964e-08, 9.4422e-08, 9.9311e-08, 1.0544e-07, 1.0219e-07, 9.2500e-08,
          8.8211e-08, 9.3711e-08, 8.9126e-08, 7.9090e-08, 8.6327e-08, 8.1980e-08,
          8.8299e-08, 8.2458e-08, 7.6450e-08, 7.9317e-08, 7.8627e-08, 7.2060e-08,
          6.8993e-08, 7.3957e-08, 7.7961e-08, 8.6862e-08, 8.3683e-08, 7.8785e-08,
          7.8605e-08, 8.1771e-08, 8.9369e-08, 8.4733e-08, 8.4885e-08, 8.6142e-08,
          9.3352e-08, 9.4181e-08, 8.6686e-08, 8.0790e-08, 7.9248e-08, 7.9655e-08,
          7.3580e-08, 7.0639e-08, 8.0341e-08, 7.6880e-08, 7.9648e-08, 8.0002e-08,
          7.3522e-08, 7.5676e-08]]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inp_ids</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;What did George Lucas make?&#39;</span><span class="p">,</span>
                              <span class="s1">&#39;George Lucas created Star Wars in 1977. He directed and produced it.&#39;</span><span class="p">)</span>

<span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">inp_ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">11</span><span class="p">:</span><span class="mi">13</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;star&#39;, &#39;wars&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note that there is a bug currently in fastai v2 (or with how I'm assembling everything) that currently prevents us from seeing the decoded predictions and probabilities for the "end" token.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inf_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">([{</span>
    <span class="s1">&#39;text0&#39;</span><span class="p">:</span> <span class="s1">&#39;When was Star Wars made?&#39;</span><span class="p">,</span>
    <span class="s1">&#39;text1&#39;</span><span class="p">:</span> <span class="s1">&#39;George Lucas created Star Wars in 1977. He directed and produced it.&#39;</span>
<span class="p">}],</span> 
    <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;columns&#39;</span><span class="p">)</span>

<span class="n">test_dl</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">test_dl</span><span class="p">(</span><span class="n">inf_df</span><span class="p">)</span>
<span class="n">inp</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">get_preds</span><span class="p">(</span><span class="n">dl</span><span class="o">=</span><span class="n">test_dl</span><span class="p">,</span> <span class="n">with_input</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_decoded</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">inp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> 
                                   <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;1977&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#slow</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mf">1e-7</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.253970</td>
      <td>00:01</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-35-59612d846f50&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg">#slow</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>learn<span class="ansi-blue-fg">.</span>fit_one_cycle<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">3</span><span class="ansi-blue-fg">,</span> lr_max<span class="ansi-blue-fg">=</span>slice<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1e-7</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">1e-4</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/development/projects/blurr/_libs/fastcore/fastcore/utils.py</span> in <span class="ansi-cyan-fg">_f</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    429</span>         init_args<span class="ansi-blue-fg">.</span>update<span class="ansi-blue-fg">(</span>log<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    430</span>         setattr<span class="ansi-blue-fg">(</span>inst<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;init_args&#39;</span><span class="ansi-blue-fg">,</span> init_args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 431</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> inst <span class="ansi-green-fg">if</span> to_return <span class="ansi-green-fg">else</span> f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    432</span>     <span class="ansi-green-fg">return</span> _f
<span class="ansi-green-intense-fg ansi-bold">    433</span> 

<span class="ansi-green-fg">~/development/projects/blurr/_libs/fastai2/fastai2/callback/schedule.py</span> in <span class="ansi-cyan-fg">fit_one_cycle</span><span class="ansi-blue-fg">(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)</span>
<span class="ansi-green-intense-fg ansi-bold">    111</span>     scheds = {&#39;lr&#39;: combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),
<span class="ansi-green-intense-fg ansi-bold">    112</span>               &#39;mom&#39;: combined_cos(pct_start, *(self.moms if moms is None else moms))}
<span class="ansi-green-fg">--&gt; 113</span><span class="ansi-red-fg">     </span>self<span class="ansi-blue-fg">.</span>fit<span class="ansi-blue-fg">(</span>n_epoch<span class="ansi-blue-fg">,</span> cbs<span class="ansi-blue-fg">=</span>ParamScheduler<span class="ansi-blue-fg">(</span>scheds<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">+</span>L<span class="ansi-blue-fg">(</span>cbs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> reset_opt<span class="ansi-blue-fg">=</span>reset_opt<span class="ansi-blue-fg">,</span> wd<span class="ansi-blue-fg">=</span>wd<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    114</span> 
<span class="ansi-green-intense-fg ansi-bold">    115</span> <span class="ansi-red-fg"># Cell</span>

<span class="ansi-green-fg">~/development/projects/blurr/_libs/fastcore/fastcore/utils.py</span> in <span class="ansi-cyan-fg">_f</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    429</span>         init_args<span class="ansi-blue-fg">.</span>update<span class="ansi-blue-fg">(</span>log<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    430</span>         setattr<span class="ansi-blue-fg">(</span>inst<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;init_args&#39;</span><span class="ansi-blue-fg">,</span> init_args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 431</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> inst <span class="ansi-green-fg">if</span> to_return <span class="ansi-green-fg">else</span> f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    432</span>     <span class="ansi-green-fg">return</span> _f
<span class="ansi-green-intense-fg ansi-bold">    433</span> 

<span class="ansi-green-fg">~/development/projects/blurr/_libs/fastai2/fastai2/learner.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-fg">(self, n_epoch, lr, wd, cbs, reset_opt)</span>
<span class="ansi-green-intense-fg ansi-bold">    198</span>                     <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    199</span>                         self<span class="ansi-blue-fg">.</span>epoch<span class="ansi-blue-fg">=</span>epoch<span class="ansi-blue-fg">;</span>          self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;begin_epoch&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 200</span><span class="ansi-red-fg">                         </span>self<span class="ansi-blue-fg">.</span>_do_epoch_train<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    201</span>                         self<span class="ansi-blue-fg">.</span>_do_epoch_validate<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    202</span>                     <span class="ansi-green-fg">except</span> CancelEpochException<span class="ansi-blue-fg">:</span>   self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;after_cancel_epoch&#39;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/development/projects/blurr/_libs/fastai2/fastai2/learner.py</span> in <span class="ansi-cyan-fg">_do_epoch_train</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    173</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    174</span>             self<span class="ansi-blue-fg">.</span>dl <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>dls<span class="ansi-blue-fg">.</span>train<span class="ansi-blue-fg">;</span>                        self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;begin_train&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 175</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>all_batches<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    176</span>         <span class="ansi-green-fg">except</span> CancelTrainException<span class="ansi-blue-fg">:</span>                         self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;after_cancel_train&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    177</span>         <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>                                             self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;after_train&#39;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/development/projects/blurr/_libs/fastai2/fastai2/learner.py</span> in <span class="ansi-cyan-fg">all_batches</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    151</span>     <span class="ansi-green-fg">def</span> all_batches<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    152</span>         self<span class="ansi-blue-fg">.</span>n_iter <span class="ansi-blue-fg">=</span> len<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>dl<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 153</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">for</span> o <span class="ansi-green-fg">in</span> enumerate<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>dl<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">.</span>one_batch<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>o<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    154</span> 
<span class="ansi-green-intense-fg ansi-bold">    155</span>     <span class="ansi-green-fg">def</span> one_batch<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> i<span class="ansi-blue-fg">,</span> b<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/development/projects/blurr/_libs/fastai2/fastai2/learner.py</span> in <span class="ansi-cyan-fg">one_batch</span><span class="ansi-blue-fg">(self, i, b)</span>
<span class="ansi-green-intense-fg ansi-bold">    162</span>             <span class="ansi-green-fg">if</span> <span class="ansi-green-fg">not</span> self<span class="ansi-blue-fg">.</span>training<span class="ansi-blue-fg">:</span> <span class="ansi-green-fg">return</span>
<span class="ansi-green-intense-fg ansi-bold">    163</span>             self<span class="ansi-blue-fg">.</span>loss<span class="ansi-blue-fg">.</span>backward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">;</span>                            self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;after_backward&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 164</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>opt<span class="ansi-blue-fg">.</span>step<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">;</span>                                 self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;after_step&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    165</span>             self<span class="ansi-blue-fg">.</span>opt<span class="ansi-blue-fg">.</span>zero_grad<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    166</span>         <span class="ansi-green-fg">except</span> CancelBatchException<span class="ansi-blue-fg">:</span>                         self<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;after_cancel_batch&#39;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/development/projects/blurr/_libs/fastai2/fastai2/optimizer.py</span> in <span class="ansi-cyan-fg">step</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">     81</span>     <span class="ansi-green-fg">def</span> step<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     82</span>         <span class="ansi-green-fg">for</span> p<span class="ansi-blue-fg">,</span>pg<span class="ansi-blue-fg">,</span>state<span class="ansi-blue-fg">,</span>hyper <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>all_params<span class="ansi-blue-fg">(</span>with_grad<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 83</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">for</span> cb <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>cbs<span class="ansi-blue-fg">:</span> state <span class="ansi-blue-fg">=</span> _update<span class="ansi-blue-fg">(</span>state<span class="ansi-blue-fg">,</span> cb<span class="ansi-blue-fg">(</span>p<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span><span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">**</span>state<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>hyper<span class="ansi-blue-fg">}</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     84</span>             self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">[</span>p<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> state
<span class="ansi-green-intense-fg ansi-bold">     85</span> 

<span class="ansi-green-fg">~/development/projects/blurr/_libs/fastai2/fastai2/optimizer.py</span> in <span class="ansi-cyan-fg">average_grad</span><span class="ansi-blue-fg">(p, mom, dampening, grad_avg, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    119</span> <span class="ansi-green-fg">def</span> average_grad<span class="ansi-blue-fg">(</span>p<span class="ansi-blue-fg">,</span> mom<span class="ansi-blue-fg">,</span> dampening<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span> grad_avg<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    120</span>     <span class="ansi-blue-fg">&#34;Keeps track of the avg grads of `p` in `state` with `mom`.&#34;</span>
<span class="ansi-green-fg">--&gt; 121</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">if</span> grad_avg <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span> grad_avg <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>zeros_like<span class="ansi-blue-fg">(</span>p<span class="ansi-blue-fg">.</span>grad<span class="ansi-blue-fg">.</span>data<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    122</span>     damp <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">-</span>mom <span class="ansi-green-fg">if</span> dampening <span class="ansi-green-fg">else</span> <span class="ansi-cyan-fg">1.</span>
<span class="ansi-green-intense-fg ansi-bold">    123</span>     grad_avg<span class="ansi-blue-fg">.</span>mul_<span class="ansi-blue-fg">(</span>mom<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>add_<span class="ansi-blue-fg">(</span>p<span class="ansi-blue-fg">.</span>grad<span class="ansi-blue-fg">.</span>data<span class="ansi-blue-fg">,</span> alpha<span class="ansi-blue-fg">=</span>damp<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">RuntimeError</span>: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 1; 10.91 GiB total capacity; 3.33 GiB already allocated; 9.88 MiB free; 3.34 GiB reserved in total by PyTorch)</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot_loss</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="o">=</span><span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inf_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preds</span><span class="p">,</span> <span class="n">pred_classes</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inf_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">preds</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inp_ids</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;When was Star Wars made?&#39;</span><span class="p">,</span>
                              <span class="s1">&#39;George Lucas created Star Wars in 1977. He directed and produced it.&#39;</span><span class="p">)</span>

<span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">inp_ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="nb">int</span><span class="p">(</span><span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span><span class="nb">int</span><span class="p">(</span><span class="n">preds</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And what about inference?</p>
<p>Note that I had to replace the loss function because of the above-mentioned issue to exporting the model with the <a href="/blurr/02c_modeling-question-answering#MultiTargetLoss"><code>MultiTargetLoss</code></a> loss function.  After getting our inference learner, we put it back and we're good to go!</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">loss_func</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s1">&#39;q_and_a_learn_export.pkl&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inf_learn</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s1">&#39;q_and_a_learn_export.pkl&#39;</span><span class="p">)</span>
<span class="n">inf_learn</span><span class="o">.</span><span class="n">loss_func</span> <span class="o">=</span> <span class="n">MultiTargetLoss</span><span class="p">()</span>

<span class="n">inf_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">([</span>
    <span class="p">{</span><span class="s1">&#39;text0&#39;</span><span class="p">:</span> <span class="s1">&#39;Who created Star Wars?&#39;</span><span class="p">,</span> 
     <span class="s1">&#39;text1&#39;</span><span class="p">:</span> <span class="s1">&#39;George Lucas created Star Wars in 1977. He directed and produced it.&#39;</span><span class="p">}],</span>
    <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;columns&#39;</span><span class="p">)</span>

<span class="n">inf_learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inf_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inp_ids</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;Who created Star Wars?&#39;</span><span class="p">,</span>
                              <span class="s1">&#39;George Lucas created Star Wars in 1977. He directed and produced it.&#39;</span><span class="p">)</span>

<span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">inp_ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">7</span><span class="p">:</span><span class="mi">9</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Cleanup">Cleanup<a class="anchor-link" href="#Cleanup"> </a></h2>
</div>
</div>
</div>
</div>
 

