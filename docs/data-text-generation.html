---

title: data.text_generation

keywords: fastai
sidebar: home_sidebar

summary: "This module contains the bits required to use the fastai DataBlock API and/or mid-level data processing pipelines to organize your data for text generation tasks using architectures like BART, T5, or good ol' GPT2, etc....  Abstract summarization and conversational agents are good examples of such tasks."
description: "This module contains the bits required to use the fastai DataBlock API and/or mid-level data processing pipelines to organize your data for text generation tasks using architectures like BART, T5, or good ol' GPT2, etc....  Abstract summarization and conversational agents are good examples of such tasks."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/01e_data-text-generation.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#cuda</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Using GPU #</span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Using GPU #1: GeForce GTX 1080 Ti
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Text-Generation-tokenization,-batch-transform,-and-DataBlock-methods">Text Generation tokenization, batch transform, and DataBlock methods<a class="anchor-link" href="#Text-Generation-tokenization,-batch-transform,-and-DataBlock-methods"> </a></h2><p>Text generation tasks attempt to generate a human-understandable and sensible response to a prior text.  For example, in summarization, our objective is to capture the meaning of a larger document in 1-3 sentences.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;./&#39;</span><span class="p">)</span>
<span class="n">cnndm_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;cnndm_sample.csv&#39;</span><span class="p">);</span> <span class="nb">len</span><span class="p">(</span><span class="n">cnndm_df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1000</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cnndm_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>article</th>
      <th>highlights</th>
      <th>ds_type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(CNN)  -- Globalization washes like a flood over the world's cultures and economies. Floods can be destructive; however, they can also bring blessings, as the annual floods of the Nile did for ancient Egypt. The world's great universities can be crucial instruments in shaping, in a positive way, humankind's reaction to globalization and the development of humankind itself. Traditionally, universities have been defined and limited by location, creating an academic community and drawing students and scholars to that place. Eventually, some universities began to encourage students to study el...</td>
      <td>John Sexton: Traditionally, universities have been defined and limited by location .\nGlobal campuses form a network of thought, innovation, he writes .\nFaculty can teach, Sexton says, students can team up in many cities at once .\nSexton: Research, scholarship can be shared and cultural ties made in "century of knowledge"</td>
      <td>train</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(CNN) -- Armenian President Robert Kocharian declared a state of emergency Saturday night after a day of clashes between police and protesters, a spokeswoman for the Armenian Foreign Ministry said. Opposition supporters wave an Armenian flag during a protest rally in Yerevan, Armenia, on Saturday. The protesters claim last month's presidential election was rigged. The state of emergency will "hopefully bring some order" to the capital, Yerevan, said Salpi Ghazarian, assistant to the Armenian foreign minister, who spoke to CNN early Sunday. The state of emergency could last until March 20, ...</td>
      <td>NEW: Protest moves after crackdown at Freedom Square .\nOrder sought after protests over last month's election turn violent .\nDemonstrators say the election was fraudulent .\nState of emergency could last until March 20, official says .</td>
      <td>train</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;facebook/bart-large-cnn&quot;</span>

<span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> 
                                                                               <span class="n">model_cls</span><span class="o">=</span><span class="n">BartForConditionalGeneration</span><span class="p">)</span>

<span class="n">hf_arch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_config</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large-cnn and are newly initialized: [&#39;final_logits_bias&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&#39;bart&#39;,
 transformers.tokenization_bart.BartTokenizer,
 transformers.configuration_bart.BartConfig,
 transformers.modeling_bart.BartForConditionalGeneration)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="HF_TextGenerationInput" class="doc_header"><code>class</code> <code>HF_TextGenerationInput</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/text_generation.py#L17" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>HF_TextGenerationInput</code>(<strong><code>iterable</code></strong>=<em><code>()</code></em>) :: <code>list</code></p>
</blockquote>
<p>Built-in mutable sequence.</p>
<p>If no argument is given, the constructor creates a new empty list.
The argument must be an iterable if specified.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We create a subclass of <a href="/blurr/data-core#HF_BatchTransform"><code>HF_BatchTransform</code></a> for generation tasks to add <code>decoder_input_ids</code> and <code>labels</code> to our inputs during training, which will in turn allow the huggingface model to calculate the loss for us.  See <a href="https://huggingface.co/transformers/model_doc/bart.html#transformers.BartModel.forward">here</a> for more information on these additional inputs are used in summarization and conversational training tasks.</p>
<p>Note also that <code>labels</code> is simply target_ids shifted to the right by one since the task to is to predict the next token based on the current (and all previous) <code>decoder_input_ids</code>.</p>
<p>And lastly, we also update our targets to just be the <code>input_ids</code> of our target sequence so that fastai's <code>Learner.show_results</code> works (again, almost all the fastai bits require returning a single tensor to work).</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="HF_TextGenerationBatchTransform" class="doc_header"><code>class</code> <code>HF_TextGenerationBatchTransform</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/data/text_generation.py#L20" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>HF_TextGenerationBatchTransform</code>(<strong><code>hf_arch</code></strong>, <strong><code>hf_tokenizer</code></strong>, <strong>**<code>kwargs</code></strong>) :: <a href="/blurr/data-core#HF_BatchTransform"><code>HF_BatchTransform</code></a></p>
</blockquote>
<p>Handles everything you need to assemble a mini-batch of inputs and targets, as well as decode
HF_TokenizerTransform inputs</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We had to override the <code>decodes</code> method above because, while both our inputs and targets are technically the same things, we update the later to consist of <em>only</em> the target input_ids so that methods like <code>Learner.show_results</code> work.  Nevertheless, because fastai remembers what they are, <a href="/blurr/data-core#HF_TokenizerTransform.decodes"><code>HF_TokenizerTransform.decodes</code></a> will be called for both and it works on a <code>list</code> of input_ids.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hf_batch_tfm</span> <span class="o">=</span> <span class="n">HF_TextGenerationBatchTransform</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">)</span>

<span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span> 
    <span class="n">HF_TextBlock</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">),</span> 
    <span class="n">HF_TextBlock</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_batch_tfm</span><span class="o">=</span><span class="n">hf_batch_tfm</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> 
                   <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;article&#39;</span><span class="p">),</span> 
                   <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">&#39;highlights&#39;</span><span class="p">),</span> 
                   <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># dblock.summary(cnndm_df)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">cnndm_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, torch.Size([4, 512]), torch.Size([4, 150]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">dls</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Israel is confronting a problem beyond the Hamas rockets screeching overhead -- a threat underfoot. The Israeli military says it is trying to demolish a sophisticated network of tunnels that run through parts of northeast Gaza, under the border and into southern Israel. Hamas has already used the tunnels several times in the past few days to attempt assaults on Israeli soil. The first attack, on July 17, was foiled but prompted Israel to announce a ground incursion into Gaza with the stated aim of taking out the tunnels. Another assault through tunnels s few days later resulted in clashes that killed more than 10 Hamas fighters and four Israeli soldiers. The assault near the town of Sderot appeared to target two communal areas "where farmers are trying to conduct their daily lives," said Israeli government spokesman Mark Regev. The Hamas fighters were disguised as Israeli soldiers, according to the Israel Defense Forces. The clashes forced area roads to close, residents to shelter in their homes and tied up security forces for hours. The method of attack, in which militants spring out unexpectedly from underground, has struck fear into Israelis living near Gaza. "Your enemy is about to blast his way into your dining room from below the floor while you are feeding your family. Sounds like a B-rated horror movie, right? This scenario is one real example of a Hamas tunnel discovered just in time by the IDF leading into a kibbutz communal dining hall," Benay Browne Katz, a volunteer medic and grandmother who lives in Jaffa, told CNN. 'Lower Gaza' The tunnel network has also been used during combat inside Gaza, the Israeli military says, allowing Hamas fighters to pop up and fire on soldiers or toss grenades before dropping back out of sight. Israeli military officials refer to the underground works as "Lower Gaza" and suggest at least some of the war is being waged underground. The tunnels aren't a new phenomenon. Hamas used one in 2006 to capture the Israeli soldier Gilad Shalit and take him back into Gaza. He was held captive for five years until a deal was struck for his release in exchange for more than 1,000 Palestinian prisoners. Memories of his capture were revived by a foiled attack over the weekend, in which one Hamas fighter who entered Israel through a tunnel was found to be carrying tranquilizers and handcuffs, according to the Israeli military. 'A whole industry' Israel received a warning of the growing scale and sophistication of the underground threat last year with the discovery of a tunnel that ran from the Khan Younis refugee camp in Gaza and emerged near the Israeli</td>
      <td>Hamas has used tunnels to stage attacks in Israel and Gaza, the Israeli military says.\nThe military has destroyed some tunnels, but says it believes there are many more.\nHamas used a tunnel to capture an Israeli soldier in 2006.\nA tunnel into Israel discovered last year showed increasing sophistication.</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(CNN)The same superbug that contributed to two deaths in Los Angeles has been reported in North Carolina, where one person has died, a spokesman told CNN. Eighteen people have contracted carbapenem-resistant Enterobacteriaceae, or CRE, so far this year, said Kevin McCarthy, spokesman with the Carolinas HealthCare System. Of those, 15 had CRE upon admission to the hospital in Charlotte; three acquired it in the hospital, and one died, the spokesman said. The cause of death was not immediately clear. McCarthy declined to provide details on any of the patients. It was also not clear how any of them became infected. In Los Angeles, seven patients contracted CRE after routine endoscopic procedures. Two of them died, the Ronald Reagan UCLA Medical Center said last week. CRE was a contributing factor in the deaths, but the exact cause of the deaths wasn't immediately disclosed in those cases either. Hospital officials there have said the outbreak was caused by two medical scopes that still carried the deadly bacteria even though disinfection guidelines were followed. The UCLA hospital was using a duodenoscope made by Olympus, but the Food and Drug Administration is also reviewing data from the two other U.S. companies that make the devices, Fujifilm and Pentax. The medical center is contacting 179 others who underwent endoscopic procedures between October and January. It's offering them home tests to screen for the bacteria. In a statement, McCarthy said Carolinas HealthCare System uses standard methods for disinfecting its equipment, saying that all duodenoscopes that have been tested have shown to be negative for CRE. Some CRE bacteria can resist most antibiotics, the Centers for Disease Control and Prevention says on its website. CNN's Ben Tinker, Michael Martinez and Steve Almasy contributed to this report.</td>
      <td>Eighteen people have contracted CRE so far this year at a hospital in Charlotte, North Carolina.\nCRE is highly resistant to many forms of antibiotic treatments, the CDC says.</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Cleanup">Cleanup<a class="anchor-link" href="#Cleanup"> </a></h2>
</div>
</div>
</div>
</div>
 

