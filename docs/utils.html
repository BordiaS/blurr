---

title: utils

keywords: fastai
sidebar: home_sidebar

summary: "Various utility functions used by the blurr package."
description: "Various utility functions used by the blurr package."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/00_utils.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#cuda</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Using GPU #</span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Using GPU #1: GeForce GTX 1080 Ti
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="str_to_class" class="doc_header"><code>str_to_class</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/utils.py#L15" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>str_to_class</code>(<strong><code>classname</code></strong>)</p>
</blockquote>
<p>converts string representation to class</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Singleton" class="doc_header"><code>class</code> <code>Singleton</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/utils.py#L20" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Singleton</code>()</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/blurr/utils#Singleton"><code>Singleton</code></a> functions as python decorator.  Use this above any class to turn that class into a singleton (see <a href="https://python-3-patterns-idioms-test.readthedocs.io/en/latest/Singleton.html">here</a> for more info on the singleton pattern).</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@Singleton</span>
<span class="k">class</span> <span class="nc">TestSingleton</span><span class="p">:</span> <span class="k">pass</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">TestSingleton</span><span class="p">()</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">TestSingleton</span><span class="p">()</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="ModelHelper">ModelHelper<a class="anchor-link" href="#ModelHelper"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="Singleton object at 0x7f7cb9a70e90>" class="doc_header"><code>Singleton object at 0x7f7cb9a70e90></code><a href="" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>Singleton object at 0x7f7cb9a70e90></code>(<strong>*<code>args</code></strong>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/blurr/utils#ModelHelper"><code>ModelHelper</code></a> is a <a href="/blurr/utils#Singleton"><code>Singleton</code></a> (there exists only one instance, and the same instance is returned upon subsequent instantiation requests).  You can get at via the <a href="/blurr/utils#BLURR_MODEL_HELPER"><code>BLURR_MODEL_HELPER</code></a> constant below.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mh</span> <span class="o">=</span> <span class="n">ModelHelper</span><span class="p">()</span>
<span class="n">mh2</span> <span class="o">=</span> <span class="n">ModelHelper</span><span class="p">()</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">mh</span><span class="p">,</span> <span class="n">mh2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Provide-global-helper-constant">Provide global helper constant<a class="anchor-link" href="#Provide-global-helper-constant"> </a></h3><p>Users of this library can simply use <a href="/blurr/utils#BLURR_MODEL_HELPER"><code>BLURR_MODEL_HELPER</code></a> to access all the <a href="/blurr/utils#ModelHelper"><code>ModelHelper</code></a> capabilities without having to fetch an instance themselves.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ModelHelper.get_architectures" class="doc_header"><code>ModelHelper.get_architectures</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/utils.py#L80" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ModelHelper.get_architectures</code>()</p>
</blockquote>
<p>Used to get all the architectures supported by your <code>Transformers</code> install</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_architectures</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;albert&#39;, &#39;auto&#39;, &#39;bart&#39;, &#39;bert&#39;, &#39;bert_japanese&#39;, &#39;camembert&#39;, &#39;ctrl&#39;, &#39;distilbert&#39;, &#39;electra&#39;, &#39;encoder_decoder&#39;, &#39;flaubert&#39;, &#39;gpt2&#39;, &#39;longformer&#39;, &#39;marian&#39;, &#39;mmbt&#39;, &#39;mobilebert&#39;, &#39;openai&#39;, &#39;reformer&#39;, &#39;retribert&#39;, &#39;roberta&#39;, &#39;t5&#39;, &#39;transfo_xl&#39;, &#39;utils_base&#39;, &#39;utils_fast&#39;, &#39;xlm&#39;, &#39;xlm_roberta&#39;, &#39;xlnet&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll also create an enum for downstream tasks</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">L</span><span class="p">(</span><span class="n">HF_ARCHITECTURES</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(#27) [&lt;HF_ARCHITECTURES.albert: 1&gt;,&lt;HF_ARCHITECTURES.auto: 2&gt;,&lt;HF_ARCHITECTURES.bart: 3&gt;,&lt;HF_ARCHITECTURES.bert: 4&gt;,&lt;HF_ARCHITECTURES.bert_japanese: 5&gt;,&lt;HF_ARCHITECTURES.camembert: 6&gt;,&lt;HF_ARCHITECTURES.ctrl: 7&gt;,&lt;HF_ARCHITECTURES.distilbert: 8&gt;,&lt;HF_ARCHITECTURES.electra: 9&gt;,&lt;HF_ARCHITECTURES.encoder_decoder: 10&gt;...]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ModelHelper.get_config" class="doc_header"><code>ModelHelper.get_config</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/utils.py#L86" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ModelHelper.get_config</code>(<strong><code>arch</code></strong>)</p>
</blockquote>
<p>Used the locate the name of the configuration class for a given architecture</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_config</span><span class="p">(</span><span class="s1">&#39;bert&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class &#39;transformers.configuration_bert.BertConfig&#39;&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ModelHelper.get_tokenizers" class="doc_header"><code>ModelHelper.get_tokenizers</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/utils.py#L93" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ModelHelper.get_tokenizers</code>(<strong><code>arch</code></strong>)</p>
</blockquote>
<p>Used to get the available huggingface tokenizers for a given architecture. Note: There may be
multiple tokenizers and so this returns a list.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_tokenizers</span><span class="p">(</span><span class="s1">&#39;electra&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&lt;class &#39;transformers.tokenization_electra.ElectraTokenizer&#39;&gt;, &lt;class &#39;transformers.tokenization_electra.ElectraTokenizerFast&#39;&gt;]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ModelHelper.get_tasks" class="doc_header"><code>ModelHelper.get_tasks</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/utils.py#L102" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ModelHelper.get_tasks</code>(<strong><code>arch</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Get the type of tasks for which there is a custom model for (<em>optional: by architecture</em>).
There are a number of customized models built for specific tasks like token classification,
question/answering, LM, etc....</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_tasks</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_tasks</span><span class="p">(</span><span class="s1">&#39;bart&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;CausalLM&#39;, &#39;Classification&#39;, &#39;ConditionalGeneration&#39;, &#39;LMHead&#39;, &#39;LMHeadModel&#39;, &#39;MaskedLM&#39;, &#39;MultipleChoice&#39;, &#39;NextSentencePrediction&#39;, &#39;PreTraining&#39;, &#39;QuestionAnswering&#39;, &#39;QuestionAnsweringSimple&#39;, &#39;Seq2SeqLM&#39;, &#39;SequenceClassification&#39;, &#39;TokenClassification&#39;]

[&#39;ConditionalGeneration&#39;, &#39;QuestionAnswering&#39;, &#39;SequenceClassification&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll create an enum for tasks as well, one for all tasks and another for tasks available via huggingface's <code>AutoModel</code> capabilities</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--- all tasks ---&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">L</span><span class="p">(</span><span class="n">HF_TASKS_ALL</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">--- auto only ---&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">L</span><span class="p">(</span><span class="n">HF_TASKS_AUTO</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>--- all tasks ---
(#14) [&lt;HF_TASKS_ALL.CausalLM: 1&gt;,&lt;HF_TASKS_ALL.Classification: 2&gt;,&lt;HF_TASKS_ALL.ConditionalGeneration: 3&gt;,&lt;HF_TASKS_ALL.LMHead: 4&gt;,&lt;HF_TASKS_ALL.LMHeadModel: 5&gt;,&lt;HF_TASKS_ALL.MaskedLM: 6&gt;,&lt;HF_TASKS_ALL.MultipleChoice: 7&gt;,&lt;HF_TASKS_ALL.NextSentencePrediction: 8&gt;,&lt;HF_TASKS_ALL.PreTraining: 9&gt;,&lt;HF_TASKS_ALL.QuestionAnswering: 10&gt;...]

--- auto only ---
(#9) [&lt;HF_TASKS_AUTO.CausalLM: 1&gt;,&lt;HF_TASKS_AUTO.LMHead: 2&gt;,&lt;HF_TASKS_AUTO.MaskedLM: 3&gt;,&lt;HF_TASKS_AUTO.MultipleChoice: 4&gt;,&lt;HF_TASKS_AUTO.PreTraining: 5&gt;,&lt;HF_TASKS_AUTO.QuestionAnswering: 6&gt;,&lt;HF_TASKS_AUTO.Seq2SeqLM: 7&gt;,&lt;HF_TASKS_AUTO.SequenceClassification: 8&gt;,&lt;HF_TASKS_AUTO.TokenClassification: 9&gt;]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">HF_TASKS_ALL</span><span class="o">.</span><span class="n">Classification</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;HF_TASKS_ALL.Classification: 2&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ModelHelper.get_models" class="doc_header"><code>ModelHelper.get_models</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/utils.py#L112" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ModelHelper.get_models</code>(<strong><code>arch</code></strong>=<em><code>None</code></em>, <strong><code>task</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>The transformer models available for use (optional: by architecture | task)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">L</span><span class="p">(</span><span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_models</span><span class="p">()))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(#136) [&lt;class &#39;transformers.modeling_transfo_xl.AdaptiveEmbedding&#39;&gt;,&lt;class &#39;transformers.modeling_albert.AlbertForMaskedLM&#39;&gt;,&lt;class &#39;transformers.modeling_albert.AlbertForMultipleChoice&#39;&gt;,&lt;class &#39;transformers.modeling_albert.AlbertForPreTraining&#39;&gt;,&lt;class &#39;transformers.modeling_albert.AlbertForQuestionAnswering&#39;&gt;,&lt;class &#39;transformers.modeling_albert.AlbertForSequenceClassification&#39;&gt;,&lt;class &#39;transformers.modeling_albert.AlbertForTokenClassification&#39;&gt;,&lt;class &#39;transformers.modeling_albert.AlbertModel&#39;&gt;,&lt;class &#39;transformers.modeling_albert.AlbertPreTrainedModel&#39;&gt;,&lt;class &#39;transformers.modeling_auto.AutoModel&#39;&gt;...]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_models</span><span class="p">(</span><span class="n">arch</span><span class="o">=</span><span class="s1">&#39;bert&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&lt;class &#39;transformers.modeling_bert.BertForMaskedLM&#39;&gt;, &lt;class &#39;transformers.modeling_bert.BertForMultipleChoice&#39;&gt;, &lt;class &#39;transformers.modeling_bert.BertForNextSentencePrediction&#39;&gt;, &lt;class &#39;transformers.modeling_bert.BertForPreTraining&#39;&gt;, &lt;class &#39;transformers.modeling_bert.BertForQuestionAnswering&#39;&gt;, &lt;class &#39;transformers.modeling_bert.BertForSequenceClassification&#39;&gt;, &lt;class &#39;transformers.modeling_bert.BertForTokenClassification&#39;&gt;, &lt;class &#39;transformers.modeling_bert.BertLMHeadModel&#39;&gt;, &lt;class &#39;transformers.modeling_bert.BertLayer&#39;&gt;, &lt;class &#39;transformers.modeling_bert.BertModel&#39;&gt;, &lt;class &#39;transformers.modeling_bert.BertPreTrainedModel&#39;&gt;]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_models</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s1">&#39;TokenClassification&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&lt;class &#39;transformers.modeling_albert.AlbertForTokenClassification&#39;&gt;, &lt;class &#39;transformers.modeling_auto.AutoModelForTokenClassification&#39;&gt;, &lt;class &#39;transformers.modeling_bert.BertForTokenClassification&#39;&gt;, &lt;class &#39;transformers.modeling_camembert.CamembertForTokenClassification&#39;&gt;, &lt;class &#39;transformers.modeling_distilbert.DistilBertForTokenClassification&#39;&gt;, &lt;class &#39;transformers.modeling_electra.ElectraForTokenClassification&#39;&gt;, &lt;class &#39;transformers.modeling_longformer.LongformerForTokenClassification&#39;&gt;, &lt;class &#39;transformers.modeling_mobilebert.MobileBertForTokenClassification&#39;&gt;, &lt;class &#39;transformers.modeling_roberta.RobertaForTokenClassification&#39;&gt;, &lt;class &#39;transformers.modeling_xlm.XLMForTokenClassification&#39;&gt;, &lt;class &#39;transformers.modeling_xlm_roberta.XLMRobertaForTokenClassification&#39;&gt;, &lt;class &#39;transformers.modeling_xlnet.XLNetForTokenClassification&#39;&gt;]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_models</span><span class="p">(</span><span class="n">arch</span><span class="o">=</span><span class="s1">&#39;bert&#39;</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s1">&#39;TokenClassification&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&lt;class &#39;transformers.modeling_bert.BertForTokenClassification&#39;&gt;]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ModelHelper.get_classes_for_model" class="doc_header"><code>ModelHelper.get_classes_for_model</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/utils.py#L121" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ModelHelper.get_classes_for_model</code>(<strong><code>model_name_or_cls</code></strong>)</p>
</blockquote>
<p>Get tokenizers, config, and model for a given model name / class</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">config</span><span class="p">,</span> <span class="n">tokenizers</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_classes_for_model</span><span class="p">(</span><span class="s1">&#39;RobertaForSequenceClassification&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokenizers</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class &#39;transformers.configuration_roberta.RobertaConfig&#39;&gt;
&lt;class &#39;transformers.tokenization_roberta.RobertaTokenizer&#39;&gt;
&lt;class &#39;transformers.modeling_roberta.RobertaForSequenceClassification&#39;&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">config</span><span class="p">,</span> <span class="n">tokenizers</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_classes_for_model</span><span class="p">(</span><span class="n">DistilBertModel</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokenizers</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class &#39;transformers.configuration_distilbert.DistilBertConfig&#39;&gt;
&lt;class &#39;transformers.tokenization_distilbert.DistilBertTokenizer&#39;&gt;
&lt;class &#39;transformers.modeling_distilbert.DistilBertModel&#39;&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ModelHelper.get_model_architecture" class="doc_header"><code>ModelHelper.get_model_architecture</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/utils.py#L131" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ModelHelper.get_model_architecture</code>(<strong><code>model_name_or_enum</code></strong>)</p>
</blockquote>
<p>Get the architecture for a given model name / enum</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_model_architecture</span><span class="p">(</span><span class="s1">&#39;RobertaForSequenceClassification&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;roberta&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Methods-for-loading-pre-trained-(configs,-tokenizer,-model)-hugginface-classes">Methods for loading pre-trained (configs, tokenizer, model) hugginface classes<a class="anchor-link" href="#Methods-for-loading-pre-trained-(configs,-tokenizer,-model)-hugginface-classes"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ModelHelper.get_hf_objects" class="doc_header"><code>ModelHelper.get_hf_objects</code><a href="https://github.com/ohmeow/blurr/tree/master/blurr/utils.py#L136" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ModelHelper.get_hf_objects</code>(<strong><code>pretrained_model_name_or_path</code></strong>, <strong><code>task</code></strong>=<em><code>None</code></em>, <strong><code>config</code></strong>=<em><code>None</code></em>, <strong><code>tokenizer_cls</code></strong>=<em><code>None</code></em>, <strong><code>model_cls</code></strong>=<em><code>None</code></em>, <strong><code>config_kwargs</code></strong>=<em><code>{}</code></em>, <strong><code>tokenizer_kwargs</code></strong>=<em><code>{}</code></em>, <strong><code>model_kwargs</code></strong>=<em><code>{}</code></em>, <strong><code>cache_dir</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Returns the architecture (str), config (obj), tokenizer (obj), and model (obj) given at minimum a
<code>pre-trained model name or path</code>. Specify a <code>task</code> to ensure the right "AutoModelFor<task>" is used to
create the model.</p>
<p>Optionally, you can pass a config (obj), tokenizer (class), and/or model (class) (along with any
related kwargs for each) to get as specific as you want w/r/t what huggingface objects are returned.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">arch</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="s2">&quot;bert-base-cased-finetuned-mrpc&quot;</span><span class="p">,</span>
                                                                   <span class="n">task</span><span class="o">=</span><span class="n">HF_TASKS_AUTO</span><span class="o">.</span><span class="n">LMHead</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">config</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/wgilliam/anaconda3/envs/blurr/lib/python3.7/site-packages/transformers/modeling_auto.py:798: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.
  FutureWarning,
Some weights of the model checkpoint at bert-base-cased-finetuned-mrpc were not used when initializing BertForMaskedLM: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;]
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-cased-finetuned-mrpc and are newly initialized: [&#39;cls.predictions.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.predictions.decoder.bias&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>bert
&lt;class &#39;transformers.configuration_bert.BertConfig&#39;&gt;
&lt;class &#39;transformers.tokenization_bert.BertTokenizer&#39;&gt;
&lt;class &#39;transformers.modeling_bert.BertForMaskedLM&#39;&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">arch</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="s2">&quot;fmikaelian/flaubert-base-uncased-squad&quot;</span><span class="p">,</span>
                                                                   <span class="n">task</span><span class="o">=</span><span class="n">HF_TASKS_AUTO</span><span class="o">.</span><span class="n">QuestionAnswering</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">config</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of the model checkpoint at fmikaelian/flaubert-base-uncased-squad were not used when initializing FlaubertForQuestionAnsweringSimple: [&#39;qa_outputs.start_logits.dense.weight&#39;, &#39;qa_outputs.start_logits.dense.bias&#39;, &#39;qa_outputs.end_logits.dense_0.weight&#39;, &#39;qa_outputs.end_logits.dense_0.bias&#39;, &#39;qa_outputs.end_logits.LayerNorm.weight&#39;, &#39;qa_outputs.end_logits.LayerNorm.bias&#39;, &#39;qa_outputs.end_logits.dense_1.weight&#39;, &#39;qa_outputs.end_logits.dense_1.bias&#39;, &#39;qa_outputs.answer_class.dense_0.weight&#39;, &#39;qa_outputs.answer_class.dense_0.bias&#39;, &#39;qa_outputs.answer_class.dense_1.weight&#39;]
- This IS expected if you are initializing FlaubertForQuestionAnsweringSimple from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing FlaubertForQuestionAnsweringSimple from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of FlaubertForQuestionAnsweringSimple were not initialized from the model checkpoint at fmikaelian/flaubert-base-uncased-squad and are newly initialized: [&#39;qa_outputs.weight&#39;, &#39;qa_outputs.bias&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>flaubert
&lt;class &#39;transformers.tokenization_flaubert.FlaubertTokenizer&#39;&gt;
&lt;class &#39;transformers.configuration_flaubert.FlaubertConfig&#39;&gt;
&lt;class &#39;transformers.modeling_flaubert.FlaubertForQuestionAnsweringSimple&#39;&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">arch</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">BLURR_MODEL_HELPER</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="s2">&quot;bert-base-cased-finetuned-mrpc&quot;</span><span class="p">,</span>
                                                                   <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                                   <span class="n">tokenizer_cls</span><span class="o">=</span><span class="n">BertTokenizer</span><span class="p">,</span> 
                                                                   <span class="n">model_cls</span><span class="o">=</span><span class="n">BertForNextSentencePrediction</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">config</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of the model checkpoint at bert-base-cased-finetuned-mrpc were not used when initializing BertForNextSentencePrediction: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;]
- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForNextSentencePrediction were not initialized from the model checkpoint at bert-base-cased-finetuned-mrpc and are newly initialized: [&#39;cls.seq_relationship.weight&#39;, &#39;cls.seq_relationship.bias&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>bert
&lt;class &#39;transformers.tokenization_bert.BertTokenizer&#39;&gt;
&lt;class &#39;transformers.configuration_bert.BertConfig&#39;&gt;
&lt;class &#39;transformers.modeling_bert.BertForNextSentencePrediction&#39;&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Cleanup">Cleanup<a class="anchor-link" href="#Cleanup"> </a></h2>
</div>
</div>
</div>
</div>
 

